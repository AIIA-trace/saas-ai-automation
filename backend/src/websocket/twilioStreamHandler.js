const logger = require('../utils/logger');
const azureTTSService = require('../services/azureTTSRestService');
const openaiService = require('../services/openaiService');
const ContextBuilder = require('../utils/contextBuilder');
const { OpenAI } = require('openai');

class TwilioStreamHandler {
  constructor() {
    this.activeStreams = new Map();
    this.audioBuffers = new Map();
    this.conversationState = new Map();
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
    this.ttsService = azureTTSService;
  }

  /**
   * Manejar nueva conexiÃ³n WebSocket
   */
  handleConnection(ws, req) {
    const streamId = `stream_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    ws.streamId = streamId;

    logger.info(`ğŸ”Œ NUEVA CONEXIÃ“N TWILIO STREAM: ${streamId}`);
    logger.info(`ğŸ” Request URL: ${req.url}`);
    logger.info(`ğŸ” Request Headers: ${JSON.stringify(req.headers)}`);

    // Configurar heartbeat
    ws.isAlive = true;
    ws.on('pong', () => {
      ws.isAlive = true;
    });

    // Manejar mensajes
    ws.on('message', async (message) => {
      logger.info(`ğŸ“¨ MENSAJE WEBSOCKET RECIBIDO en ${streamId}: ${message.toString().substring(0, 200)}...`);
      
      try {
        const data = JSON.parse(message);
        logger.info(`ğŸ“¨ DATOS PARSEADOS: ${JSON.stringify(data, null, 2)}`);
        await this.handleTwilioMessage(ws, data);
      } catch (error) {
        logger.error(`âŒ Error parseando mensaje: ${error.message}`);
      }
    });

    // Manejar cierre de conexiÃ³n
    ws.on('close', (code, reason) => {
      logger.info(`ğŸ”Œ ConexiÃ³n cerrada: ${streamId} - CÃ³digo: ${code}, RazÃ³n: ${reason}`);
      this.cleanupStream(streamId);
    });

    // Manejar errores
    ws.on('error', (error) => {
      logger.error(`âŒ Error en WebSocket ${streamId}: ${error.message}`);
      this.cleanupStream(streamId);
    });
  }

  /**
   * Manejo centralizado de mensajes WebSocket de Twilio
   */
  async handleTwilioMessage(ws, data) {
    const event = data.event;
    const streamSid = data.streamSid;
    
    logger.info(`ğŸ“¨ Evento recibido: ${event} para stream: ${streamSid}`);
    
    try {
      // Procesar eventos de forma secuencial y explÃ­cita
      switch (event) {
        case "connected":
          logger.info('ğŸ”Œ Media WS: Connected event received');
          await this.handleStreamConnected(ws, data);
          break;
          
        case "start":
          logger.info('ğŸ¤ Media WS: Start event received');
          // Asegurar que el start se procese completamente antes de continuar
          await this.handleStreamStart(ws, data);
          logger.info(`âœ… Start event procesado completamente para stream: ${streamSid}`);
          break;
          
        case "media":
          // Verificar que el stream estÃ© registrado antes de procesar media
          if (!this.activeStreams.has(streamSid)) {
            logger.warn(`âš ï¸ Media event recibido para stream no registrado: ${streamSid}`);
            logger.info(`ğŸ“Š Streams activos: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
            return;
          }
          await this.handleMediaChunk(ws, data);
          break;
          
        case "stop":
          logger.info('ğŸ›‘ Media WS: Stop event received');
          await this.handleStreamStop(ws, data);
          break;
          
        default:
          logger.warn(`âš ï¸ Evento desconocido: ${event}`);
      }
    } catch (error) {
      logger.error(`âŒ Error procesando evento ${event} para stream ${streamSid}: ${error.message}`);
      logger.error(`âŒ Stack: ${error.stack}`);
      
      // Log adicional del estado actual
      logger.error(`ğŸ“Š Estado actual - Streams activos: ${this.activeStreams.size}`);
      logger.error(`ğŸ—‚ï¸ Stream IDs: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
    }
  }

  /**
   * Stream conectado - inicializar
   */
  async handleStreamConnected(ws, data) {
    logger.info(`âœ… Stream conectado, esperando evento start para parÃ¡metros completos`);
  }

  /**
   * Stream iniciado - configurar cliente
   */
  async handleStreamStart(ws, data) {
    const { streamSid, callSid, customParameters } = data.start;
    const clientId = customParameters?.clientId;

    logger.info(`ğŸ¤ ===== INICIO handleStreamStart =====`);
    logger.info(`ğŸ¤ Processing start event:`);
    logger.info(`ğŸ¤ Stream starting: ${streamSid} for call ${callSid}, clientId: ${clientId}`);
    logger.info(`ğŸ¤ Data completa: ${JSON.stringify(data, null, 2)}`);

    // Verificar si el stream ya existe
    if (this.activeStreams.has(streamSid)) {
      logger.warn(`âš ï¸ Stream ${streamSid} ya existe en activeStreams`);
      return;
    }

    // REGISTRO INMEDIATO DEL STREAM - Antes de la consulta DB lenta
    logger.info('ğŸš€ REGISTRO INMEDIATO: Registrando stream antes de consulta DB...');
    const placeholderStreamData = {
      streamSid,
      ws,
      client: null, // Se llenarÃ¡ despuÃ©s
      callSid,
      audioBuffer: [],
      conversationHistory: [],
      lastActivity: Date.now(),
      isProcessing: false,
      isSendingTTS: false,
      isInitializing: true // Flag para indicar que estÃ¡ inicializando
    };
    
    this.activeStreams.set(streamSid, placeholderStreamData);
    this.audioBuffers.set(streamSid, []);
    this.conversationState.set(streamSid, []);
    
    logger.info(`ğŸš€ Stream registrado INMEDIATAMENTE: ${streamSid}`);
    logger.info(`ğŸ“Š Active streams: ${this.activeStreams.size}`);

    try {
      console.log(`ğŸ” ===== DATABASE CONFIGURATION ANALYSIS =====`);
      console.log(`â° Config Start Time: ${new Date().toISOString()}`);
      
      logger.info('ğŸ” PASO 1: Obteniendo configuraciÃ³n del cliente desde parÃ¡metros...');
      
      // ANÃLISIS COMPLETO DE PARÃMETROS RECIBIDOS
      console.log(`ğŸ“ PARAMETER VALIDATION:`);
      console.log(`  â”œâ”€â”€ ClientId: ${customParameters?.clientId || 'MISSING'}`);
      console.log(`  â”œâ”€â”€ CompanyName: ${customParameters?.companyName || 'MISSING'}`);
      console.log(`  â”œâ”€â”€ Greeting: ${customParameters?.greeting ? customParameters.greeting.substring(0, 50) + '...' : 'MISSING'}`);
      console.log(`  â”œâ”€â”€ VoiceId: ${customParameters?.voiceId || 'MISSING'}`);
      console.log(`  â”œâ”€â”€ Enabled: ${customParameters?.enabled || 'MISSING'}`);
      console.log(`  â””â”€â”€ Email: ${customParameters?.email || 'MISSING'}`);
      
      // OBTENER CONFIGURACIÃ“N COMPLETA DESDE PARÃMETROS - CÃ“DIGO EXACTO DEL TEST
      const clientConfig = {
        id: clientId ? parseInt(clientId) : 1,
        companyName: customParameters?.companyName || 'Sistema de AtenciÃ³n',
        email: customParameters?.email || '',
        callConfig: {
          greeting: customParameters?.greeting || 'Hola, gracias por llamar. Soy el asistente virtual. Â¿En quÃ© puedo ayudarte?',
          voiceId: customParameters?.voiceId || 'es-ES-DarioNeural',
          enabled: customParameters?.enabled !== 'false'
        },
        // Campos JSON exactos como en el test
        companyInfo: customParameters?.companyInfo || null,
        botConfig: customParameters?.botConfig || null,
        businessHours: customParameters?.businessHours || null,
        notificationConfig: customParameters?.notificationConfig || null,
        faqs: JSON.parse(customParameters?.faqs || '[]'), // Parsear como arreglo JSON
        contextFiles: JSON.parse(customParameters?.contextFiles || '[]'), // Parsear como arreglo JSON
        // RelaciÃ³n con nÃºmeros Twilio
        twilioNumbers: [{
          phoneNumber: customParameters?.phoneNumber || '',
          status: 'active'
        }]
      };

      logger.info(`ğŸ” DEBUG STREAM: ParÃ¡metros recibidos del WebSocket:`);
      logger.info(`ğŸ” DEBUG STREAM: - clientId: ${customParameters?.clientId}`);
      logger.info(`ğŸ” DEBUG STREAM: - companyName: ${customParameters?.companyName}`);
      logger.info(`ğŸ” DEBUG STREAM: - greeting: "${customParameters?.greeting}"`);
      logger.info(`ğŸ” DEBUG STREAM: - voiceId: ${customParameters?.voiceId}`);
      logger.info(`ğŸ” DEBUG STREAM: - companyInfo presente: ${!!customParameters?.companyInfo}`);
      logger.info(`ğŸ” DEBUG STREAM: - botConfig presente: ${!!customParameters?.botConfig}`);
      logger.info(`ğŸ” DEBUG STREAM: - businessHours presente: ${!!customParameters?.businessHours}`);
      logger.info(`ğŸ” DEBUG STREAM: - faqs presente: ${!!customParameters?.faqs}`);
      logger.info(`ğŸ” DEBUG STREAM: - contextFiles presente: ${!!customParameters?.contextFiles}`);
      
      logger.info(`ğŸ” PASO 2: Cliente configurado: ${clientConfig.companyName}`);
      logger.info(`ğŸ” PASO 2a: Saludo: "${clientConfig.callConfig.greeting}"`);
      logger.info(`ğŸ” PASO 2b: Voz: "${clientConfig.callConfig.voiceId}"`);
      logger.info(`ğŸ” PASO 2c: FAQs cargadas: ${clientConfig.faqs.length}`);
      logger.info(`ğŸ” PASO 2d: Archivos contexto: ${clientConfig.contextFiles.length}`);

      // GENERAR CONTEXTO COMPLETO PARA OPENAI
      const systemPrompt = ContextBuilder.buildSystemPrompt(clientConfig);
      logger.info(`ğŸ“‹ PASO 2e: Contexto generado: ${systemPrompt.length} caracteres`);

      // ACTUALIZAR EL STREAM CON CONFIGURACIÃ“N REAL Y CONTEXTO
      const streamData = this.activeStreams.get(streamSid);
      streamData.client = clientConfig;
      streamData.systemPrompt = systemPrompt; // Contexto completo disponible
      streamData.isInitializing = false;
      
      logger.info(`ğŸ”„ PASO 3: Stream actualizado con configuraciÃ³n real y contexto completo`);

      logger.info('ğŸ” PASO 4: Enviando saludo inicial con configuraciÃ³n real...');
      
      // Enviar saludo con configuraciÃ³n real
      const greetingPromise = this.sendInitialGreeting(ws, { streamSid, callSid });
      
      const greetingTimeout = new Promise((_, reject) => {
        setTimeout(() => reject(new Error('sendInitialGreeting timeout after 10 seconds')), 10000);
      });

      try {
        await Promise.race([greetingPromise, greetingTimeout]);
        logger.info('ğŸ” PASO 7: âœ… Saludo inicial enviado correctamente');
      } catch (error) {
        logger.error(`âŒ Error en saludo inicial: ${error.message}`);
        // Continuar sin saludo si hay error
      }
      
      logger.info('ğŸ” PASO 8: âœ… handleStreamStart COMPLETADO EXITOSAMENTE');

      // VerificaciÃ³n final
      logger.info(`ğŸ” VERIFICACIÃ“N FINAL: Stream ${streamSid} existe: ${this.activeStreams.has(streamSid)}`);

    } catch (error) {
      logger.error(`âŒ Error in handleStreamStart: ${error.message}`);
      logger.error(`âŒ Stack: ${error.stack}`);
      
      // Limpiar en caso de error
      this.activeStreams.delete(streamSid);
      this.audioBuffers.delete(streamSid);
      this.conversationState.delete(streamSid);
      
      throw error; // Re-lanzar el error para que se capture en el nivel superior
    }
  }

  /**
   * Enviar saludo inicial con Azure TTS - DEBUG ULTRA-DETALLADO
   */
  async sendInitialGreeting(ws, data) {
    const debugId = `DEBUG_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const startTime = Date.now();
    
    try {
      logger.info(`ğŸ” [${debugId}] ===== INICIO SALUDO INICIAL ULTRA-DEBUG =====`);
      logger.info(`ğŸ” [${debugId}] Timestamp: ${new Date().toISOString()}`);
      logger.info(`ğŸ” [${debugId}] WebSocket state: ${ws.readyState} (1=OPEN, 0=CONNECTING, 2=CLOSING, 3=CLOSED)`);
      
      const { streamSid, callSid } = data;
      logger.info(`ğŸ” [${debugId}] StreamSid: ${streamSid}`);
      logger.info(`ğŸ” [${debugId}] CallSid: ${callSid}`);
      
      // PASO 1: Verificar stream data
      logger.info(`ğŸ” [${debugId}] PASO 1: Verificando stream data...`);
      const streamData = this.activeStreams.get(streamSid);
      if (!streamData) {
        logger.error(`âŒ [${debugId}] FALLO CRÃTICO: No se encontrÃ³ stream data para ${streamSid}`);
        logger.error(`âŒ [${debugId}] Active streams disponibles: ${Array.from(this.activeStreams.keys())}`);
        return;
      }
      logger.info(`âœ… [${debugId}] Stream data encontrado`);

      // PASO 2: Verificar cliente
      logger.info(`ğŸ” [${debugId}] PASO 2: Verificando cliente...`);
      const { client } = streamData;
      if (!client) {
        logger.error(`âŒ [${debugId}] FALLO CRÃTICO: No hay cliente en stream data`);
        return;
      }
      logger.info(`âœ… [${debugId}] Cliente encontrado: ID=${client.id}, Email=${client.email}`);
      
      // PASO 3: Analizar callConfig en detalle
      logger.info(`ğŸ” [${debugId}] PASO 3: Analizando callConfig...`);
      logger.info(`ğŸ” [${debugId}] client.callConfig existe: ${!!client.callConfig}`);
      
      if (client.callConfig) {
        logger.info(`ğŸ” [${debugId}] callConfig tipo: ${typeof client.callConfig}`);
        logger.info(`ğŸ” [${debugId}] callConfig keys: ${Object.keys(client.callConfig)}`);
        logger.info(`ğŸ” [${debugId}] callConfig completo: ${JSON.stringify(client.callConfig, null, 2)}`);
      } else {
        logger.warn(`âš ï¸ [${debugId}] callConfig es null/undefined`);
      }
      
      // DIAGNÃ“STICO COMPLETO DEL SALUDO
      logger.info(`ğŸ” [${debugId}] PASO 3a: DIAGNÃ“STICO COMPLETO DEL SALUDO`);
      
      const expectedGreeting = 'Hola, gracias por llamar. Soy el asistente virtual. Â¿En quÃ© puedo ayudarte?';
      let greeting = expectedGreeting;
      
      // AnÃ¡lisis detallado de por quÃ© el saludo puede estar vacÃ­o
      logger.info(`ğŸ“ [${debugId}] ANÃLISIS DEL SALUDO:`);
      logger.info(`ğŸ“ [${debugId}]   â”œâ”€â”€ Saludo esperado: "${expectedGreeting}"`);
      logger.info(`ğŸ“ [${debugId}]   â”œâ”€â”€ client existe: ${!!client}`);
      logger.info(`ğŸ“ [${debugId}]   â”œâ”€â”€ client.callConfig existe: ${!!client?.callConfig}`);
      logger.info(`ğŸ“ [${debugId}]   â”œâ”€â”€ client.callConfig.greeting existe: ${!!client?.callConfig?.greeting}`);
      
      if (client?.callConfig?.greeting) {
        const receivedGreeting = client.callConfig.greeting;
        logger.info(`ğŸ“ [${debugId}]   â”œâ”€â”€ Saludo recibido: "${receivedGreeting}"`);
        logger.info(`ğŸ“ [${debugId}]   â”œâ”€â”€ Tipo: ${typeof receivedGreeting}`);
        logger.info(`ğŸ“ [${debugId}]   â”œâ”€â”€ Longitud: ${receivedGreeting.length}`);
        logger.info(`ğŸ“ [${debugId}]   â””â”€â”€ Es vacÃ­o: ${!receivedGreeting || receivedGreeting.trim().length === 0}`);
        
        if (!receivedGreeting || receivedGreeting.trim().length === 0) {
          logger.error(`âŒ [${debugId}] TEXTO VACÃO DETECTADO:`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ PROBLEMA: client.callConfig.greeting estÃ¡ vacÃ­o o es null`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ VALOR ESPERADO: "${expectedGreeting}"`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ VALOR RECIBIDO: "${receivedGreeting}"`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ CAUSA RAÃZ: Base de datos no tiene greeting configurado para el cliente`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ SOLUCIÃ“N: Verificar tabla clients, campo callConfig.greeting`);
          logger.error(`âŒ [${debugId}]   â””â”€â”€ ACCIÃ“N: Usando saludo por defecto para evitar audio vacÃ­o`);
          greeting = expectedGreeting;
        } else {
          greeting = receivedGreeting;
          logger.info(`âœ… [${debugId}] Saludo personalizado vÃ¡lido obtenido: "${greeting}"`);
        }
      } else {
        logger.warn(`âš ï¸ [${debugId}] CONFIGURACIÃ“N DE SALUDO FALTANTE:`);
        logger.warn(`âš ï¸ [${debugId}]   â”œâ”€â”€ PROBLEMA: No hay client.callConfig.greeting`);
        logger.warn(`âš ï¸ [${debugId}]   â”œâ”€â”€ POSIBLES CAUSAS:`);
        logger.warn(`âš ï¸ [${debugId}]   â”‚   â”œâ”€â”€ Cliente no tiene callConfig en BD`);
        logger.warn(`âš ï¸ [${debugId}]   â”‚   â”œâ”€â”€ callConfig.greeting es null en BD`);
        logger.warn(`âš ï¸ [${debugId}]   â”‚   â””â”€â”€ Error en consulta de BD o parÃ¡metros WebSocket`);
        logger.warn(`âš ï¸ [${debugId}]   â”œâ”€â”€ VALOR ESPERADO: "${expectedGreeting}"`);
        logger.warn(`âš ï¸ [${debugId}]   â”œâ”€â”€ ACCIÃ“N: Usando saludo por defecto`);
        logger.warn(`âš ï¸ [${debugId}]   â””â”€â”€ RECOMENDACIÃ“N: Configurar greeting en dashboard del cliente`);
        greeting = expectedGreeting;
      }

      // DIAGNÃ“STICO COMPLETO DE VOZ
      logger.info(`ğŸ” [${debugId}] PASO 3b: DIAGNÃ“STICO COMPLETO DE VOZ`);
      
      const voiceMapping = {
        'neutral': 'es-ES-DarioNeural',
        'lola': 'en-US-LolaMultilingualNeural',
        'dario': 'es-ES-DarioNeural',
        'elvira': 'es-ES-ElviraNeural',
        'female': 'es-ES-ElviraNeural',
        'male': 'es-ES-DarioNeural'
      };
      
      const validAzureVoices = [
        'es-ES-DarioNeural', 'es-ES-ElviraNeural', 'es-ES-AlvaroNeural',
        'en-US-LolaMultilingualNeural', 'es-ES-ArabellaMultilingualNeural'
      ];
      
      const expectedVoice = 'es-ES-DarioNeural';
      let voiceId = expectedVoice;
      
      logger.info(`ğŸ¤ [${debugId}] ANÃLISIS DE VOZ:`);
      logger.info(`ğŸ¤ [${debugId}]   â”œâ”€â”€ Voz esperada por defecto: "${expectedVoice}"`);
      logger.info(`ğŸ¤ [${debugId}]   â”œâ”€â”€ Voces vÃ¡lidas Azure: [${validAzureVoices.join(', ')}]`);
      logger.info(`ğŸ¤ [${debugId}]   â”œâ”€â”€ Mapeo legacy disponible: ${JSON.stringify(voiceMapping, null, 2)}`);
      logger.info(`ğŸ¤ [${debugId}]   â”œâ”€â”€ client.callConfig.voiceId existe: ${!!client?.callConfig?.voiceId}`);
      
      if (client?.callConfig?.voiceId) {
        const userVoice = client.callConfig.voiceId;
        logger.info(`ğŸ¤ [${debugId}]   â”œâ”€â”€ Voz recibida del cliente: "${userVoice}"`);
        logger.info(`ğŸ¤ [${debugId}]   â”œâ”€â”€ Tipo: ${typeof userVoice}`);
        logger.info(`ğŸ¤ [${debugId}]   â”œâ”€â”€ Es legacy voice: ${!!voiceMapping[userVoice]}`);
        logger.info(`ğŸ¤ [${debugId}]   â”œâ”€â”€ Es voz Azure vÃ¡lida: ${validAzureVoices.includes(userVoice)}`);
        
        // Mapear voz legacy o usar directamente si es vÃ¡lida de Azure
        if (voiceMapping[userVoice]) {
          voiceId = voiceMapping[userVoice];
          logger.info(`âœ… [${debugId}]   â”œâ”€â”€ MAPEO LEGACY: "${userVoice}" â†’ "${voiceId}"`);
          logger.info(`âœ… [${debugId}]   â””â”€â”€ Voz final vÃ¡lida para Azure TTS`);
        } else if (validAzureVoices.includes(userVoice)) {
          voiceId = userVoice;
          logger.info(`âœ… [${debugId}]   â”œâ”€â”€ VOZ AZURE VÃLIDA: "${userVoice}" usada directamente`);
          logger.info(`âœ… [${debugId}]   â””â”€â”€ No requiere mapeo`);
        } else {
          logger.error(`âŒ [${debugId}] VOZ INVÃLIDA DETECTADA:`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ PROBLEMA: Voz "${userVoice}" no es vÃ¡lida para Azure TTS`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ VALOR ESPERADO: Una de [${validAzureVoices.join(', ')}]`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ VALOR RECIBIDO: "${userVoice}"`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ CAUSA RAÃZ: Base de datos tiene voiceId invÃ¡lido o no mapeado`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ SOLUCIÃ“N: Actualizar callConfig.voiceId en BD o aÃ±adir mapeo`);
          logger.error(`âŒ [${debugId}]   â”œâ”€â”€ ACCIÃ“N: Usando voz por defecto "${expectedVoice}"`);
          logger.error(`âŒ [${debugId}]   â””â”€â”€ ESTO CAUSARÃ ERROR 400 EN AZURE TTS SI NO SE CORRIGE`);
          voiceId = expectedVoice;
        }
      } else {
        logger.warn(`âš ï¸ [${debugId}] CONFIGURACIÃ“N DE VOZ FALTANTE:`);
        logger.warn(`âš ï¸ [${debugId}]   â”œâ”€â”€ PROBLEMA: No hay client.callConfig.voiceId`);
        logger.warn(`âš ï¸ [${debugId}]   â”œâ”€â”€ POSIBLES CAUSAS:`);
        logger.warn(`âš ï¸ [${debugId}]   â”‚   â”œâ”€â”€ Cliente no tiene callConfig en BD`);
        logger.warn(`âš ï¸ [${debugId}]   â”‚   â”œâ”€â”€ callConfig.voiceId es null en BD`);
        logger.warn(`âš ï¸ [${debugId}]   â”‚   â””â”€â”€ Error en consulta de BD o parÃ¡metros WebSocket`);
        logger.warn(`âš ï¸ [${debugId}]   â”œâ”€â”€ VALOR ESPERADO: "${expectedVoice}" o una voz vÃ¡lida`);
        logger.warn(`âš ï¸ [${debugId}]   â”œâ”€â”€ ACCIÃ“N: Usando voz por defecto`);
        logger.warn(`âš ï¸ [${debugId}]   â””â”€â”€ RECOMENDACIÃ“N: Configurar voiceId en dashboard del cliente`);
        voiceId = expectedVoice;
      }

      // DIAGNÃ“STICO COMPLETO DE VARIABLES AZURE
      logger.info(`ğŸ” [${debugId}] PASO 4: DIAGNÃ“STICO COMPLETO DE VARIABLES AZURE`);
      
      const expectedAzureKey = 'Una clave vÃ¡lida de 32+ caracteres de Azure Speech Service';
      const expectedAzureRegion = 'westeurope, eastus, etc.';
      
      const azureKey = process.env.AZURE_SPEECH_KEY;
      const azureRegion = process.env.AZURE_SPEECH_REGION;
      
      logger.info(`ğŸ”§ [${debugId}] ANÃLISIS DE VARIABLES AZURE:`);
      logger.info(`ğŸ”§ [${debugId}]   â”œâ”€â”€ AZURE_SPEECH_KEY esperada: ${expectedAzureKey}`);
      logger.info(`ğŸ”§ [${debugId}]   â”œâ”€â”€ AZURE_SPEECH_REGION esperada: ${expectedAzureRegion}`);
      logger.info(`ğŸ”§ [${debugId}]   â”œâ”€â”€ AZURE_SPEECH_KEY existe: ${!!azureKey}`);
      logger.info(`ğŸ”§ [${debugId}]   â”œâ”€â”€ AZURE_SPEECH_KEY longitud: ${azureKey?.length || 0}`);
      logger.info(`ğŸ”§ [${debugId}]   â”œâ”€â”€ AZURE_SPEECH_REGION recibida: "${azureRegion}"`);
      logger.info(`ğŸ”§ [${debugId}]   â””â”€â”€ AZURE_SPEECH_REGION tipo: ${typeof azureRegion}`);
      
      if (!azureKey) {
        logger.error(`âŒ [${debugId}] VARIABLE AZURE KEY FALTANTE:`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ PROBLEMA: AZURE_SPEECH_KEY no estÃ¡ definida`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ VALOR ESPERADO: ${expectedAzureKey}`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ VALOR RECIBIDO: undefined/null`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ CAUSA RAÃZ: Variable de entorno no configurada en servidor`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ SOLUCIÃ“N: Configurar AZURE_SPEECH_KEY en .env o variables del sistema`);
        logger.error(`âŒ [${debugId}]   â””â”€â”€ ESTO CAUSARÃ FALLO TOTAL EN AZURE TTS`);
        throw new Error('AZURE_SPEECH_KEY no configurada');
      }
      
      if (!azureRegion) {
        logger.error(`âŒ [${debugId}] VARIABLE AZURE REGION FALTANTE:`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ PROBLEMA: AZURE_SPEECH_REGION no estÃ¡ definida`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ VALOR ESPERADO: ${expectedAzureRegion}`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ VALOR RECIBIDO: undefined/null`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ CAUSA RAÃZ: Variable de entorno no configurada en servidor`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ SOLUCIÃ“N: Configurar AZURE_SPEECH_REGION en .env o variables del sistema`);
        logger.error(`âŒ [${debugId}]   â””â”€â”€ ESTO CAUSARÃ FALLO TOTAL EN AZURE TTS`);
        throw new Error('AZURE_SPEECH_REGION no configurada');
      }
      
      if (azureKey.length < 32) {
        logger.error(`âŒ [${debugId}] AZURE KEY INVÃLIDA:`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ PROBLEMA: AZURE_SPEECH_KEY demasiado corta`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ LONGITUD ESPERADA: 32+ caracteres`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ LONGITUD RECIBIDA: ${azureKey.length}`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ CAUSA RAÃZ: Clave incorrecta o truncada`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ SOLUCIÃ“N: Verificar clave en Azure Portal > Speech Service > Keys`);
        logger.error(`âŒ [${debugId}]   â””â”€â”€ ESTO CAUSARÃ ERROR 401/403 EN AZURE TTS`);
      }
      
      logger.info(`âœ… [${debugId}] Variables Azure configuradas correctamente`);
      logger.info(`âœ… [${debugId}]   â”œâ”€â”€ Key: ${azureKey.substring(0, 8)}...${azureKey.substring(azureKey.length - 4)}`);
      logger.info(`âœ… [${debugId}]   â””â”€â”€ Region: ${azureRegion}`);
      
      // DIAGNÃ“STICO DE WEBSOCKET
      logger.info(`ğŸ” [${debugId}] PASO 4b: DIAGNÃ“STICO DE WEBSOCKET`);
      const expectedWebSocketState = 1; // OPEN
      const currentWebSocketState = ws.readyState;
      
      logger.info(`ğŸ”Œ [${debugId}] ANÃLISIS DE WEBSOCKET:`);
      logger.info(`ğŸ”Œ [${debugId}]   â”œâ”€â”€ Estado esperado: ${expectedWebSocketState} (OPEN)`);
      logger.info(`ğŸ”Œ [${debugId}]   â”œâ”€â”€ Estado actual: ${currentWebSocketState}`);
      logger.info(`ğŸ”Œ [${debugId}]   â”œâ”€â”€ Estados posibles: 0=CONNECTING, 1=OPEN, 2=CLOSING, 3=CLOSED`);
      
      if (currentWebSocketState !== 1) {
        logger.error(`âŒ [${debugId}] WEBSOCKET CERRADO/INVÃLIDO:`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ PROBLEMA: WebSocket no estÃ¡ en estado OPEN`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ ESTADO ESPERADO: 1 (OPEN)`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ ESTADO ACTUAL: ${currentWebSocketState}`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ CAUSA RAÃZ: ConexiÃ³n cerrada prematuramente o timeout`);
        logger.error(`âŒ [${debugId}]   â”œâ”€â”€ SOLUCIÃ“N: Verificar conectividad de red y timeouts`);
        logger.error(`âŒ [${debugId}]   â””â”€â”€ ESTO IMPEDIRÃ ENVÃO DE AUDIO A TWILIO`);
        throw new Error(`WebSocket cerrado: estado ${currentWebSocketState}`);
      }
      
      logger.info(`âœ… [${debugId}] WebSocket en estado correcto para envÃ­o de audio`);

      // PASO 5: Generar audio con timing detallado
      logger.info(`ğŸ” [${debugId}] PASO 5: Iniciando generaciÃ³n de audio...`);
      logger.info(`ğŸ” [${debugId}] Texto a sintetizar: "${greeting}" (${greeting.length} caracteres)`);
      logger.info(`ğŸ” [${debugId}] Voz Azure: ${voiceId}`);
      logger.info(`ğŸ” [${debugId}] TTS Service disponible: ${!!this.ttsService}`);
      logger.info(`ğŸ” [${debugId}] MÃ©todo generateSpeech disponible: ${typeof this.ttsService?.generateSpeech}`);
      
      const ttsStartTime = Date.now();
      
      try {
        logger.info(`ğŸ” [${debugId}] âš¡ LLAMANDO A AZURE TTS - INICIO`);
        logger.info(`ğŸ” [${debugId}] âš¡ ParÃ¡metros: texto="${greeting.substring(0, 50)}...", voz="${voiceId}"`);
        const audioResult = await this.ttsService.generateSpeech(greeting, voiceId);
        logger.info(`ğŸ” [${debugId}] âš¡ AZURE TTS COMPLETADO - resultado recibido`);
        logger.info(`ğŸ” [${debugId}] âš¡ Tipo de resultado: ${typeof audioResult}`);
        logger.info(`ğŸ” [${debugId}] âš¡ Resultado es objeto: ${audioResult !== null && typeof audioResult === 'object'}`);
        logger.info(`ğŸ” [${debugId}] âš¡ Keys del resultado: ${audioResult ? Object.keys(audioResult).join(', ') : 'N/A'}`);
        logger.info(`ğŸ” [${debugId}] âš¡ Success property: ${audioResult?.success}`);
        logger.info(`ğŸ” [${debugId}] âš¡ AudioBuffer exists: ${!!audioResult?.audioBuffer}`);
        logger.info(`ğŸ” [${debugId}] âš¡ AudioBuffer length: ${audioResult?.audioBuffer?.length || 0}`);
        logger.info(`ğŸ” [${debugId}] âš¡ Error property: ${audioResult?.error || 'none'}`);
        logger.info(`ğŸ” [${debugId}] âš¡ AZURE TTS ANÃLISIS COMPLETO`);
        
        if (audioResult?.audioBuffer && audioResult.audioBuffer.length > 0) {
          logger.info(`ğŸ” [${debugId}] âš¡ AUDIO VÃLIDO DETECTADO - ${audioResult.audioBuffer.length} bytes`);
        } else {
          logger.error(`ğŸ” [${debugId}] âš¡ AUDIO INVÃLIDO O VACÃO DETECTADO`);
        }
        const ttsEndTime = Date.now();
        const ttsDuration = ttsEndTime - ttsStartTime;
        
        logger.info(`ğŸ” [${debugId}] TTS completado en ${ttsDuration}ms`);
        logger.info(`ğŸ” [${debugId}] Resultado TTS:`);
        logger.info(`ğŸ” [${debugId}]   - success: ${audioResult?.success}`);
        logger.info(`ğŸ” [${debugId}]   - error: ${audioResult?.error || 'ninguno'}`);
        logger.info(`ğŸ” [${debugId}]   - audioBuffer existe: ${!!audioResult?.audioBuffer}`);
        
        if (audioResult?.audioBuffer) {
          logger.info(`ğŸ” [${debugId}]   - audioBuffer tipo: ${typeof audioResult.audioBuffer}`);
          logger.info(`ğŸ” [${debugId}]   - audioBuffer constructor: ${audioResult.audioBuffer.constructor.name}`);
          logger.info(`ğŸ” [${debugId}]   - audioBuffer length: ${audioResult.audioBuffer.byteLength || audioResult.audioBuffer.length}`);
        }
        
        if (!audioResult || !audioResult.success) {
          const errorMsg = `Azure TTS fallÃ³: ${audioResult?.error || 'Error desconocido'}`;
          logger.error(`âŒ [${debugId}] ${errorMsg}`);
          throw new Error(errorMsg);
        }

        // PASO 6: Procesar buffer de audio
        logger.info(`ğŸ” [${debugId}] PASO 6: Procesando buffer de audio...`);
        
        if (!audioResult.audioBuffer) {
          logger.error(`âŒ [${debugId}] FALLO: audioBuffer es null/undefined`);
          throw new Error('Audio buffer vacÃ­o');
        }
        
        const audioBuffer = Buffer.from(audioResult.audioBuffer);
        logger.info(`âœ… [${debugId}] Buffer creado exitosamente:`);
        logger.info(`ğŸ” [${debugId}]   - TamaÃ±o original: ${audioResult.audioBuffer.byteLength} bytes`);
        logger.info(`ğŸ” [${debugId}]   - Buffer Node.js: ${audioBuffer.length} bytes`);
        logger.info(`ğŸ” [${debugId}]   - Primeros 10 bytes: [${Array.from(audioBuffer.slice(0, 10)).join(', ')}]`);
        logger.info(`ğŸ” [${debugId}]   - Ãšltimos 10 bytes: [${Array.from(audioBuffer.slice(-10)).join(', ')}]`);
        
        // Verificar formato de audio
        const isValidAudio = audioBuffer.length > 44; // MÃ­nimo para WAV header
        logger.info(`ğŸ” [${debugId}]   - Audio vÃ¡lido (>44 bytes): ${isValidAudio}`);
        
        if (audioBuffer.length > 4) {
          const header = audioBuffer.slice(0, 4).toString('ascii');
          logger.info(`ğŸ” [${debugId}]   - Header detectado: "${header}"`);
        }

        // PASO 7: Verificar WebSocket antes de enviar
        logger.info(`ğŸ” [${debugId}] PASO 7: Verificando WebSocket...`);
        logger.info(`ğŸ” [${debugId}] WebSocket readyState: ${ws.readyState}`);
        logger.info(`ğŸ” [${debugId}] WebSocket bufferedAmount: ${ws.bufferedAmount}`);
        
        if (ws.readyState !== 1) {
          logger.error(`âŒ [${debugId}] FALLO: WebSocket no estÃ¡ abierto (state: ${ws.readyState})`);
          throw new Error(`WebSocket no disponible (state: ${ws.readyState})`);
        }

        // PASO 8: Enviar audio a Twilio con timing
        logger.info(`ğŸ” [${debugId}] PASO 8: Enviando audio a Twilio...`);
        const sendStartTime = Date.now();
        
        await this.sendAudioToTwilio(ws, audioBuffer, streamSid);
        
        const sendEndTime = Date.now();
        const sendDuration = sendEndTime - sendStartTime;
        const totalDuration = sendEndTime - startTime;
        
        logger.info(`âœ… [${debugId}] Ã‰XITO COMPLETO:`);
        logger.info(`ğŸ” [${debugId}]   - TTS generaciÃ³n: ${ttsDuration}ms`);
        logger.info(`ğŸ” [${debugId}]   - EnvÃ­o a Twilio: ${sendDuration}ms`);
        logger.info(`ğŸ” [${debugId}]   - Tiempo total: ${totalDuration}ms`);
        logger.info(`ğŸ” [${debugId}]   - Audio enviado: ${audioBuffer.length} bytes`);
        
      } catch (ttsError) {
        const ttsEndTime = Date.now();
        const ttsDuration = ttsEndTime - ttsStartTime;
        
        logger.error(`âŒ [${debugId}] ERROR EN TTS despuÃ©s de ${ttsDuration}ms:`);
        logger.error(`âŒ [${debugId}] Error message: ${ttsError.message}`);
        logger.error(`âŒ [${debugId}] Error stack: ${ttsError.stack}`);
        logger.error(`âŒ [${debugId}] Error name: ${ttsError.name}`);
        
        if (ttsError.code) {
          logger.error(`âŒ [${debugId}] Error code: ${ttsError.code}`);
        }
        
        logger.info(`ğŸ”„ [${debugId}] Activando fallback...`);
        await this.sendTextFallback(ws, greeting, streamSid);
        throw ttsError;
      }

    } catch (error) {
      const totalDuration = Date.now() - startTime;
      logger.error(`âŒ [${debugId}] ERROR GENERAL despuÃ©s de ${totalDuration}ms:`);
      logger.error(`âŒ [${debugId}] Error: ${error.message}`);
      logger.error(`âŒ [${debugId}] Stack: ${error.stack}`);
      logger.error(`âŒ [${debugId}] ===== FIN SALUDO INICIAL (CON ERROR) =====`);
    }
  }

  /**
   * Fallback para enviar audio simple cuando Azure TTS falla - DEBUG DETALLADO
   */
  async sendTextFallback(ws, text, streamSid) {
    const fallbackId = `FALLBACK_${Date.now()}`;
    
    try {
      logger.info(`ğŸ”„ [${fallbackId}] ===== INICIANDO FALLBACK =====`);
      logger.info(`ğŸ”„ [${fallbackId}] Texto original: "${text}"`);
      logger.info(`ğŸ”„ [${fallbackId}] StreamSid: ${streamSid}`);
      logger.info(`ğŸ”„ [${fallbackId}] WebSocket state: ${ws.readyState}`);
      
      // DIAGNÃ“STICO COMPLETO DEL MÃ‰TODO sendAudioToTwilio
      logger.info(`ğŸ” [${fallbackId}] VERIFICANDO MÃ‰TODO sendAudioToTwilio:`);
      logger.info(`ğŸ” [${fallbackId}]   â”œâ”€â”€ this existe: ${!!this}`);
      logger.info(`ğŸ” [${fallbackId}]   â”œâ”€â”€ this.sendAudioToTwilio existe: ${!!this.sendAudioToTwilio}`);
      logger.info(`ğŸ” [${fallbackId}]   â”œâ”€â”€ Tipo de sendAudioToTwilio: ${typeof this.sendAudioToTwilio}`);
      logger.info(`ğŸ” [${fallbackId}]   â””â”€â”€ Es funciÃ³n: ${typeof this.sendAudioToTwilio === 'function'}`);
      
      if (typeof this.sendAudioToTwilio !== 'function') {
        logger.error(`âŒ [${fallbackId}] MÃ‰TODO sendAudioToTwilio NO DISPONIBLE:`);
        logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ PROBLEMA: this.sendAudioToTwilio no es una funciÃ³n`);
        logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ TIPO ACTUAL: ${typeof this.sendAudioToTwilio}`);
        logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ ESPERADO: function`);
        logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ CAUSA RAÃZ: MÃ©todo no definido o contexto 'this' incorrecto`);
        logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ SOLUCIÃ“N: Verificar definiciÃ³n de clase y binding`);
        logger.error(`âŒ [${fallbackId}]   â””â”€â”€ ACCIÃ“N: Saltando envÃ­o de beep, solo enviando mark`);
        
        // Solo enviar mark sin audio
        const markMessage = {
          event: 'mark',
          streamSid: streamSid,
          mark: {
            name: `tts_fallback_no_audio_${Date.now()}`
          }
        };
        
        if (ws.readyState === 1) {
          ws.send(JSON.stringify(markMessage));
          logger.info(`âœ… [${fallbackId}] Mark enviado sin audio debido a mÃ©todo faltante`);
        }
        return;
      }
      
      // Intentar generar un beep simple como audio de fallback
      logger.info(`ğŸ”„ [${fallbackId}] Generando beep de fallback...`);
      const fallbackAudio = this.generateSimpleBeep();
      
      if (fallbackAudio) {
        logger.info(`ğŸ”„ [${fallbackId}] Beep generado: ${fallbackAudio.length} bytes`);
        
        if (ws.readyState === 1) {
          logger.info(`ğŸ”„ [${fallbackId}] Enviando beep a Twilio...`);
          try {
            await this.sendAudioToTwilio(ws, fallbackAudio, streamSid);
            logger.info(`âœ… [${fallbackId}] Beep enviado exitosamente`);
          } catch (sendError) {
            logger.error(`âŒ [${fallbackId}] ERROR EN sendAudioToTwilio:`);
            logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ Error: ${sendError.message}`);
            logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ Stack: ${sendError.stack?.substring(0, 100)}...`);
            logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ CAUSA RAÃZ: ExcepciÃ³n en mÃ©todo sendAudioToTwilio`);
            logger.error(`âŒ [${fallbackId}]   â””â”€â”€ ACCIÃ“N: Continuando con mark solamente`);
          }
        } else {
          logger.error(`âŒ [${fallbackId}] WebSocket no disponible para beep (state: ${ws.readyState})`);
        }
      } else {
        logger.error(`âŒ [${fallbackId}] BEEP NO GENERADO:`);
        logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ PROBLEMA: generateSimpleBeep() devolviÃ³ null/undefined`);
        logger.error(`âŒ [${fallbackId}]   â”œâ”€â”€ CAUSA RAÃZ: Error en generaciÃ³n de audio sintÃ©tico`);
        logger.error(`âŒ [${fallbackId}]   â””â”€â”€ ACCIÃ“N: Continuando sin audio de fallback`);
      }
      
      // TambiÃ©n enviar un mark para indicar que hubo un problema
      const markMessage = {
        event: 'mark',
        streamSid: streamSid,
        mark: {
          name: `tts_fallback_${Date.now()}`
        }
      };
      
      if (ws.readyState === 1) {
        ws.send(JSON.stringify(markMessage));
      }
      
      logger.info(`âœ… Fallback enviado para ${streamSid}`);
      
    } catch (error) {
      logger.error(`âŒ Error enviando fallback: ${error.message}`);
    }
  }

  /**
   * Enviar audio a Twilio via WebSocket
   */
  async sendAudioToTwilio(ws, audioBuffer, streamSid) {
    const sendId = `SEND_${Date.now()}`;
    
    try {
      logger.info(`ğŸ” [${sendId}] ===== ENVIANDO AUDIO A TWILIO =====`);
      logger.info(`ğŸ” [${sendId}] StreamSid: ${streamSid}`);
      
      // DIAGNÃ“STICO COMPLETO DEL BUFFER
      logger.info(`ğŸµ [${sendId}] ANÃLISIS DEL BUFFER RECIBIDO:`);
      logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Buffer existe: ${!!audioBuffer}`);
      logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Buffer tipo: ${audioBuffer ? audioBuffer.constructor.name : 'N/A'}`);
      logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Buffer length: ${audioBuffer ? audioBuffer.length : 0} bytes`);
      
      if (!audioBuffer || audioBuffer.length === 0) {
        logger.error(`âŒ [${sendId}] BUFFER VACÃO DETECTADO:`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ PROBLEMA: audioBuffer es null/undefined o tiene 0 bytes`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ ESPERADO: Buffer vÃ¡lido con datos de audio`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ RECIBIDO: ${audioBuffer ? `${audioBuffer.length} bytes` : 'null/undefined'}`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ CAUSA RAÃZ: Azure TTS no generÃ³ audio o fallÃ³ la conversiÃ³n`);
        logger.error(`âŒ [${sendId}]   â””â”€â”€ ACCIÃ“N: Abortando envÃ­o para evitar error en Twilio`);
        return;
      }

      // DIAGNÃ“STICO COMPLETO DEL WEBSOCKET
      logger.info(`ğŸ”Œ [${sendId}] ANÃLISIS DEL WEBSOCKET:`);
      logger.info(`ğŸ”Œ [${sendId}]   â”œâ”€â”€ WebSocket existe: ${!!ws}`);
      logger.info(`ğŸ”Œ [${sendId}]   â”œâ”€â”€ ReadyState: ${ws.readyState}`);
      logger.info(`ğŸ”Œ [${sendId}]   â”œâ”€â”€ BufferedAmount: ${ws.bufferedAmount} bytes`);
      logger.info(`ğŸ”Œ [${sendId}]   â””â”€â”€ Estados: 0=CONNECTING, 1=OPEN, 2=CLOSING, 3=CLOSED`);
      
      if (ws.readyState !== 1) {
        logger.error(`âŒ [${sendId}] WEBSOCKET NO DISPONIBLE:`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ PROBLEMA: WebSocket no estÃ¡ en estado OPEN`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ ESTADO ESPERADO: 1 (OPEN)`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ ESTADO ACTUAL: ${ws.readyState}`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ CAUSA RAÃZ: ConexiÃ³n cerrada o timeout`);
        logger.error(`âŒ [${sendId}]   â””â”€â”€ ACCIÃ“N: Abortando envÃ­o, audio se perderÃ¡`);
        return;
      }

      // DIAGNÃ“STICO COMPLETO DEL FORMATO DE AUDIO
      logger.info(`ğŸ” [${sendId}] PASO 1: ANÃLISIS DEL FORMATO DE AUDIO`);
      
      const expectedFormats = ['MP3', 'WAV', 'PCM', 'mulaw'];
      let detectedFormat = 'DESCONOCIDO';
      let processedAudio;
      
      // Analizar primeros bytes para detectar formato
      if (audioBuffer.length >= 2) {
        const byte1 = audioBuffer[0];
        const byte2 = audioBuffer[1];
        logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Primeros 2 bytes: 0x${byte1.toString(16).padStart(2, '0')} 0x${byte2.toString(16).padStart(2, '0')}`);
        
        if (byte1 === 0xFF && (byte2 & 0xE0) === 0xE0) {
          detectedFormat = 'MP3';
        } else if (audioBuffer.length >= 4 && audioBuffer.toString('ascii', 0, 4) === 'RIFF') {
          detectedFormat = 'WAV';
        } else if (audioBuffer.length >= 8 && audioBuffer.toString('ascii', 8, 12) === 'WAVE') {
          detectedFormat = 'WAV';
        } else {
          detectedFormat = 'PCM_O_MULAW';
        }
      }
      
      logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Formato detectado: ${detectedFormat}`);
      logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Formatos esperados: [${expectedFormats.join(', ')}]`);
      logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Es formato vÃ¡lido: ${expectedFormats.includes(detectedFormat) || detectedFormat === 'PCM_O_MULAW'}`);
      
      // Procesar segÃºn formato detectado
      if (detectedFormat === 'MP3') {
        logger.info(`ğŸµ [${sendId}] PROCESANDO MP3:`);
        logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ PROBLEMA: MP3 requiere conversiÃ³n a mulaw para Twilio`);
        logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ SOLUCIÃ“N ACTUAL: Enviar como estÃ¡ (Twilio puede manejar MP3)`);
        logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ RECOMENDACIÃ“N: Implementar conversiÃ³n MP3â†’PCMâ†’mulaw`);
        logger.info(`ğŸµ [${sendId}]   â””â”€â”€ ACCIÃ“N: Usando MP3 directo`);
        processedAudio = audioBuffer;
      } else if (detectedFormat === 'WAV') {
        logger.info(`ğŸµ [${sendId}] PROCESANDO WAV:`);
        logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Intentando extraer PCM del WAV...`);
        const pcmData = this.extractPCMFromWAV(audioBuffer);
        if (pcmData) {
          logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ PCM extraÃ­do: ${pcmData.length} bytes`);
          logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Convirtiendo PCM a mulaw...`);
          processedAudio = this.convertPCMToMulaw(pcmData);
          logger.info(`ğŸµ [${sendId}]   â””â”€â”€ ConversiÃ³n completada: ${processedAudio.length} bytes mulaw`);
        } else {
          logger.error(`âŒ [${sendId}] FALLO EN EXTRACCIÃ“N PCM:`);
          logger.error(`âŒ [${sendId}]   â”œâ”€â”€ PROBLEMA: No se pudo extraer PCM del WAV`);
          logger.error(`âŒ [${sendId}]   â”œâ”€â”€ CAUSA RAÃZ: WAV corrupto o formato no soportado`);
          logger.error(`âŒ [${sendId}]   â””â”€â”€ ACCIÃ“N: Usando WAV original sin conversiÃ³n`);
          processedAudio = audioBuffer;
        }
      } else {
        logger.info(`ğŸµ [${sendId}] FORMATO DESCONOCIDO/PCM:`);
        logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Asumiendo que ya estÃ¡ en formato correcto para Twilio`);
        logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Si es PCM: deberÃ­a convertirse a mulaw`);
        logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Si es mulaw: listo para envÃ­o`);
        logger.info(`ğŸµ [${sendId}]   â””â”€â”€ ACCIÃ“N: Usando datos sin modificar`);
        processedAudio = audioBuffer;
      }
      
      logger.info(`ğŸµ [${sendId}] RESULTADO DEL PROCESAMIENTO:`);
      logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Audio original: ${audioBuffer.length} bytes`);
      logger.info(`ğŸµ [${sendId}]   â”œâ”€â”€ Audio procesado: ${processedAudio.length} bytes`);
      logger.info(`ğŸµ [${sendId}]   â””â”€â”€ ReducciÃ³n/expansiÃ³n: ${((processedAudio.length - audioBuffer.length) / audioBuffer.length * 100).toFixed(1)}%`);

      // DIAGNÃ“STICO COMPLETO DEL ENVÃO POR CHUNKS
      logger.info(`ğŸ” [${sendId}] PASO 2: PREPARANDO ENVÃO POR CHUNKS`);
      
      const chunkSize = 1024; // 1KB chunks
      const expectedBase64Length = Math.ceil(processedAudio.length * 4 / 3); // Base64 es ~33% mÃ¡s grande
      
      logger.info(`ğŸ“¦ [${sendId}] ANÃLISIS DE CHUNKS:`);
      logger.info(`ğŸ“¦ [${sendId}]   â”œâ”€â”€ TamaÃ±o de chunk: ${chunkSize} bytes`);
      logger.info(`ğŸ“¦ [${sendId}]   â”œâ”€â”€ Audio procesado: ${processedAudio.length} bytes`);
      logger.info(`ğŸ“¦ [${sendId}]   â”œâ”€â”€ Base64 esperado: ~${expectedBase64Length} caracteres`);
      
      const base64Audio = processedAudio.toString('base64');
      const totalChunks = Math.ceil(base64Audio.length / chunkSize);
      
      logger.info(`ğŸ“¦ [${sendId}]   â”œâ”€â”€ Base64 real: ${base64Audio.length} caracteres`);
      logger.info(`ğŸ“¦ [${sendId}]   â”œâ”€â”€ Total chunks: ${totalChunks}`);
      logger.info(`ğŸ“¦ [${sendId}]   â””â”€â”€ Tiempo estimado: ~${totalChunks * 10}ms (10ms por chunk)`);
      
      // Verificar que base64 no estÃ© vacÃ­o
      if (base64Audio.length === 0) {
        logger.error(`âŒ [${sendId}] BASE64 VACÃO:`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ PROBLEMA: ConversiÃ³n a base64 resultÃ³ en string vacÃ­o`);
        logger.error(`âŒ [${sendId}]   â”œâ”€â”€ CAUSA RAÃZ: processedAudio estÃ¡ vacÃ­o o corrupto`);
        logger.error(`âŒ [${sendId}]   â””â”€â”€ ACCIÃ“N: Abortando envÃ­o`);
        return;
      }
      
      logger.info(`ğŸ” [${sendId}] PASO 3: ENVIANDO CHUNKS A TWILIO`);
      const sendStartTime = Date.now();
      let chunksSent = 0;
      let chunksError = 0;
      
      for (let i = 0; i < base64Audio.length; i += chunkSize) {
        const chunkIndex = Math.floor(i / chunkSize) + 1;
        const chunk = base64Audio.slice(i, i + chunkSize);
        
        logger.info(`ğŸ“¤ [${sendId}] Enviando chunk ${chunkIndex}/${totalChunks} (${chunk.length} chars)`);
        
        const mediaMessage = {
          event: 'media',
          streamSid: streamSid,
          media: {
            payload: chunk
          }
        };

        // Verificar WebSocket antes de cada chunk
        if (ws.readyState === 1) {
          try {
            ws.send(JSON.stringify(mediaMessage));
            chunksSent++;
            logger.info(`âœ… [${sendId}] Chunk ${chunkIndex} enviado exitosamente`);
          } catch (sendError) {
            chunksError++;
            logger.error(`âŒ [${sendId}] ERROR ENVIANDO CHUNK ${chunkIndex}:`);
            logger.error(`âŒ [${sendId}]   â”œâ”€â”€ Error: ${sendError.message}`);
            logger.error(`âŒ [${sendId}]   â”œâ”€â”€ WebSocket state: ${ws.readyState}`);
            logger.error(`âŒ [${sendId}]   â””â”€â”€ Continuando con siguiente chunk...`);
          }
        } else {
          chunksError++;
          logger.error(`âŒ [${sendId}] WEBSOCKET CERRADO EN CHUNK ${chunkIndex}:`);
          logger.error(`âŒ [${sendId}]   â”œâ”€â”€ Estado WebSocket: ${ws.readyState}`);
          logger.error(`âŒ [${sendId}]   â”œâ”€â”€ Chunks enviados: ${chunksSent}/${totalChunks}`);
          logger.error(`âŒ [${sendId}]   â””â”€â”€ ACCIÃ“N: Abortando envÃ­o restante`);
          break;
        }
      }
      
      const sendEndTime = Date.now();
      const sendDuration = sendEndTime - sendStartTime;
      
      logger.info(`ğŸ” [${sendId}] RESUMEN DEL ENVÃO:`);
      logger.info(`ğŸ“Š [${sendId}]   â”œâ”€â”€ Chunks enviados: ${chunksSent}/${totalChunks}`);
      logger.info(`ğŸ“Š [${sendId}]   â”œâ”€â”€ Chunks con error: ${chunksError}`);
      logger.info(`ğŸ“Š [${sendId}]   â”œâ”€â”€ Tasa de Ã©xito: ${((chunksSent / totalChunks) * 100).toFixed(1)}%`);
      logger.info(`ğŸ“Š [${sendId}]   â”œâ”€â”€ Tiempo total: ${sendDuration}ms`);
      logger.info(`ğŸ“Š [${sendId}]   â”œâ”€â”€ Tiempo por chunk: ${(sendDuration / chunksSent).toFixed(1)}ms`);
      logger.info(`ğŸ“Š [${sendId}]   â””â”€â”€ Bytes enviados: ${processedAudio.length} bytes`);
      
      if (chunksSent === totalChunks) {
        logger.info(`âœ… [${sendId}] ENVÃO COMPLETADO EXITOSAMENTE`);
      } else {
        logger.error(`âŒ [${sendId}] ENVÃO INCOMPLETO: ${chunksSent}/${totalChunks} chunks`);
      }
      
    } catch (error) {
      logger.error(`âŒ [${sendId}] EXCEPCIÃ“N CRÃTICA EN ENVÃO:`);
      logger.error(`âŒ [${sendId}]   â”œâ”€â”€ Error: ${error.message}`);
      logger.error(`âŒ [${sendId}]   â”œâ”€â”€ Stack: ${error.stack?.substring(0, 200)}...`);
      logger.error(`âŒ [${sendId}]   â”œâ”€â”€ CAUSA RAÃZ: Exception durante envÃ­o a Twilio`);
      logger.error(`âŒ [${sendId}]   â”œâ”€â”€ POSIBLES CAUSAS:`);
      logger.error(`âŒ [${sendId}]   â”‚   â”œâ”€â”€ WebSocket cerrado inesperadamente`);
      logger.error(`âŒ [${sendId}]   â”‚   â”œâ”€â”€ Error en conversiÃ³n de formato de audio`);
      logger.error(`âŒ [${sendId}]   â”‚   â”œâ”€â”€ Memoria insuficiente para base64`);
      logger.error(`âŒ [${sendId}]   â”‚   â””â”€â”€ Error de red con Twilio`);
      logger.error(`âŒ [${sendId}]   â””â”€â”€ ACCIÃ“N: Propagando error para activar fallback`);
      throw error;
    }
  }

  /**
   * Generar un beep simple como audio de fallback
   */
  generateSimpleBeep() {
    try {
      // Generar un beep simple de 500ms en formato mulaw 8kHz
      const sampleRate = 8000;
      const duration = 0.5; // 500ms
      const frequency = 800; // 800Hz
      const samples = Math.floor(sampleRate * duration);
      
      const audioBuffer = Buffer.alloc(samples);
      
      for (let i = 0; i < samples; i++) {
        // Generar onda senoidal
        const sample = Math.sin(2 * Math.PI * frequency * i / sampleRate);
        // Convertir a mulaw (aproximaciÃ³n simple)
        const mulaw = this.linearToMulaw(sample * 0.5); // Volumen reducido
        audioBuffer[i] = mulaw;
      }
      
      logger.info(`ğŸ”” Beep generado: ${audioBuffer.length} bytes`);
      return audioBuffer;
      
    } catch (error) {
      logger.error(`âŒ Error generando beep: ${error.message}`);
      return null;
    }
  }

  /**
   * ConversiÃ³n simple de linear a mulaw
   */
  linearToMulaw(sample) {
    const BIAS = 0x84;
    const CLIP = 32635;
    
    let sign = (sample < 0) ? 0x80 : 0x00;
    if (sign) sample = -sample;
    
    sample = Math.min(sample * 32767, CLIP);
    
    if (sample >= 256) {
      let exponent = Math.floor(Math.log2(sample / 256));
      let mantissa = Math.floor((sample >> (exponent + 3)) & 0x0F);
      sample = (exponent << 4) | mantissa;
    } else {
      sample = sample >> 4;
    }
    
    return (sample ^ 0x55) | sign;
  }

  /**
   * Manejar chunk de audio
   */
  async handleMediaChunk(ws, data) {
    const streamSid = data.streamSid;
    
    logger.info(`ğŸ“¨ Media chunk recibido para StreamSid: "${streamSid}"`);
    logger.info(`ğŸ—‚ï¸ Streams activos disponibles: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
    logger.info(`ğŸ” Â¿Stream existe? ${this.activeStreams.has(streamSid)}`);

    const streamData = this.activeStreams.get(streamSid);
    
    if (!streamData) {
      logger.warn(`âš ï¸ Stream no encontrado para StreamSid: ${streamSid}`);
      logger.warn(`âš ï¸ Streams disponibles: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
      return;
    }

    // Si el stream estÃ¡ inicializÃ¡ndose, solo almacenar el audio sin procesar
    if (streamData.isInitializing) {
      logger.info(`ğŸ”„ Stream ${streamSid} estÃ¡ inicializÃ¡ndose, almacenando audio...`);
      // Solo almacenar el audio, no procesar aÃºn
      if (data.media.track === 'inbound') {
        const audioBuffer = this.audioBuffers.get(streamSid) || [];
        audioBuffer.push(data.media.payload);
        this.audioBuffers.set(streamSid, audioBuffer);
      }
      return;
    }

    // Solo procesar audio entrante (inbound)
    if (data.media.track === 'inbound') {
      logger.info(`ğŸ”Š Procesando chunk de audio inbound: ${data.media.payload.length} bytes`);
      const audioBuffer = this.audioBuffers.get(streamSid) || [];
      audioBuffer.push(data.media.payload);
      this.audioBuffers.set(streamSid, audioBuffer);

      // Actualizar Ãºltima actividad
      streamData.lastActivity = Date.now();

      // Procesar cuando tengamos suficiente audio (aproximadamente 1 segundo)
      if (audioBuffer.length >= 50 && !streamData.isProcessing) {
        await this.processAudioBuffer(streamSid);
      }
    }
  }

  /**
   * Procesar buffer de audio acumulado
   */
  async processAudioBuffer(streamSid) {
    const streamData = this.activeStreams.get(streamSid);
    if (!streamData || streamData.isProcessing) {
      return;
    }

    streamData.isProcessing = true;
    
    try {
      const audioBuffer = this.audioBuffers.get(streamSid) || [];
      if (audioBuffer.length === 0) {
        streamData.isProcessing = false;
        return;
      }

      logger.info(`ğŸ¤ Procesando ${audioBuffer.length} chunks de audio para ${streamSid}`);

      // Limpiar buffer
      this.audioBuffers.set(streamSid, []);

      // Usar el contexto completo del cliente para generar respuesta con OpenAI
      const systemPrompt = streamData.systemPrompt || `Eres un asistente virtual para ${streamData.client?.companyName || 'la empresa'}.`;
      
      // AquÃ­ irÃ­a la transcripciÃ³n del audio (por ahora simulamos)
      const userMessage = "Usuario hablÃ³"; // Placeholder para transcripciÃ³n real
      
      // Generar respuesta usando OpenAI con contexto completo
      const response = await this.generateAIResponse(userMessage, systemPrompt, streamData);
      
      // Generar respuesta de audio con Azure TTS usando la voz del usuario
      // Mapear voz del usuario con el mismo sistema que en handleStreamStart
      const voiceMapping = {
        'neutral': 'es-ES-DarioNeural',
        'lola': 'es-ES-ElviraNeural', 
        'dario': 'es-ES-DarioNeural',
        'elvira': 'es-ES-ElviraNeural',
        'female': 'es-ES-ElviraNeural',
        'male': 'es-ES-DarioNeural'
      };
      
      const userVoice = streamData.client?.callConfig?.voiceId;
      const voiceId = userVoice ? (voiceMapping[userVoice] || userVoice) : 'es-ES-DarioNeural';
      logger.info(`ğŸ”Š Generando audio para texto: ${response}`);
      const ttsResult = await this.ttsService.generateSpeech(response, voiceId);
      
      if (ttsResult && ttsResult.success && ttsResult.audioBuffer) {
        await this.sendAudioToTwilio(streamData.ws, ttsResult.audioBuffer, streamSid);
      }

      streamData.isSendingTTS = true;

      // Verificar que el WebSocket estÃ© abierto
      if (ws.readyState !== 1) { // WebSocket.OPEN = 1
        logger.error(`âŒ WebSocket no estÃ¡ abierto (readyState: ${ws.readyState})`);
        streamData.isSendingTTS = false;
        return;
      }

      // Extraer datos PCM del WAV y convertir a mulaw
      const wavData = this.extractPCMFromWAV(audioBuffer);
      if (!wavData) {
        logger.error(`âŒ No se pudo extraer PCM del audio WAV`);
        streamData.isSendingTTS = false;
        return;
      }
      
      const mulawData = this.convertPCMToMulaw(wavData);
      const chunkSize = 160; // 20ms de audio a 8kHz mulaw
      const totalChunks = Math.ceil(mulawData.length / chunkSize);
      
      logger.info(`ğŸµ Audio WAV convertido a mulaw: ${mulawData.length} bytes`);
      logger.info(`ğŸµ Enviando ${totalChunks} chunks de audio...`);
      
      for (let i = 0; i < mulawData.length; i += chunkSize) {
        const chunk = mulawData.slice(i, i + chunkSize);
        const base64Chunk = chunk.toString('base64');
        
        const mediaMessage = {
          event: 'media',
          streamSid: streamSid,
          media: {
            timestamp: Date.now(),
            payload: base64Chunk
          }
        };

        // Verificar WebSocket antes de cada envÃ­o
        if (ws.readyState !== 1) {
          logger.warn(`âš ï¸ WebSocket cerrado durante envÃ­o en chunk ${Math.floor(i/chunkSize) + 1}`);
          break;
        }

        ws.send(JSON.stringify(mediaMessage));
        
        // Log cada 25 chunks
        if ((Math.floor(i/chunkSize) + 1) % 25 === 0) {
          logger.info(`ğŸµ Enviado chunk ${Math.floor(i/chunkSize) + 1}/${totalChunks}`);
        }

        // PequeÃ±a pausa entre chunks para simular tiempo real
        await new Promise(resolve => setTimeout(resolve, 20));
      }

      streamData.isSendingTTS = false;
      logger.info(`âœ… Audio enviado correctamente a ${streamSid} (${totalChunks} chunks)`);

    } catch (error) {
      logger.error(`âŒ Error enviando audio: ${error.message}`);
      logger.error(`âŒ Stack: ${error.stack}`);
      const streamData = this.activeStreams.get(streamSid);
      if (streamData) {
        streamData.isSendingTTS = false;
      }
    }
  }

  /**
   * Stream detenido
   */
  async handleStreamStop(ws, data) {
    const streamSid = data.streamSid;
    logger.info(`ğŸ›‘ Stream detenido: ${streamSid}`);
    
    this.cleanupStream(streamSid);
  }

  /**
   * Limpiar recursos del stream
   */
  cleanupStream(streamId) {
    // Buscar por streamId o streamSid
    let streamSidToClean = null;
    
    for (const [streamSid, streamData] of this.activeStreams.entries()) {
      if (streamData.ws && streamData.ws.streamId === streamId) {
        streamSidToClean = streamSid;
        break;
      }
    }
    
    if (streamSidToClean) {
      this.activeStreams.delete(streamSidToClean);
      this.audioBuffers.delete(streamSidToClean);
      this.conversationState.delete(streamSidToClean);
      logger.info(`ğŸ§¹ Stream limpiado: ${streamSidToClean}`);
    }
  }

  /**
   * Limpiar streams inactivos
   */
  cleanupInactiveStreams() {
    const now = Date.now();
    const timeout = 5 * 60 * 1000; // 5 minutos

    for (const [streamSid, streamData] of this.activeStreams.entries()) {
      if (now - streamData.lastActivity > timeout) {
        logger.info(`ğŸ§¹ Limpiando stream inactivo: ${streamSid}`);
        this.cleanupStream(streamData.ws.streamId);
      }
    }
  }

  /**
   * Iniciar heartbeat para mantener conexiones activas
   */
  startHeartbeat() {
    // Limpiar streams inactivos cada 2 minutos
    setInterval(() => {
      this.cleanupInactiveStreams();
    }, 2 * 60 * 1000);

    logger.info('ğŸ’“ Heartbeat iniciado para limpieza de streams inactivos');
  }

  /**
   * Extraer datos PCM de un archivo WAV
   */
  extractPCMFromWAV(wavBuffer) {
    try {
      // Verificar header WAV
      if (wavBuffer.length < 44) {
        logger.error('âŒ Buffer WAV demasiado pequeÃ±o');
        return null;
      }

      // Verificar RIFF header
      const riffHeader = wavBuffer.toString('ascii', 0, 4);
      if (riffHeader !== 'RIFF') {
        logger.error('âŒ No es un archivo WAV vÃ¡lido (falta RIFF)');
        return null;
      }

      // Verificar WAVE header
      const waveHeader = wavBuffer.toString('ascii', 8, 12);
      if (waveHeader !== 'WAVE') {
        logger.error('âŒ No es un archivo WAV vÃ¡lido (falta WAVE)');
        return null;
      }

      // Buscar chunk de datos
      let dataOffset = 12;
      while (dataOffset < wavBuffer.length - 8) {
        const chunkId = wavBuffer.toString('ascii', dataOffset, dataOffset + 4);
        const chunkSize = wavBuffer.readUInt32LE(dataOffset + 4);
        
        if (chunkId === 'data') {
          // Encontrado el chunk de datos
          const pcmData = wavBuffer.slice(dataOffset + 8, dataOffset + 8 + chunkSize);
          logger.info(`ğŸµ PCM extraÃ­do: ${pcmData.length} bytes`);
          return pcmData;
        }
        
        dataOffset += 8 + chunkSize;
      }

      logger.error('âŒ No se encontrÃ³ chunk de datos en WAV');
      return null;
    } catch (error) {
      logger.error(`âŒ Error extrayendo PCM: ${error.message}`);
      return null;
    }
  }

  /**
   * Convertir PCM 16-bit a mulaw 8-bit
   */
  convertPCMToMulaw(pcmBuffer) {
    try {
      const mulawBuffer = Buffer.alloc(pcmBuffer.length / 2);
      
      for (let i = 0; i < pcmBuffer.length; i += 2) {
        // Leer sample PCM 16-bit little endian
        const pcmSample = pcmBuffer.readInt16LE(i);
        
        // Convertir a mulaw
        const mulawSample = this.linearToMulaw(pcmSample);
        mulawBuffer[i / 2] = mulawSample;
      }
      
      logger.info(`ğŸµ PCM convertido a mulaw: ${mulawBuffer.length} bytes`);
      return mulawBuffer;
    } catch (error) {
      logger.error(`âŒ Error convirtiendo a mulaw: ${error.message}`);
      return Buffer.alloc(0);
    }
  }

  /**
   * Convertir sample linear PCM a mulaw
   */
  linearToMulaw(pcmSample) {
    // Tabla de conversiÃ³n mulaw
    const MULAW_MAX = 0x1FFF;
    const MULAW_BIAS = 33;
    
    let sign = 0;
    let position = 0;
    let lsb = 0;
    
    if (pcmSample < 0) {
      pcmSample = -pcmSample;
      sign = 0x80;
    }
    
    pcmSample += MULAW_BIAS;
    if (pcmSample > MULAW_MAX) pcmSample = MULAW_MAX;
    
    // Encontrar posiciÃ³n del bit mÃ¡s significativo
    for (position = 12; position >= 5; position--) {
      if (pcmSample & (1 << position)) break;
    }
    
    lsb = (pcmSample >> (position - 4)) & 0x0F;
    return (~(sign | ((position - 5) << 4) | lsb)) & 0xFF;
  }
}

module.exports = TwilioStreamHandler;
