const logger = require('../utils/logger');
const azureTTSService = require('../services/azureTTSRestService');
const openaiService = require('../services/openaiService');
const ContextBuilder = require('../utils/contextBuilder');
const { OpenAI } = require('openai');

class TwilioStreamHandler {
  constructor() {
    this.activeStreams = new Map();
    this.audioBuffers = new Map();
    this.conversationState = new Map();
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
    this.ttsService = azureTTSService;
  }

  /**
   * Manejar nueva conexi√≥n WebSocket
   */
  handleConnection(ws, req) {
    const streamId = `stream_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    ws.streamId = streamId;

    logger.info(`üîå NUEVA CONEXI√ìN TWILIO STREAM: ${streamId}`);
    logger.info(`üîç Request URL: ${req.url}`);
    logger.info(`üîç Request Headers: ${JSON.stringify(req.headers)}`);

    // Configurar heartbeat
    ws.isAlive = true;
    ws.on('pong', () => {
      ws.isAlive = true;
    });

    // Manejar mensajes
    ws.on('message', async (message) => {
      logger.info(`üì® MENSAJE WEBSOCKET RECIBIDO en ${streamId}: ${message.toString().substring(0, 200)}...`);
      
      try {
        const data = JSON.parse(message);
        logger.info(`üì® DATOS PARSEADOS: ${JSON.stringify(data, null, 2)}`);
        await this.handleTwilioMessage(ws, data);
      } catch (error) {
        logger.error(`‚ùå Error parseando mensaje: ${error.message}`);
      }
    });

    // Manejar cierre de conexi√≥n
    ws.on('close', (code, reason) => {
      logger.info(`üîå Conexi√≥n cerrada: ${streamId} - C√≥digo: ${code}, Raz√≥n: ${reason}`);
      this.cleanupStream(streamId);
    });

    // Manejar errores
    ws.on('error', (error) => {
      logger.error(`‚ùå Error en WebSocket ${streamId}: ${error.message}`);
      this.cleanupStream(streamId);
    });
  }

  /**
   * Manejo centralizado de mensajes WebSocket de Twilio
   */
  async handleTwilioMessage(ws, data) {
    const event = data.event;
    const streamSid = data.streamSid;
    
    logger.info(`üì® Evento recibido: ${event} para stream: ${streamSid}`);
    
    try {
      // Procesar eventos de forma secuencial y expl√≠cita
      switch (event) {
        case "connected":
          logger.info('üîå Media WS: Connected event received');
          await this.handleStreamConnected(ws, data);
          break;
          
        case "start":
          logger.info('üé§ Media WS: Start event received');
          // Asegurar que el start se procese completamente antes de continuar
          await this.handleStreamStart(ws, data);
          logger.info(`‚úÖ Start event procesado completamente para stream: ${streamSid}`);
          break;
          
        case "media":
          // Verificar que el stream est√© registrado antes de procesar media
          if (!this.activeStreams.has(streamSid)) {
            logger.warn(`‚ö†Ô∏è Media event recibido para stream no registrado: ${streamSid}`);
            logger.info(`üìä Streams activos: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
            return;
          }
          await this.handleMediaChunk(ws, data);
          break;
          
        case "stop":
          logger.info('üõë Media WS: Stop event received');
          await this.handleStreamStop(ws, data);
          break;
          
        default:
          logger.warn(`‚ö†Ô∏è Evento desconocido: ${event}`);
      }
    } catch (error) {
      logger.error(`‚ùå Error procesando evento ${event} para stream ${streamSid}: ${error.message}`);
      logger.error(`‚ùå Stack: ${error.stack}`);
      
      // Log adicional del estado actual
      logger.error(`üìä Estado actual - Streams activos: ${this.activeStreams.size}`);
      logger.error(`üóÇÔ∏è Stream IDs: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
    }
  }

  /**
   * Stream conectado - inicializar
   */
  async handleStreamConnected(ws, data) {
    logger.info(`‚úÖ Stream conectado, esperando evento start para par√°metros completos`);
  }

  /**
   * Stream iniciado - configurar cliente
   */
  async handleStreamStart(ws, data) {
    const { streamSid, callSid, customParameters } = data.start;
    const clientId = customParameters?.clientId;

    logger.info(`üé§ ===== INICIO handleStreamStart =====`);
    logger.info(`üé§ Processing start event:`);
    logger.info(`üé§ Stream starting: ${streamSid} for call ${callSid}, clientId: ${clientId}`);
    logger.info(`üé§ Data completa: ${JSON.stringify(data, null, 2)}`);

    // Verificar si el stream ya existe
    if (this.activeStreams.has(streamSid)) {
      logger.warn(`‚ö†Ô∏è Stream ${streamSid} ya existe en activeStreams`);
      return;
    }

    // REGISTRO INMEDIATO DEL STREAM - Antes de la consulta DB lenta
    logger.info('üöÄ REGISTRO INMEDIATO: Registrando stream antes de consulta DB...');
    const placeholderStreamData = {
      streamSid,
      ws,
      client: null, // Se llenar√° despu√©s
      callSid,
      audioBuffer: [],
      conversationHistory: [],
      lastActivity: Date.now(),
      isProcessing: false,
      isSendingTTS: false,
      isInitializing: true // Flag para indicar que est√° inicializando
    };
    
    this.activeStreams.set(streamSid, placeholderStreamData);
    this.audioBuffers.set(streamSid, []);
    this.conversationState.set(streamSid, []);
    
    logger.info(`üöÄ Stream registrado INMEDIATAMENTE: ${streamSid}`);
    logger.info(`üìä Active streams: ${this.activeStreams.size}`);

    try {
      logger.info('üîç PASO 1: Obteniendo configuraci√≥n del cliente desde par√°metros...');
      
      // OBTENER CONFIGURACI√ìN COMPLETA DESDE PAR√ÅMETROS - C√ìDIGO EXACTO DEL TEST
      const clientConfig = {
        id: clientId ? parseInt(clientId) : 1,
        companyName: customParameters?.companyName || 'Sistema de Atenci√≥n',
        email: customParameters?.email || '',
        callConfig: {
          greeting: customParameters?.greeting || 'Hola, gracias por llamar. Soy el asistente virtual. ¬øEn qu√© puedo ayudarte?',
          voiceId: customParameters?.voiceId || 'lola',
          enabled: customParameters?.enabled !== 'false'
        },
        // Campos JSON exactos como en el test
        companyInfo: customParameters?.companyInfo || null,
        botConfig: customParameters?.botConfig || null,
        businessHours: customParameters?.businessHours || null,
        notificationConfig: customParameters?.notificationConfig || null,
        faqs: customParameters?.faqs || null,
        contextFiles: customParameters?.contextFiles || null,
        // Relaci√≥n con n√∫meros Twilio
        twilioNumbers: [{
          phoneNumber: customParameters?.phoneNumber || '',
          status: 'active'
        }]
      };

      logger.info(`üîç DEBUG STREAM: Par√°metros recibidos del WebSocket:`);
      logger.info(`üîç DEBUG STREAM: - clientId: ${customParameters?.clientId}`);
      logger.info(`üîç DEBUG STREAM: - companyName: ${customParameters?.companyName}`);
      logger.info(`üîç DEBUG STREAM: - greeting: "${customParameters?.greeting}"`);
      logger.info(`üîç DEBUG STREAM: - voiceId: ${customParameters?.voiceId}`);
      logger.info(`üîç DEBUG STREAM: - companyInfo presente: ${!!customParameters?.companyInfo}`);
      logger.info(`üîç DEBUG STREAM: - botConfig presente: ${!!customParameters?.botConfig}`);
      logger.info(`üîç DEBUG STREAM: - businessHours presente: ${!!customParameters?.businessHours}`);
      logger.info(`üîç DEBUG STREAM: - faqs presente: ${!!customParameters?.faqs}`);
      logger.info(`üîç DEBUG STREAM: - contextFiles presente: ${!!customParameters?.contextFiles}`);
      
      logger.info(`üîç PASO 2: Cliente configurado: ${clientConfig.companyName}`);
      logger.info(`üîç PASO 2a: Saludo: "${clientConfig.callConfig.greeting}"`);
      logger.info(`üîç PASO 2b: Voz: "${clientConfig.callConfig.voiceId}"`);
      logger.info(`üîç PASO 2c: FAQs cargadas: ${clientConfig.faqs.length}`);
      logger.info(`üîç PASO 2d: Archivos contexto: ${clientConfig.contextFiles.length}`);

      // GENERAR CONTEXTO COMPLETO PARA OPENAI
      const systemPrompt = ContextBuilder.buildSystemPrompt(clientConfig);
      logger.info(`üìã PASO 2e: Contexto generado: ${systemPrompt.length} caracteres`);

      // ACTUALIZAR EL STREAM CON CONFIGURACI√ìN REAL Y CONTEXTO
      const streamData = this.activeStreams.get(streamSid);
      streamData.client = clientConfig;
      streamData.systemPrompt = systemPrompt; // Contexto completo disponible
      streamData.isInitializing = false;
      
      logger.info(`üîÑ PASO 3: Stream actualizado con configuraci√≥n real y contexto completo`);

      logger.info('üîç PASO 4: Enviando saludo inicial con configuraci√≥n real...');
      
      // Enviar saludo con configuraci√≥n real
      const greetingPromise = this.sendInitialGreeting(ws, { streamSid, callSid });
      
      const greetingTimeout = new Promise((_, reject) => {
        setTimeout(() => reject(new Error('sendInitialGreeting timeout after 10 seconds')), 10000);
      });

      try {
        await Promise.race([greetingPromise, greetingTimeout]);
        logger.info('üîç PASO 7: ‚úÖ Saludo inicial enviado correctamente');
      } catch (error) {
        logger.error(`‚ùå Error en saludo inicial: ${error.message}`);
        // Continuar sin saludo si hay error
      }
      
      logger.info('üîç PASO 8: ‚úÖ handleStreamStart COMPLETADO EXITOSAMENTE');

      // Verificaci√≥n final
      logger.info(`üîç VERIFICACI√ìN FINAL: Stream ${streamSid} existe: ${this.activeStreams.has(streamSid)}`);

    } catch (error) {
      logger.error(`‚ùå Error in handleStreamStart: ${error.message}`);
      logger.error(`‚ùå Stack: ${error.stack}`);
      
      // Limpiar en caso de error
      this.activeStreams.delete(streamSid);
      this.audioBuffers.delete(streamSid);
      this.conversationState.delete(streamSid);
      
      throw error; // Re-lanzar el error para que se capture en el nivel superior
    }
  }

  /**
   * Enviar saludo inicial con Azure TTS - DEBUG ULTRA-DETALLADO
   */
  async sendInitialGreeting(ws, data) {
    const debugId = `DEBUG_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const startTime = Date.now();
    
    try {
      logger.info(`üîç [${debugId}] ===== INICIO SALUDO INICIAL ULTRA-DEBUG =====`);
      logger.info(`üîç [${debugId}] Timestamp: ${new Date().toISOString()}`);
      logger.info(`üîç [${debugId}] WebSocket state: ${ws.readyState} (1=OPEN, 0=CONNECTING, 2=CLOSING, 3=CLOSED)`);
      
      const { streamSid, callSid } = data;
      logger.info(`üîç [${debugId}] StreamSid: ${streamSid}`);
      logger.info(`üîç [${debugId}] CallSid: ${callSid}`);
      
      // PASO 1: Verificar stream data
      logger.info(`üîç [${debugId}] PASO 1: Verificando stream data...`);
      const streamData = this.activeStreams.get(streamSid);
      if (!streamData) {
        logger.error(`‚ùå [${debugId}] FALLO CR√çTICO: No se encontr√≥ stream data para ${streamSid}`);
        logger.error(`‚ùå [${debugId}] Active streams disponibles: ${Array.from(this.activeStreams.keys())}`);
        return;
      }
      logger.info(`‚úÖ [${debugId}] Stream data encontrado`);

      // PASO 2: Verificar cliente
      logger.info(`üîç [${debugId}] PASO 2: Verificando cliente...`);
      const { client } = streamData;
      if (!client) {
        logger.error(`‚ùå [${debugId}] FALLO CR√çTICO: No hay cliente en stream data`);
        return;
      }
      logger.info(`‚úÖ [${debugId}] Cliente encontrado: ID=${client.id}, Email=${client.email}`);
      
      // PASO 3: Analizar callConfig en detalle
      logger.info(`üîç [${debugId}] PASO 3: Analizando callConfig...`);
      logger.info(`üîç [${debugId}] client.callConfig existe: ${!!client.callConfig}`);
      
      if (client.callConfig) {
        logger.info(`üîç [${debugId}] callConfig tipo: ${typeof client.callConfig}`);
        logger.info(`üîç [${debugId}] callConfig keys: ${Object.keys(client.callConfig)}`);
        logger.info(`üîç [${debugId}] callConfig completo: ${JSON.stringify(client.callConfig, null, 2)}`);
      } else {
        logger.warn(`‚ö†Ô∏è [${debugId}] callConfig es null/undefined`);
      }
      
      // Obtener saludo
      let greeting = 'Hola, gracias por llamar. ¬øEn qu√© puedo ayudarte?';
      if (client.callConfig && client.callConfig.greeting) {
        greeting = client.callConfig.greeting;
        logger.info(`‚úÖ [${debugId}] Saludo personalizado obtenido: "${greeting}"`);
      } else {
        logger.warn(`‚ö†Ô∏è [${debugId}] Usando saludo por defecto: "${greeting}"`);
      }

      // Obtener voz
      let voiceId = 'lola';
      if (client.callConfig && client.callConfig.voiceId) {
        voiceId = client.callConfig.voiceId;
        logger.info(`‚úÖ [${debugId}] Voz personalizada obtenida: ${voiceId}`);
      } else {
        logger.warn(`‚ö†Ô∏è [${debugId}] Usando voz por defecto: ${voiceId}`);
      }

      // PASO 4: Verificar variables de entorno Azure
      logger.info(`üîç [${debugId}] PASO 4: Verificando configuraci√≥n Azure...`);
      const azureKey = process.env.AZURE_SPEECH_KEY;
      const azureRegion = process.env.AZURE_SPEECH_REGION;
      logger.info(`üîç [${debugId}] AZURE_SPEECH_KEY existe: ${!!azureKey} (length: ${azureKey?.length || 0})`);
      logger.info(`üîç [${debugId}] AZURE_SPEECH_REGION: ${azureRegion}`);
      
      if (!azureKey || !azureRegion) {
        logger.error(`‚ùå [${debugId}] FALLO CR√çTICO: Variables Azure no configuradas`);
        throw new Error('Variables de entorno Azure TTS no configuradas');
      }

      // PASO 5: Generar audio con timing detallado
      logger.info(`üîç [${debugId}] PASO 5: Iniciando generaci√≥n de audio...`);
      logger.info(`üîç [${debugId}] Texto a sintetizar: "${greeting}" (${greeting.length} caracteres)`);
      logger.info(`üîç [${debugId}] Voz Azure: ${voiceId}`);
      
      const ttsStartTime = Date.now();
      
      try {
        logger.info(`üîç [${debugId}] Llamando a ttsService.generateSpeech...`);
        const audioResult = await this.ttsService.generateSpeech(greeting, voiceId);
        const ttsEndTime = Date.now();
        const ttsDuration = ttsEndTime - ttsStartTime;
        
        logger.info(`üîç [${debugId}] TTS completado en ${ttsDuration}ms`);
        logger.info(`üîç [${debugId}] Resultado TTS:`);
        logger.info(`üîç [${debugId}]   - success: ${audioResult?.success}`);
        logger.info(`üîç [${debugId}]   - error: ${audioResult?.error || 'ninguno'}`);
        logger.info(`üîç [${debugId}]   - audioBuffer existe: ${!!audioResult?.audioBuffer}`);
        
        if (audioResult?.audioBuffer) {
          logger.info(`üîç [${debugId}]   - audioBuffer tipo: ${typeof audioResult.audioBuffer}`);
          logger.info(`üîç [${debugId}]   - audioBuffer constructor: ${audioResult.audioBuffer.constructor.name}`);
          logger.info(`üîç [${debugId}]   - audioBuffer length: ${audioResult.audioBuffer.byteLength || audioResult.audioBuffer.length}`);
        }
        
        if (!audioResult || !audioResult.success) {
          const errorMsg = `Azure TTS fall√≥: ${audioResult?.error || 'Error desconocido'}`;
          logger.error(`‚ùå [${debugId}] ${errorMsg}`);
          throw new Error(errorMsg);
        }

        // PASO 6: Procesar buffer de audio
        logger.info(`üîç [${debugId}] PASO 6: Procesando buffer de audio...`);
        
        if (!audioResult.audioBuffer) {
          logger.error(`‚ùå [${debugId}] FALLO: audioBuffer es null/undefined`);
          throw new Error('Audio buffer vac√≠o');
        }
        
        const audioBuffer = Buffer.from(audioResult.audioBuffer);
        logger.info(`‚úÖ [${debugId}] Buffer creado exitosamente:`);
        logger.info(`üîç [${debugId}]   - Tama√±o original: ${audioResult.audioBuffer.byteLength} bytes`);
        logger.info(`üîç [${debugId}]   - Buffer Node.js: ${audioBuffer.length} bytes`);
        logger.info(`üîç [${debugId}]   - Primeros 10 bytes: [${Array.from(audioBuffer.slice(0, 10)).join(', ')}]`);
        logger.info(`üîç [${debugId}]   - √öltimos 10 bytes: [${Array.from(audioBuffer.slice(-10)).join(', ')}]`);
        
        // Verificar formato de audio
        const isValidAudio = audioBuffer.length > 44; // M√≠nimo para WAV header
        logger.info(`üîç [${debugId}]   - Audio v√°lido (>44 bytes): ${isValidAudio}`);
        
        if (audioBuffer.length > 4) {
          const header = audioBuffer.slice(0, 4).toString('ascii');
          logger.info(`üîç [${debugId}]   - Header detectado: "${header}"`);
        }

        // PASO 7: Verificar WebSocket antes de enviar
        logger.info(`üîç [${debugId}] PASO 7: Verificando WebSocket...`);
        logger.info(`üîç [${debugId}] WebSocket readyState: ${ws.readyState}`);
        logger.info(`üîç [${debugId}] WebSocket bufferedAmount: ${ws.bufferedAmount}`);
        
        if (ws.readyState !== 1) {
          logger.error(`‚ùå [${debugId}] FALLO: WebSocket no est√° abierto (state: ${ws.readyState})`);
          throw new Error(`WebSocket no disponible (state: ${ws.readyState})`);
        }

        // PASO 8: Enviar audio a Twilio con timing
        logger.info(`üîç [${debugId}] PASO 8: Enviando audio a Twilio...`);
        const sendStartTime = Date.now();
        
        await this.sendAudioToTwilio(ws, audioBuffer, streamSid);
        
        const sendEndTime = Date.now();
        const sendDuration = sendEndTime - sendStartTime;
        const totalDuration = sendEndTime - startTime;
        
        logger.info(`‚úÖ [${debugId}] √âXITO COMPLETO:`);
        logger.info(`üîç [${debugId}]   - TTS generaci√≥n: ${ttsDuration}ms`);
        logger.info(`üîç [${debugId}]   - Env√≠o a Twilio: ${sendDuration}ms`);
        logger.info(`üîç [${debugId}]   - Tiempo total: ${totalDuration}ms`);
        logger.info(`üîç [${debugId}]   - Audio enviado: ${audioBuffer.length} bytes`);
        
      } catch (ttsError) {
        const ttsEndTime = Date.now();
        const ttsDuration = ttsEndTime - ttsStartTime;
        
        logger.error(`‚ùå [${debugId}] ERROR EN TTS despu√©s de ${ttsDuration}ms:`);
        logger.error(`‚ùå [${debugId}] Error message: ${ttsError.message}`);
        logger.error(`‚ùå [${debugId}] Error stack: ${ttsError.stack}`);
        logger.error(`‚ùå [${debugId}] Error name: ${ttsError.name}`);
        
        if (ttsError.code) {
          logger.error(`‚ùå [${debugId}] Error code: ${ttsError.code}`);
        }
        
        logger.info(`üîÑ [${debugId}] Activando fallback...`);
        await this.sendTextFallback(ws, greeting, streamSid);
        throw ttsError;
      }

    } catch (error) {
      const totalDuration = Date.now() - startTime;
      logger.error(`‚ùå [${debugId}] ERROR GENERAL despu√©s de ${totalDuration}ms:`);
      logger.error(`‚ùå [${debugId}] Error: ${error.message}`);
      logger.error(`‚ùå [${debugId}] Stack: ${error.stack}`);
      logger.error(`‚ùå [${debugId}] ===== FIN SALUDO INICIAL (CON ERROR) =====`);
    }
  }

  /**
   * Fallback para enviar audio simple cuando Azure TTS falla - DEBUG DETALLADO
   */
  async sendTextFallback(ws, text, streamSid) {
    const fallbackId = `FALLBACK_${Date.now()}`;
    
    try {
      logger.info(`üîÑ [${fallbackId}] ===== INICIANDO FALLBACK =====`);
      logger.info(`üîÑ [${fallbackId}] Texto original: "${text}"`);
      logger.info(`üîÑ [${fallbackId}] StreamSid: ${streamSid}`);
      logger.info(`üîÑ [${fallbackId}] WebSocket state: ${ws.readyState}`);
      
      // Intentar generar un beep simple como audio de fallback
      logger.info(`üîÑ [${fallbackId}] Generando beep de fallback...`);
      const fallbackAudio = this.generateSimpleBeep();
      
      if (fallbackAudio) {
        logger.info(`üîÑ [${fallbackId}] Beep generado: ${fallbackAudio.length} bytes`);
        
        if (ws.readyState === 1) {
          logger.info(`üîÑ [${fallbackId}] Enviando beep a Twilio...`);
          await this.sendAudioToTwilio(ws, fallbackAudio, streamSid);
          logger.info(`‚úÖ [${fallbackId}] Beep enviado exitosamente`);
        } else {
          logger.error(`‚ùå [${fallbackId}] WebSocket no disponible para beep (state: ${ws.readyState})`);
        }
      } else {
        logger.error(`‚ùå [${fallbackId}] No se pudo generar beep de fallback`);
      }
      
      // Tambi√©n enviar un mark para indicar que hubo un problema
      const markMessage = {
        event: 'mark',
        streamSid: streamSid,
        mark: {
          name: `tts_fallback_${Date.now()}`
        }
      };
      
      if (ws.readyState === 1) {
        ws.send(JSON.stringify(markMessage));
      }
      
      logger.info(`‚úÖ Fallback enviado para ${streamSid}`);
      
    } catch (error) {
      logger.error(`‚ùå Error enviando fallback: ${error.message}`);
    }
  }

  /**
   * Generar un beep simple como audio de fallback
   */
  generateSimpleBeep() {
    try {
      // Generar un beep simple de 500ms en formato mulaw 8kHz
      const sampleRate = 8000;
      const duration = 0.5; // 500ms
      const frequency = 800; // 800Hz
      const samples = Math.floor(sampleRate * duration);
      
      const audioBuffer = Buffer.alloc(samples);
      
      for (let i = 0; i < samples; i++) {
        // Generar onda senoidal
        const sample = Math.sin(2 * Math.PI * frequency * i / sampleRate);
        // Convertir a mulaw (aproximaci√≥n simple)
        const mulaw = this.linearToMulaw(sample * 0.5); // Volumen reducido
        audioBuffer[i] = mulaw;
      }
      
      logger.info(`üîî Beep generado: ${audioBuffer.length} bytes`);
      return audioBuffer;
      
    } catch (error) {
      logger.error(`‚ùå Error generando beep: ${error.message}`);
      return null;
    }
  }

  /**
   * Conversi√≥n simple de linear a mulaw
   */
  linearToMulaw(sample) {
    const BIAS = 0x84;
    const CLIP = 32635;
    
    let sign = (sample < 0) ? 0x80 : 0x00;
    if (sign) sample = -sample;
    
    sample = Math.min(sample * 32767, CLIP);
    
    if (sample >= 256) {
      let exponent = Math.floor(Math.log2(sample / 256));
      let mantissa = Math.floor((sample >> (exponent + 3)) & 0x0F);
      sample = (exponent << 4) | mantissa;
    } else {
      sample = sample >> 4;
    }
    
    return (sample ^ 0x55) | sign;
  }

  /**
   * Manejar chunk de audio
   */
  async handleMediaChunk(ws, data) {
    const streamSid = data.streamSid;
    
    logger.info(`üì® Media chunk recibido para StreamSid: "${streamSid}"`);
    logger.info(`üóÇÔ∏è Streams activos disponibles: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
    logger.info(`üîç ¬øStream existe? ${this.activeStreams.has(streamSid)}`);

    const streamData = this.activeStreams.get(streamSid);
    
    if (!streamData) {
      logger.warn(`‚ö†Ô∏è Stream no encontrado para StreamSid: ${streamSid}`);
      logger.warn(`‚ö†Ô∏è Streams disponibles: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
      return;
    }

    // Si el stream est√° inicializ√°ndose, solo almacenar el audio sin procesar
    if (streamData.isInitializing) {
      logger.info(`üîÑ Stream ${streamSid} est√° inicializ√°ndose, almacenando audio...`);
      // Solo almacenar el audio, no procesar a√∫n
      if (data.media.track === 'inbound') {
        const audioBuffer = this.audioBuffers.get(streamSid) || [];
        audioBuffer.push(data.media.payload);
        this.audioBuffers.set(streamSid, audioBuffer);
      }
      return;
    }

    // Solo procesar audio entrante (inbound)
    if (data.media.track === 'inbound') {
      logger.info(`üîä Procesando chunk de audio inbound: ${data.media.payload.length} bytes`);
      const audioBuffer = this.audioBuffers.get(streamSid) || [];
      audioBuffer.push(data.media.payload);
      this.audioBuffers.set(streamSid, audioBuffer);

      // Actualizar √∫ltima actividad
      streamData.lastActivity = Date.now();

      // Procesar cuando tengamos suficiente audio (aproximadamente 1 segundo)
      if (audioBuffer.length >= 50 && !streamData.isProcessing) {
        await this.processAudioBuffer(streamSid);
      }
    }
  }

  /**
   * Procesar buffer de audio acumulado
   */
  async processAudioBuffer(streamSid) {
    const streamData = this.activeStreams.get(streamSid);
    if (!streamData || streamData.isProcessing) {
      return;
    }

    streamData.isProcessing = true;
    
    try {
      const audioBuffer = this.audioBuffers.get(streamSid) || [];
      if (audioBuffer.length === 0) {
        streamData.isProcessing = false;
        return;
      }

      logger.info(`üé§ Procesando ${audioBuffer.length} chunks de audio para ${streamSid}`);

      // Limpiar buffer
      this.audioBuffers.set(streamSid, []);

      // Usar el contexto completo del cliente para generar respuesta con OpenAI
      const systemPrompt = streamData.systemPrompt || `Eres un asistente virtual para ${streamData.client?.companyName || 'la empresa'}.`;
      
      // Aqu√≠ ir√≠a la transcripci√≥n del audio (por ahora simulamos)
      const userMessage = "Usuario habl√≥"; // Placeholder para transcripci√≥n real
      
      // Generar respuesta usando OpenAI con contexto completo
      const response = await this.generateAIResponse(userMessage, systemPrompt, streamData);
      
      // Generar respuesta de audio con Azure TTS usando la voz del usuario
      const voiceId = streamData.client?.callConfig?.voiceId || 'lola';
      logger.info(`üîä Generando audio para texto: ${response}`);
      const ttsResult = await this.ttsService.generateSpeech(response, voiceId);
      
      if (ttsResult && ttsResult.success && ttsResult.audioBuffer) {
        await this.sendAudioToTwilio(streamData.ws, ttsResult.audioBuffer, streamSid);
      }

      streamData.isSendingTTS = true;

      // Verificar que el WebSocket est√© abierto
      if (ws.readyState !== 1) { // WebSocket.OPEN = 1
        logger.error(`‚ùå WebSocket no est√° abierto (readyState: ${ws.readyState})`);
        streamData.isSendingTTS = false;
        return;
      }

      // Extraer datos PCM del WAV y convertir a mulaw
      const wavData = this.extractPCMFromWAV(audioBuffer);
      if (!wavData) {
        logger.error(`‚ùå No se pudo extraer PCM del audio WAV`);
        streamData.isSendingTTS = false;
        return;
      }
      
      const mulawData = this.convertPCMToMulaw(wavData);
      const chunkSize = 160; // 20ms de audio a 8kHz mulaw
      const totalChunks = Math.ceil(mulawData.length / chunkSize);
      
      logger.info(`üéµ Audio WAV convertido a mulaw: ${mulawData.length} bytes`);
      logger.info(`üéµ Enviando ${totalChunks} chunks de audio...`);
      
      for (let i = 0; i < mulawData.length; i += chunkSize) {
        const chunk = mulawData.slice(i, i + chunkSize);
        const base64Chunk = chunk.toString('base64');
        
        const mediaMessage = {
          event: 'media',
          streamSid: streamSid,
          media: {
            timestamp: Date.now(),
            payload: base64Chunk
          }
        };

        // Verificar WebSocket antes de cada env√≠o
        if (ws.readyState !== 1) {
          logger.warn(`‚ö†Ô∏è WebSocket cerrado durante env√≠o en chunk ${Math.floor(i/chunkSize) + 1}`);
          break;
        }

        ws.send(JSON.stringify(mediaMessage));
        
        // Log cada 25 chunks
        if ((Math.floor(i/chunkSize) + 1) % 25 === 0) {
          logger.info(`üéµ Enviado chunk ${Math.floor(i/chunkSize) + 1}/${totalChunks}`);
        }

        // Peque√±a pausa entre chunks para simular tiempo real
        await new Promise(resolve => setTimeout(resolve, 20));
      }

      streamData.isSendingTTS = false;
      logger.info(`‚úÖ Audio enviado correctamente a ${streamSid} (${totalChunks} chunks)`);

    } catch (error) {
      logger.error(`‚ùå Error enviando audio: ${error.message}`);
      logger.error(`‚ùå Stack: ${error.stack}`);
      const streamData = this.activeStreams.get(streamSid);
      if (streamData) {
        streamData.isSendingTTS = false;
      }
    }
  }

  /**
   * Stream detenido
   */
  async handleStreamStop(ws, data) {
    const streamSid = data.streamSid;
    logger.info(`üõë Stream detenido: ${streamSid}`);
    
    this.cleanupStream(streamSid);
  }

  /**
   * Limpiar recursos del stream
   */
  cleanupStream(streamId) {
    // Buscar por streamId o streamSid
    let streamSidToClean = null;
    
    for (const [streamSid, streamData] of this.activeStreams.entries()) {
      if (streamData.ws && streamData.ws.streamId === streamId) {
        streamSidToClean = streamSid;
        break;
      }
    }
    
    if (streamSidToClean) {
      this.activeStreams.delete(streamSidToClean);
      this.audioBuffers.delete(streamSidToClean);
      this.conversationState.delete(streamSidToClean);
      logger.info(`üßπ Stream limpiado: ${streamSidToClean}`);
    }
  }

  /**
   * Limpiar streams inactivos
   */
  cleanupInactiveStreams() {
    const now = Date.now();
    const timeout = 5 * 60 * 1000; // 5 minutos

    for (const [streamSid, streamData] of this.activeStreams.entries()) {
      if (now - streamData.lastActivity > timeout) {
        logger.info(`üßπ Limpiando stream inactivo: ${streamSid}`);
        this.cleanupStream(streamData.ws.streamId);
      }
    }
  }

  /**
   * Iniciar heartbeat para mantener conexiones activas
   */
  startHeartbeat() {
    // Limpiar streams inactivos cada 2 minutos
    setInterval(() => {
      this.cleanupInactiveStreams();
    }, 2 * 60 * 1000);

    logger.info('üíì Heartbeat iniciado para limpieza de streams inactivos');
  }

  /**
   * Extraer datos PCM de un archivo WAV
   */
  extractPCMFromWAV(wavBuffer) {
    try {
      // Verificar header WAV
      if (wavBuffer.length < 44) {
        logger.error('‚ùå Buffer WAV demasiado peque√±o');
        return null;
      }

      // Verificar RIFF header
      const riffHeader = wavBuffer.toString('ascii', 0, 4);
      if (riffHeader !== 'RIFF') {
        logger.error('‚ùå No es un archivo WAV v√°lido (falta RIFF)');
        return null;
      }

      // Verificar WAVE header
      const waveHeader = wavBuffer.toString('ascii', 8, 12);
      if (waveHeader !== 'WAVE') {
        logger.error('‚ùå No es un archivo WAV v√°lido (falta WAVE)');
        return null;
      }

      // Buscar chunk de datos
      let dataOffset = 12;
      while (dataOffset < wavBuffer.length - 8) {
        const chunkId = wavBuffer.toString('ascii', dataOffset, dataOffset + 4);
        const chunkSize = wavBuffer.readUInt32LE(dataOffset + 4);
        
        if (chunkId === 'data') {
          // Encontrado el chunk de datos
          const pcmData = wavBuffer.slice(dataOffset + 8, dataOffset + 8 + chunkSize);
          logger.info(`üéµ PCM extra√≠do: ${pcmData.length} bytes`);
          return pcmData;
        }
        
        dataOffset += 8 + chunkSize;
      }

      logger.error('‚ùå No se encontr√≥ chunk de datos en WAV');
      return null;
    } catch (error) {
      logger.error(`‚ùå Error extrayendo PCM: ${error.message}`);
      return null;
    }
  }

  /**
   * Convertir PCM 16-bit a mulaw 8-bit
   */
  convertPCMToMulaw(pcmBuffer) {
    try {
      const mulawBuffer = Buffer.alloc(pcmBuffer.length / 2);
      
      for (let i = 0; i < pcmBuffer.length; i += 2) {
        // Leer sample PCM 16-bit little endian
        const pcmSample = pcmBuffer.readInt16LE(i);
        
        // Convertir a mulaw
        const mulawSample = this.linearToMulaw(pcmSample);
        mulawBuffer[i / 2] = mulawSample;
      }
      
      logger.info(`üéµ PCM convertido a mulaw: ${mulawBuffer.length} bytes`);
      return mulawBuffer;
    } catch (error) {
      logger.error(`‚ùå Error convirtiendo a mulaw: ${error.message}`);
      return Buffer.alloc(0);
    }
  }

  /**
   * Convertir sample linear PCM a mulaw
   */
  linearToMulaw(pcmSample) {
    // Tabla de conversi√≥n mulaw
    const MULAW_MAX = 0x1FFF;
    const MULAW_BIAS = 33;
    
    let sign = 0;
    let position = 0;
    let lsb = 0;
    
    if (pcmSample < 0) {
      pcmSample = -pcmSample;
      sign = 0x80;
    }
    
    pcmSample += MULAW_BIAS;
    if (pcmSample > MULAW_MAX) pcmSample = MULAW_MAX;
    
    // Encontrar posici√≥n del bit m√°s significativo
    for (position = 12; position >= 5; position--) {
      if (pcmSample & (1 << position)) break;
    }
    
    lsb = (pcmSample >> (position - 4)) & 0x0F;
    return (~(sign | ((position - 5) << 4) | lsb)) & 0xFF;
  }
}

module.exports = TwilioStreamHandler;
