const logger = require('../utils/logger');
const { PrismaClient } = require('@prisma/client');
const azureTTSService = require('../services/azureTTSService');
const openaiService = require('../services/openaiService');
const ContextBuilder = require('../utils/contextBuilder');

const prisma = new PrismaClient();

class TwilioStreamHandler {
  constructor() {
    this.activeStreams = new Map();
    this.audioBuffers = new Map();
    this.conversationState = new Map();
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
    this.ttsService = azureTTSService;
    this.ttsSimple = azureTTSSimple;
  }

  /**
   * Manejar nueva conexi√≥n WebSocket
   */
  handleConnection(ws, req) {
    const streamId = `stream_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    ws.streamId = streamId;

    logger.info(`üîå NUEVA CONEXI√ìN TWILIO STREAM: ${streamId}`);
    logger.info(`üîç Request URL: ${req.url}`);
    logger.info(`üîç Request Headers: ${JSON.stringify(req.headers)}`);

    // Configurar heartbeat
    ws.isAlive = true;
    ws.on('pong', () => {
      ws.isAlive = true;
    });

    // Manejar mensajes
    ws.on('message', async (message) => {
      logger.info(`üì® MENSAJE WEBSOCKET RECIBIDO en ${streamId}: ${message.toString().substring(0, 200)}...`);
      
      try {
        const data = JSON.parse(message);
        logger.info(`üì® DATOS PARSEADOS: ${JSON.stringify(data, null, 2)}`);
        await this.handleTwilioMessage(ws, data);
      } catch (error) {
        logger.error(`‚ùå Error parseando mensaje: ${error.message}`);
      }
    });

    // Manejar cierre de conexi√≥n
    ws.on('close', (code, reason) => {
      logger.info(`üîå Conexi√≥n cerrada: ${streamId} - C√≥digo: ${code}, Raz√≥n: ${reason}`);
      this.cleanupStream(streamId);
    });

    // Manejar errores
    ws.on('error', (error) => {
      logger.error(`‚ùå Error en WebSocket ${streamId}: ${error.message}`);
      this.cleanupStream(streamId);
    });
  }

  /**
   * Manejo centralizado de mensajes WebSocket de Twilio
   */
  async handleTwilioMessage(ws, data) {
    const event = data.event;
    const streamSid = data.streamSid;
    
    logger.info(`üì® Evento recibido: ${event} para stream: ${streamSid}`);
    
    try {
      // Procesar eventos de forma secuencial y expl√≠cita
      switch (event) {
        case "connected":
          logger.info('üîå Media WS: Connected event received');
          await this.handleStreamConnected(ws, data);
          break;
          
        case "start":
          logger.info('üé§ Media WS: Start event received');
          // Asegurar que el start se procese completamente antes de continuar
          await this.handleStreamStart(ws, data);
          logger.info(`‚úÖ Start event procesado completamente para stream: ${streamSid}`);
          break;
          
        case "media":
          // Verificar que el stream est√© registrado antes de procesar media
          if (!this.activeStreams.has(streamSid)) {
            logger.warn(`‚ö†Ô∏è Media event recibido para stream no registrado: ${streamSid}`);
            logger.info(`üìä Streams activos: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
            return;
          }
          await this.handleMediaChunk(ws, data);
          break;
          
        case "stop":
          logger.info('üõë Media WS: Stop event received');
          await this.handleStreamStop(ws, data);
          break;
          
        default:
          logger.warn(`‚ö†Ô∏è Evento desconocido: ${event}`);
      }
    } catch (error) {
      logger.error(`‚ùå Error procesando evento ${event} para stream ${streamSid}: ${error.message}`);
      logger.error(`‚ùå Stack: ${error.stack}`);
      
      // Log adicional del estado actual
      logger.error(`üìä Estado actual - Streams activos: ${this.activeStreams.size}`);
      logger.error(`üóÇÔ∏è Stream IDs: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
    }
  }

  /**
   * Stream conectado - inicializar
   */
  async handleStreamConnected(ws, data) {
    logger.info(`‚úÖ Stream conectado, esperando evento start para par√°metros completos`);
  }

  /**
   * Stream iniciado - configurar cliente
   */
  async handleStreamStart(ws, data) {
    const { streamSid, callSid, customParameters } = data.start;
    const clientId = customParameters?.clientId;

    logger.info(`üé§ ===== INICIO handleStreamStart =====`);
    logger.info(`üé§ Processing start event:`);
    logger.info(`üé§ Stream starting: ${streamSid} for call ${callSid}, clientId: ${clientId}`);
    logger.info(`üé§ Data completa: ${JSON.stringify(data, null, 2)}`);

    // Verificar si el stream ya existe
    if (this.activeStreams.has(streamSid)) {
      logger.warn(`‚ö†Ô∏è Stream ${streamSid} ya existe en activeStreams`);
      return;
    }

    // REGISTRO INMEDIATO DEL STREAM - Antes de la consulta DB lenta
    logger.info('üöÄ REGISTRO INMEDIATO: Registrando stream antes de consulta DB...');
    const placeholderStreamData = {
      streamSid,
      ws,
      client: null, // Se llenar√° despu√©s
      callSid,
      audioBuffer: [],
      conversationHistory: [],
      lastActivity: Date.now(),
      isProcessing: false,
      isSendingTTS: false,
      isInitializing: true // Flag para indicar que est√° inicializando
    };
    
    this.activeStreams.set(streamSid, placeholderStreamData);
    this.audioBuffers.set(streamSid, []);
    this.conversationState.set(streamSid, []);
    
    logger.info(`üöÄ Stream registrado INMEDIATAMENTE: ${streamSid}`);
    logger.info(`üìä Active streams: ${this.activeStreams.size}`);

    try {
      logger.info('üîç PASO 1: Obteniendo configuraci√≥n del cliente desde par√°metros...');
      
      // OBTENER CONFIGURACI√ìN COMPLETA DESDE PAR√ÅMETROS (ya consultada en webhook)
      const clientConfig = {
        id: clientId ? parseInt(clientId) : 1,
        companyName: customParameters?.companyName || 'Sistema de Atenci√≥n',
        callConfig: {
          greeting: customParameters?.greeting || 'Hola, gracias por llamar. Soy el asistente virtual. ¬øEn qu√© puedo ayudarte?',
          voiceId: customParameters?.voiceId || 'lola',
          enabled: customParameters?.enabled !== 'false'
        },
        // Informaci√≥n completa de la empresa para contexto
        companyInfo: customParameters?.companyInfo ? JSON.parse(customParameters.companyInfo) : null,
        botConfig: customParameters?.botConfig ? JSON.parse(customParameters.botConfig) : null,
        businessHours: customParameters?.businessHours ? JSON.parse(customParameters.businessHours) : null,
        notificationConfig: customParameters?.notificationConfig ? JSON.parse(customParameters.notificationConfig) : null,
        // FAQs y archivos de contexto
        faqs: customParameters?.faqs ? JSON.parse(customParameters.faqs) : [],
        contextFiles: customParameters?.contextFiles ? JSON.parse(customParameters.contextFiles) : []
      };

      logger.info(`üîç DEBUG STREAM: Par√°metros recibidos del WebSocket:`);
      logger.info(`üîç DEBUG STREAM: - clientId: ${customParameters?.clientId}`);
      logger.info(`üîç DEBUG STREAM: - companyName: ${customParameters?.companyName}`);
      logger.info(`üîç DEBUG STREAM: - greeting: "${customParameters?.greeting}"`);
      logger.info(`üîç DEBUG STREAM: - voiceId: ${customParameters?.voiceId}`);
      logger.info(`üîç DEBUG STREAM: - companyInfo presente: ${!!customParameters?.companyInfo}`);
      logger.info(`üîç DEBUG STREAM: - botConfig presente: ${!!customParameters?.botConfig}`);
      logger.info(`üîç DEBUG STREAM: - businessHours presente: ${!!customParameters?.businessHours}`);
      logger.info(`üîç DEBUG STREAM: - faqs presente: ${!!customParameters?.faqs}`);
      logger.info(`üîç DEBUG STREAM: - contextFiles presente: ${!!customParameters?.contextFiles}`);
      
      logger.info(`üîç PASO 2: Cliente configurado: ${clientConfig.companyName}`);
      logger.info(`üîç PASO 2a: Saludo: "${clientConfig.callConfig.greeting}"`);
      logger.info(`üîç PASO 2b: Voz: "${clientConfig.callConfig.voiceId}"`);
      logger.info(`üîç PASO 2c: FAQs cargadas: ${clientConfig.faqs.length}`);
      logger.info(`üîç PASO 2d: Archivos contexto: ${clientConfig.contextFiles.length}`);

      // GENERAR CONTEXTO COMPLETO PARA OPENAI
      const systemPrompt = ContextBuilder.buildSystemPrompt(clientConfig);
      logger.info(`üìã PASO 2e: Contexto generado: ${systemPrompt.length} caracteres`);

      // ACTUALIZAR EL STREAM CON CONFIGURACI√ìN REAL Y CONTEXTO
      const streamData = this.activeStreams.get(streamSid);
      streamData.client = clientConfig;
      streamData.systemPrompt = systemPrompt; // Contexto completo disponible
      streamData.isInitializing = false;
      
      logger.info(`üîÑ PASO 3: Stream actualizado con configuraci√≥n real y contexto completo`);

      logger.info('üîç PASO 4: Enviando saludo inicial con configuraci√≥n real...');
      
      // Enviar saludo con configuraci√≥n real
      const greetingPromise = this.sendInitialGreeting(ws, { streamSid, callSid });
      
      const greetingTimeout = new Promise((_, reject) => {
        setTimeout(() => reject(new Error('sendInitialGreeting timeout after 10 seconds')), 10000);
      });

      try {
        await Promise.race([greetingPromise, greetingTimeout]);
        logger.info('üîç PASO 7: ‚úÖ Saludo inicial enviado correctamente');
      } catch (error) {
        logger.error(`‚ùå Error en saludo inicial: ${error.message}`);
        // Continuar sin saludo si hay error
      }
      
      logger.info('üîç PASO 8: ‚úÖ handleStreamStart COMPLETADO EXITOSAMENTE');

      // Verificaci√≥n final
      logger.info(`üîç VERIFICACI√ìN FINAL: Stream ${streamSid} existe: ${this.activeStreams.has(streamSid)}`);

    } catch (error) {
      logger.error(`‚ùå Error in handleStreamStart: ${error.message}`);
      logger.error(`‚ùå Stack: ${error.stack}`);
      
      // Limpiar en caso de error
      this.activeStreams.delete(streamSid);
      this.audioBuffers.delete(streamSid);
      this.conversationState.delete(streamSid);
      
      throw error; // Re-lanzar el error para que se capture en el nivel superior
    }
  }

  /**
   * Enviar saludo inicial con Azure TTS
   */
  async sendInitialGreeting(ws, data) {
    try {
      logger.info('üéµ INICIO sendInitialGreeting');
      const { streamSid, callSid } = data;
      
      logger.info(`üéµ PASO 1: Obteniendo stream data para ${streamSid}`);
      const streamData = this.activeStreams.get(streamSid);
      if (!streamData) {
        logger.error(`‚ùå No se encontr√≥ stream data para ${streamSid}`);
        return;
      }

      logger.info('üéµ PASO 2: Obteniendo cliente');
      const { client } = streamData;
      
      // Obtener el saludo desde callConfig.greeting
      let greeting = 'Hola, gracias por llamar. ¬øEn qu√© puedo ayudarte?';
      
      logger.info('üéµ PASO 3: Verificando callConfig');
      if (client.callConfig && client.callConfig.greeting) {
        greeting = client.callConfig.greeting;
      }

      // Obtener la voz configurada por el usuario
      let voiceId = this.ttsSimple.defaultVoice; // Voz por defecto
      if (client.callConfig && client.callConfig.voiceId) {
        voiceId = client.callConfig.voiceId;
      }

      logger.info(`üéµ PASO 4: Saludo preparado: "${greeting}"`);
      logger.info(`üéµ PASO 4a: Voz seleccionada: ${voiceId}`);

      // Generar audio con Azure TTS Simple (m√°s confiable)
      try {
        logger.info('üéµ PASO 5: Generando audio con Azure TTS Simple...');
        logger.info(`üéµ PASO 5a: Usando voz del usuario: ${voiceId}`);
        
        // Timeout para TTS de 3 segundos (m√°s agresivo)
        const ttsPromise = this.ttsSimple.generateSpeech(greeting, voiceId);
        const ttsTimeout = new Promise((_, reject) => {
          setTimeout(() => reject(new Error('TTS timeout after 3 seconds')), 3000);
        });

        const ttsResult = await Promise.race([ttsPromise, ttsTimeout]);
        
        logger.info(`üéµ PASO 6: Azure TTS Simple completado, success: ${ttsResult?.success}`);
        logger.info(`üéµ PASO 6a: Audio buffer size: ${ttsResult?.audioBuffer?.length || 0} bytes`);
        
        if (ttsResult && ttsResult.success && ttsResult.audioBuffer && ttsResult.audioBuffer.length > 0) {
          logger.info('üéµ PASO 7: Enviando audio a Twilio...');
          await this.sendAudioToTwilio(ws, ttsResult.audioBuffer, streamSid);
          logger.info('üéµ PASO 8: ‚úÖ Audio enviado correctamente');
        } else {
          logger.warn(`‚ö†Ô∏è Azure TTS Simple fall√≥: ${ttsResult?.error || 'Audio buffer vac√≠o'}`);
          logger.info('üîÑ FALLBACK: Enviando saludo como mensaje de texto inmediatamente...');
          this.sendTextFallback(ws, greeting, streamSid);
        }
      } catch (error) {
        logger.error(`‚ùå Error en Azure TTS Simple: ${error.message}`);
        logger.error(`‚ùå Stack: ${error.stack}`);
        logger.info('üîÑ FALLBACK: Enviando saludo como mensaje de texto inmediatamente...');
        this.sendTextFallback(ws, greeting, streamSid);
      }

    } catch (error) {
      logger.error(`‚ùå Error enviando saludo inicial: ${error.message}`);
      logger.error(`‚ùå Stack: ${error.stack}`);
    }
  }

  /**
   * Fallback para enviar audio simple cuando Azure TTS falla
   */
  async sendTextFallback(ws, text, streamSid) {
    try {
      logger.info(`üìù Iniciando fallback para: "${text}"`);
      
      // Intentar generar un beep simple como audio de fallback
      const fallbackAudio = this.generateSimpleBeep();
      
      if (fallbackAudio && ws.readyState === 1) {
        logger.info('üîî Enviando beep de fallback...');
        await this.sendAudioToTwilio(ws, fallbackAudio, streamSid);
      }
      
      // Tambi√©n enviar un mark para indicar que hubo un problema
      const markMessage = {
        event: 'mark',
        streamSid: streamSid,
        mark: {
          name: `tts_fallback_${Date.now()}`
        }
      };
      
      if (ws.readyState === 1) {
        ws.send(JSON.stringify(markMessage));
      }
      
      logger.info(`‚úÖ Fallback enviado para ${streamSid}`);
      
    } catch (error) {
      logger.error(`‚ùå Error enviando fallback: ${error.message}`);
    }
  }

  /**
   * Generar un beep simple como audio de fallback
   */
  generateSimpleBeep() {
    try {
      // Generar un beep simple de 500ms en formato mulaw 8kHz
      const sampleRate = 8000;
      const duration = 0.5; // 500ms
      const frequency = 800; // 800Hz
      const samples = Math.floor(sampleRate * duration);
      
      const audioBuffer = Buffer.alloc(samples);
      
      for (let i = 0; i < samples; i++) {
        // Generar onda senoidal
        const sample = Math.sin(2 * Math.PI * frequency * i / sampleRate);
        // Convertir a mulaw (aproximaci√≥n simple)
        const mulaw = this.linearToMulaw(sample * 0.5); // Volumen reducido
        audioBuffer[i] = mulaw;
      }
      
      logger.info(`üîî Beep generado: ${audioBuffer.length} bytes`);
      return audioBuffer;
      
    } catch (error) {
      logger.error(`‚ùå Error generando beep: ${error.message}`);
      return null;
    }
  }

  /**
   * Conversi√≥n simple de linear a mulaw
   */
  linearToMulaw(sample) {
    const BIAS = 0x84;
    const CLIP = 32635;
    
    let sign = (sample < 0) ? 0x80 : 0x00;
    if (sign) sample = -sample;
    
    sample = Math.min(sample * 32767, CLIP);
    
    if (sample >= 256) {
      let exponent = Math.floor(Math.log2(sample / 256));
      let mantissa = Math.floor((sample >> (exponent + 3)) & 0x0F);
      sample = (exponent << 4) | mantissa;
    } else {
      sample = sample >> 4;
    }
    
    return (sample ^ 0x55) | sign;
  }

  /**
   * Manejar chunk de audio
   */
  async handleMediaChunk(ws, data) {
    const streamSid = data.streamSid;
    
    logger.info(`üì® Media chunk recibido para StreamSid: "${streamSid}"`);
    logger.info(`üóÇÔ∏è Streams activos disponibles: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
    logger.info(`üîç ¬øStream existe? ${this.activeStreams.has(streamSid)}`);

    const streamData = this.activeStreams.get(streamSid);
    
    if (!streamData) {
      logger.warn(`‚ö†Ô∏è Stream no encontrado para StreamSid: ${streamSid}`);
      logger.warn(`‚ö†Ô∏è Streams disponibles: [${Array.from(this.activeStreams.keys()).join(', ')}]`);
      return;
    }

    // Si el stream est√° inicializ√°ndose, solo almacenar el audio sin procesar
    if (streamData.isInitializing) {
      logger.info(`üîÑ Stream ${streamSid} est√° inicializ√°ndose, almacenando audio...`);
      // Solo almacenar el audio, no procesar a√∫n
      if (data.media.track === 'inbound') {
        const audioBuffer = this.audioBuffers.get(streamSid) || [];
        audioBuffer.push(data.media.payload);
        this.audioBuffers.set(streamSid, audioBuffer);
      }
      return;
    }

    // Solo procesar audio entrante (inbound)
    if (data.media.track === 'inbound') {
      const audioBuffer = this.audioBuffers.get(streamSid) || [];
      audioBuffer.push(data.media.payload);
      this.audioBuffers.set(streamSid, audioBuffer);

      // Actualizar √∫ltima actividad
      streamData.lastActivity = Date.now();

      // Procesar cuando tengamos suficiente audio (aproximadamente 1 segundo)
      if (audioBuffer.length >= 50 && !streamData.isProcessing) {
        await this.processAudioBuffer(streamSid);
      }
    }
  }

  /**
   * Procesar buffer de audio acumulado
   */
  async processAudioBuffer(streamSid) {
    const streamData = this.activeStreams.get(streamSid);
    if (!streamData || streamData.isProcessing) {
      return;
    }

    streamData.isProcessing = true;
    
    try {
      const audioBuffer = this.audioBuffers.get(streamSid) || [];
      if (audioBuffer.length === 0) {
        streamData.isProcessing = false;
        return;
      }

      logger.info(`üé§ Procesando ${audioBuffer.length} chunks de audio para ${streamSid}`);

      // Limpiar buffer
      this.audioBuffers.set(streamSid, []);

      // Usar el contexto completo del cliente para generar respuesta con OpenAI
      const systemPrompt = streamData.systemPrompt || `Eres un asistente virtual para ${streamData.client?.companyName || 'la empresa'}.`;
      
      // Aqu√≠ ir√≠a la transcripci√≥n del audio (por ahora simulamos)
      const userMessage = "Usuario habl√≥"; // Placeholder para transcripci√≥n real
      
      // Generar respuesta usando OpenAI con contexto completo
      const response = await this.generateAIResponse(userMessage, systemPrompt, streamData);
      
      // Generar respuesta de audio
      const ttsResult = await this.ttsService.generateSpeech(response);
      
      if (ttsResult && ttsResult.success && ttsResult.audioBuffer) {
        await this.sendAudioToTwilio(streamData.ws, ttsResult.audioBuffer, streamSid);
      }

      streamData.isSendingTTS = true;

      // Verificar que el WebSocket est√© abierto
      if (ws.readyState !== 1) { // WebSocket.OPEN = 1
        logger.error(`‚ùå WebSocket no est√° abierto (readyState: ${ws.readyState})`);
        streamData.isSendingTTS = false;
        return;
      }

      // Extraer datos PCM del WAV y convertir a mulaw
      const wavData = this.extractPCMFromWAV(audioBuffer);
      if (!wavData) {
        logger.error(`‚ùå No se pudo extraer PCM del audio WAV`);
        streamData.isSendingTTS = false;
        return;
      }
      
      const mulawData = this.convertPCMToMulaw(wavData);
      const chunkSize = 160; // 20ms de audio a 8kHz mulaw
      const totalChunks = Math.ceil(mulawData.length / chunkSize);
      
      logger.info(`üéµ Audio WAV convertido a mulaw: ${mulawData.length} bytes`);
      logger.info(`üéµ Enviando ${totalChunks} chunks de audio...`);
      
      for (let i = 0; i < mulawData.length; i += chunkSize) {
        const chunk = mulawData.slice(i, i + chunkSize);
        const base64Chunk = chunk.toString('base64');
        
        const mediaMessage = {
          event: 'media',
          streamSid: streamSid,
          media: {
            timestamp: Date.now(),
            payload: base64Chunk
          }
        };

        // Verificar WebSocket antes de cada env√≠o
        if (ws.readyState !== 1) {
          logger.warn(`‚ö†Ô∏è WebSocket cerrado durante env√≠o en chunk ${Math.floor(i/chunkSize) + 1}`);
          break;
        }

        ws.send(JSON.stringify(mediaMessage));
        
        // Log cada 25 chunks
        if ((Math.floor(i/chunkSize) + 1) % 25 === 0) {
          logger.info(`üéµ Enviado chunk ${Math.floor(i/chunkSize) + 1}/${totalChunks}`);
        }

        // Peque√±a pausa entre chunks para simular tiempo real
        await new Promise(resolve => setTimeout(resolve, 20));
      }

      streamData.isSendingTTS = false;
      logger.info(`‚úÖ Audio enviado correctamente a ${streamSid} (${totalChunks} chunks)`);

    } catch (error) {
      logger.error(`‚ùå Error enviando audio: ${error.message}`);
      logger.error(`‚ùå Stack: ${error.stack}`);
      const streamData = this.activeStreams.get(streamSid);
      if (streamData) {
        streamData.isSendingTTS = false;
      }
    }
  }

  /**
   * Stream detenido
   */
  async handleStreamStop(ws, data) {
    const streamSid = data.streamSid;
    logger.info(`üõë Stream detenido: ${streamSid}`);
    
    this.cleanupStream(streamSid);
  }

  /**
   * Limpiar recursos del stream
   */
  cleanupStream(streamId) {
    // Buscar por streamId o streamSid
    let streamSidToClean = null;
    
    for (const [streamSid, streamData] of this.activeStreams.entries()) {
      if (streamData.ws && streamData.ws.streamId === streamId) {
        streamSidToClean = streamSid;
        break;
      }
    }
    
    if (streamSidToClean) {
      this.activeStreams.delete(streamSidToClean);
      this.audioBuffers.delete(streamSidToClean);
      this.conversationState.delete(streamSidToClean);
      logger.info(`üßπ Stream limpiado: ${streamSidToClean}`);
    }
  }

  /**
   * Limpiar streams inactivos
   */
  cleanupInactiveStreams() {
    const now = Date.now();
    const timeout = 5 * 60 * 1000; // 5 minutos

    for (const [streamSid, streamData] of this.activeStreams.entries()) {
      if (now - streamData.lastActivity > timeout) {
        logger.info(`üßπ Limpiando stream inactivo: ${streamSid}`);
        this.cleanupStream(streamData.ws.streamId);
      }
    }
  }

  /**
   * Iniciar heartbeat para mantener conexiones activas
   */
  startHeartbeat() {
    // Limpiar streams inactivos cada 2 minutos
    setInterval(() => {
      this.cleanupInactiveStreams();
    }, 2 * 60 * 1000);

    logger.info('üíì Heartbeat iniciado para limpieza de streams inactivos');
  }

  /**
   * Extraer datos PCM de un archivo WAV
   */
  extractPCMFromWAV(wavBuffer) {
    try {
      // Verificar header WAV
      if (wavBuffer.length < 44) {
        logger.error('‚ùå Buffer WAV demasiado peque√±o');
        return null;
      }

      // Verificar RIFF header
      const riffHeader = wavBuffer.toString('ascii', 0, 4);
      if (riffHeader !== 'RIFF') {
        logger.error('‚ùå No es un archivo WAV v√°lido (falta RIFF)');
        return null;
      }

      // Verificar WAVE header
      const waveHeader = wavBuffer.toString('ascii', 8, 12);
      if (waveHeader !== 'WAVE') {
        logger.error('‚ùå No es un archivo WAV v√°lido (falta WAVE)');
        return null;
      }

      // Buscar chunk de datos
      let dataOffset = 12;
      while (dataOffset < wavBuffer.length - 8) {
        const chunkId = wavBuffer.toString('ascii', dataOffset, dataOffset + 4);
        const chunkSize = wavBuffer.readUInt32LE(dataOffset + 4);
        
        if (chunkId === 'data') {
          // Encontrado el chunk de datos
          const pcmData = wavBuffer.slice(dataOffset + 8, dataOffset + 8 + chunkSize);
          logger.info(`üéµ PCM extra√≠do: ${pcmData.length} bytes`);
          return pcmData;
        }
        
        dataOffset += 8 + chunkSize;
      }

      logger.error('‚ùå No se encontr√≥ chunk de datos en WAV');
      return null;
    } catch (error) {
      logger.error(`‚ùå Error extrayendo PCM: ${error.message}`);
      return null;
    }
  }

  /**
   * Convertir PCM 16-bit a mulaw 8-bit
   */
  convertPCMToMulaw(pcmBuffer) {
    try {
      const mulawBuffer = Buffer.alloc(pcmBuffer.length / 2);
      
      for (let i = 0; i < pcmBuffer.length; i += 2) {
        // Leer sample PCM 16-bit little endian
        const pcmSample = pcmBuffer.readInt16LE(i);
        
        // Convertir a mulaw
        const mulawSample = this.linearToMulaw(pcmSample);
        mulawBuffer[i / 2] = mulawSample;
      }
      
      logger.info(`üéµ PCM convertido a mulaw: ${mulawBuffer.length} bytes`);
      return mulawBuffer;
    } catch (error) {
      logger.error(`‚ùå Error convirtiendo a mulaw: ${error.message}`);
      return Buffer.alloc(0);
    }
  }

  /**
   * Convertir sample linear PCM a mulaw
   */
  linearToMulaw(pcmSample) {
    // Tabla de conversi√≥n mulaw
    const MULAW_MAX = 0x1FFF;
    const MULAW_BIAS = 33;
    
    let sign = 0;
    let position = 0;
    let lsb = 0;
    
    if (pcmSample < 0) {
      pcmSample = -pcmSample;
      sign = 0x80;
    }
    
    pcmSample += MULAW_BIAS;
    if (pcmSample > MULAW_MAX) pcmSample = MULAW_MAX;
    
    // Encontrar posici√≥n del bit m√°s significativo
    for (position = 12; position >= 5; position--) {
      if (pcmSample & (1 << position)) break;
    }
    
    lsb = (pcmSample >> (position - 4)) & 0x0F;
    return (~(sign | ((position - 5) << 4) | lsb)) & 0xFF;
  }
}

module.exports = TwilioStreamHandler;
