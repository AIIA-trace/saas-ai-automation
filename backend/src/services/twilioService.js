const twilio = require('twilio');
const logger = require('../utils/logger');
const { processUserMessage } = require('./aiConversationService');
const azureTTSService = require('./azureTTSService');
const openaiWhisperService = require('./openaiWhisperService');
const { makeTextNatural, getVoiceSettings } = require('./naturalPersonalityService');
const { PrismaClient } = require('@prisma/client');
const prisma = new PrismaClient();

// Cache para respuestas de clientes (evita consultas repetidas)
const clientCache = new Map();
const CACHE_DURATION = 5 * 60 * 1000; // 5 minutos

class TwilioService {
  constructor() {
    // Solo inicializar Twilio si hay credenciales
    if (process.env.TWILIO_ACCOUNT_SID && process.env.TWILIO_AUTH_TOKEN) {
      this.client = twilio(
        process.env.TWILIO_ACCOUNT_SID,
        process.env.TWILIO_AUTH_TOKEN
      );
    } else {
      this.client = null;
      logger.warn('Twilio credentials not configured');
    }
    
    // PERSONALIDAD ULTRA-REALISTA GLOBAL (Com√∫n para todos los clientes)
    this.globalPersonality = {
      // NATURALIDAD POR IDIOMA
      naturalness: {
        // üé≠ PAUTAS DE NATURALIDAD POR IDIOMA (NO frases hardcodeadas)
        languageGuidelines: {
          'es-ES': {
            muletillas: "Usar muletillas espa√±olas naturales como 'eh', 'bueno', 'pues', 'vale', 'a ver'",
            pausas: "Incluir pausas naturales, respiraci√≥n y momentos de reflexi√≥n",
            transiciones: "Conectar ideas con 'entonces', 'bueno', 'por tanto', 'en ese caso'",
            confirmaciones: "Confirmar comprensi√≥n con 's√≠', 'exacto', 'perfecto', 'entiendo'",
            rellenos: "Usar rellenos conversacionales como '¬øsabes?', '¬øvale?', '¬øno?'"
          },
          'en-US': {
            muletillas: "Use natural English fillers like 'uh', 'um', 'well', 'so', 'like', 'you know'",
            pausas: "Include natural pauses, breathing and thinking moments",
            transiciones: "Connect ideas with 'so', 'well', 'therefore', 'in that case'",
            confirmaciones: "Confirm understanding with 'yes', 'exactly', 'perfect', 'I see'",
            rellenos: "Use conversational fillers like 'you know?', 'right?', 'okay?'"
          },
          'fr-FR': {
            muletillas: "Utiliser des h√©sitations fran√ßaises naturelles comme 'euh', 'bon', 'alors', 'voil√†', 'donc'",
            pausas: "Inclure des pauses naturelles, respiration et moments de r√©flexion",
            transiciones: "Connecter les id√©es avec 'donc', 'alors', 'par cons√©quent', 'dans ce cas'",
            confirmaciones: "Confirmer la compr√©hension avec 'oui', 'exactement', 'parfait', 'je vois'",
            rellenos: "Utiliser des mots de remplissage comme 'vous voyez?', 'd'accord?', 'n'est-ce pas?'"
          }
        }
      },
      
      // üéµ SONIDOS DE FONDO REALISTAS
      backgroundSounds: {
        enabled: true,
        officeAmbient: {
          keyboardTyping: ["*tecleo suave*", "*click de rat√≥n*"],
          paperSounds: ["*hoja de papel*", "*escribiendo*"],
          phoneRings: ["*tel√©fono de fondo*"],
          voicesDistance: ["*voces lejanas*", "*conversaci√≥n de fondo*"],
          chairSounds: ["*silla girando*"],
          probability: 0.15 // 15% probabilidad de a√±adir sonido
        },
        naturalBreathing: {
          enabled: true,
          sounds: ["*respira*", "*suspira ligeramente*"],
          probability: 0.25 // 25% probabilidad
        }
      },
      
      // üéØ CONFIGURACI√ìN DE VOZ POR DEFECTO
      voiceConfig: {
        azureVoice: 'es-ES-LolaNeural',
        language: 'es-ES',
        rate: '0.95', // Ligeramente m√°s lento para naturalidad
        pitch: '0', // Tono neutro
        volume: '0' // Volumen neutro
      },
      
      // üé≠ CONFIGURACI√ìN DE NATURALIDAD (Solo elementos t√©cnicos, no frases)
      naturalnessProbabilities: {
        muletillas: 0.4,        // 40% probabilidad de a√±adir muletillas
        breathing: 0.25,        // 25% probabilidad de respiraci√≥n
        transitions: 0.3,       // 30% probabilidad de transiciones
        fillers: 0.25,          // 25% probabilidad de rellenos
        backgroundSounds: 0.15  // 15% probabilidad de sonidos de fondo
      }
    };
  }

  /**
   * M√âTODO PRINCIPAL: Generar respuesta completa para llamada entrante
   */
  async generateCallResponse({ client, callerNumber, callSid }) {
    try {
      logger.info(`üéØ Generando respuesta para ${client.companyName} (${callSid})`);
      
      // 1. Obtener datos del cliente (con cach√©)
      const clientData = await this.getClientDataCached(client.id);
      
      // 2. Verificar horarios comerciales
      const isOpen = this.checkBusinessHours(clientData.businessHoursConfig);
      
      // 3. Generar saludo personalizado
      const greeting = this.generateNaturalGreeting(clientData, isOpen);
      
      // 4. Generar audio con Azure TTS
      const audioUrl = await this.generateAzureAudio(greeting, clientData);
      
      // 5. Crear TwiML optimizado
      const twiml = this.createOptimizedTwiML(audioUrl, greeting, clientData);
      
      logger.info(`‚úÖ Respuesta generada para ${client.companyName}: ${greeting.substring(0, 50)}...`);
      return twiml;
      
    } catch (error) {
      logger.error(`‚ùå Error generando respuesta: ${error.message}`);
      return this.generateErrorTwiML();
    }
  }

  /**
   * Procesar respuesta del usuario durante la llamada
   */
  async processUserResponse({ client, userInput, callSid }) {
    try {
      logger.info(`üé§ Procesando respuesta: "${userInput}" para ${client.companyName}`);
      
      // 1. Obtener datos completos del cliente (con contexto empresarial)
      const clientData = await this.getClientDataCached(client.id);
      
      // 2. Procesar con IA conversacional CON CONTEXTO EMPRESARIAL + PAUTAS DE COMPORTAMIENTO
      const aiResponse = await processUserMessage(
        client.id,           // clientId
        callSid,            // sessionId
        userInput,          // userMessage
        {                   // context
          context: 'phone_call',
        language: clientData.language || 'es-ES',
        
        // üè¢ CONTEXTO EMPRESARIAL COMPLETO PARA IA
        companyInfo: {
          name: clientData.companyName,
          description: clientData.companyDescription,
          industry: clientData.industry,
          phone: clientData.phone,
          address: clientData.address,
          website: clientData.website,
          businessHours: clientData.businessHoursConfig
        },
        faqs: clientData.faqs || [],
        contextFiles: clientData.contextFiles || [],
        botPersonality: clientData.botPersonality || 'profesional y amigable',
        
        // üé≠ PAUTAS DE COMPORTAMIENTO HUMANO (NO frases hardcodeadas)
        behaviorGuidelines: this.globalPersonality.behaviorGuidelines
        }
      );
      
      // 2. Extraer el string de la respuesta de IA (puede venir como objeto)
      let aiResponseText;
      if (typeof aiResponse === 'string') {
        aiResponseText = aiResponse;
      } else if (aiResponse && typeof aiResponse === 'object' && aiResponse.response) {
        aiResponseText = aiResponse.response;
      } else if (aiResponse && typeof aiResponse === 'object' && aiResponse.content) {
        aiResponseText = aiResponse.content;
      } else {
        logger.error(`‚ùå Formato de aiResponse no reconocido:`, aiResponse);
        aiResponseText = "Disculpa, ha ocurrido un error procesando tu consulta. ¬øPuedes repetir tu pregunta?";
      }
      
      logger.info(`ü§ñ Respuesta IA extra√≠da: "${aiResponseText}"`);
      
      // 3. Hacer respuesta natural CON COMPORTAMIENTO HUMANO
      const naturalResponse = this.makeResponseNatural(aiResponseText, clientData, userInput);
      
      // 3. Generar audio con Azure TTS
      const audioUrl = await this.generateAzureAudio(naturalResponse, client);
      
      // 4. Crear TwiML de continuaci√≥n
      const twiml = this.createContinuationTwiML(audioUrl, naturalResponse, client);
      
      return twiml;
      
    } catch (error) {
      logger.error(`‚ùå Error procesando respuesta: ${error.message}`);
      return this.generateErrorTwiML('Disculpa, no he entendido bien. ¬øPuedes repetir?');
    }
  }

  /**
   * Procesar audio del usuario usando OpenAI Whisper
   * @param {Object} params - Par√°metros
   * @param {Object} params.client - Cliente
   * @param {string} params.audioUrl - URL del audio de Twilio
   * @param {string} params.callSid - ID de la llamada
   * @param {number} params.duration - Duraci√≥n del audio
   * @returns {Promise<string>} - TwiML response
   */
  async processUserAudio({ client, audioUrl, callSid, duration }) {
    const processId = `PROC-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    const startTime = Date.now();
    
    logger.info(`üéôÔ∏è [PROCESS-DEBUG-${processId}] ===== INICIANDO PROCESAMIENTO DE AUDIO =====`);
    logger.info(`üéôÔ∏è [PROCESS-DEBUG-${processId}] Cliente: ${client.companyName} (ID: ${client.id})`);
    logger.info(`üéôÔ∏è [PROCESS-DEBUG-${processId}] Audio URL: ${audioUrl}`);
    logger.info(`üéôÔ∏è [PROCESS-DEBUG-${processId}] Call SID: ${callSid}`);
    logger.info(`üéôÔ∏è [PROCESS-DEBUG-${processId}] Duraci√≥n: ${duration}s`);
    
    try {
      // 1. Obtener datos completos del cliente
      logger.info(`üîç [PROCESS-DEBUG-${processId}] Obteniendo datos del cliente...`);
      const clientDataStart = Date.now();
      
      const clientData = await this.getClientDataCached(client.id);
      
      const clientDataTime = Date.now() - clientDataStart;
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Datos del cliente obtenidos en ${clientDataTime}ms`);
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Idioma del cliente: ${clientData.language}`);
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Empresa: ${clientData.companyName}`);
      
      // 2. Transcribir audio con OpenAI Whisper
      logger.info(`üîÑ [PROCESS-DEBUG-${processId}] Iniciando transcripci√≥n con OpenAI Whisper...`);
      const transcriptionStart = Date.now();
      
      const transcription = await openaiWhisperService.transcribeWithRetry(
        audioUrl, 
        clientData.language === 'en' ? 'en' : 'es'
      );
      
      const transcriptionTime = Date.now() - transcriptionStart;
      
      if (!transcription) {
        logger.warn(`‚ö†Ô∏è [PROCESS-DEBUG-${processId}] No se pudo transcribir el audio despu√©s de ${transcriptionTime}ms`);
        return this.generateErrorTwiML("No he podido escuchar tu respuesta claramente. ¬øPuedes repetir tu pregunta?");
      }
      
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Transcripci√≥n completada en ${transcriptionTime}ms`);
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Texto transcrito: "${transcription}"`);
      
      // 3. Guardar transcripci√≥n en base de datos
      logger.info(`üíæ [PROCESS-DEBUG-${processId}] Guardando transcripci√≥n en BD...`);
      const dbStart = Date.now();
      
      try {
        const callLogEntry = await prisma.callLog.create({
          data: {
            clientId: client.id,
            twilioCallSid: callSid,
            callerNumber: 'unknown', // Se actualizar√° desde el webhook principal
            recordingUrl: audioUrl,
            transcription: transcription,
            duration: duration,
            status: 'completed'
          }
        });
        
        const dbTime = Date.now() - dbStart;
        logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Transcripci√≥n guardada en BD en ${dbTime}ms (ID: ${callLogEntry.id})`);
        
      } catch (dbError) {
        const dbTime = Date.now() - dbStart;
        logger.error(`‚ùå [PROCESS-DEBUG-${processId}] Error guardando transcripci√≥n despu√©s de ${dbTime}ms: ${dbError.message}`);
        logger.error(`‚ùå [PROCESS-DEBUG-${processId}] Stack del error BD: ${dbError.stack}`);
        // Continuar sin fallar
      }
      
      // 4. Procesar con IA conversacional
      logger.info(`ü§ñ [PROCESS-DEBUG-${processId}] Enviando a IA conversacional...`);
      const aiStart = Date.now();
      
      const aiContext = {
        context: 'phone_call',
        language: clientData.language || 'es-ES',
        
        // üè¢ CONTEXTO EMPRESARIAL COMPLETO PARA IA
        companyInfo: {
          name: clientData.companyName,
          description: clientData.companyDescription,
          industry: clientData.industry,
          phone: clientData.phone,
          website: clientData.website,
          address: clientData.address
        },
        
        // üé≠ PAUTAS DE COMPORTAMIENTO HUMANO
        behaviorGuidelines: this.globalPersonality.behaviorGuidelines
      };
      
      logger.info(`ü§ñ [PROCESS-DEBUG-${processId}] Contexto IA: ${JSON.stringify(aiContext, null, 2)}`);
      
      const aiResponse = await processUserMessage(
        client.id,           // clientId
        callSid,            // sessionId
        transcription,      // userMessage (transcripci√≥n de Whisper)
        aiContext           // context
      );
      
      const aiTime = Date.now() - aiStart;
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] IA respondi√≥ en ${aiTime}ms`);
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Tipo de respuesta IA: ${typeof aiResponse}`);
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Respuesta IA raw: ${JSON.stringify(aiResponse)}`);
      
      // 5. Extraer el string de la respuesta de IA (puede venir como objeto)
      let aiResponseText;
      if (typeof aiResponse === 'string') {
        aiResponseText = aiResponse;
        logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Respuesta IA es string directo`);
      } else if (aiResponse && typeof aiResponse === 'object' && aiResponse.response) {
        aiResponseText = aiResponse.response;
        logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Respuesta IA extra√≠da de .response`);
      } else if (aiResponse && typeof aiResponse === 'object' && aiResponse.content) {
        aiResponseText = aiResponse.content;
        logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Respuesta IA extra√≠da de .content`);
      } else {
        logger.error(`‚ùå [PROCESS-DEBUG-${processId}] Formato de aiResponse no reconocido:`, aiResponse);
        aiResponseText = "Disculpa, ha ocurrido un error procesando tu consulta. ¬øPuedes repetir tu pregunta?";
      }
      
      logger.info(`ü§ñ [PROCESS-DEBUG-${processId}] Respuesta IA final: "${aiResponseText}"`);
      
      // 6. Hacer respuesta natural CON COMPORTAMIENTO HUMANO
      logger.info(`üé≠ [PROCESS-DEBUG-${processId}] Aplicando naturalidad a la respuesta...`);
      const naturalStart = Date.now();
      
      const naturalResponse = this.makeResponseNatural(aiResponseText, clientData, transcription);
      
      const naturalTime = Date.now() - naturalStart;
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Naturalidad aplicada en ${naturalTime}ms`);
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Respuesta natural: "${naturalResponse}"`);
      
      // 7. Generar audio con Azure TTS
      logger.info(`üéµ [PROCESS-DEBUG-${processId}] Generando audio con Azure TTS...`);
      const ttsStart = Date.now();
      
      const audioUrlResponse = await this.generateAzureAudio(naturalResponse, clientData);
      
      const ttsTime = Date.now() - ttsStart;
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] Audio generado en ${ttsTime}ms`);
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] URL del audio: ${audioUrlResponse}`);
      
      // 8. Crear TwiML de continuaci√≥n
      logger.info(`üìù [PROCESS-DEBUG-${processId}] Creando TwiML de respuesta...`);
      const twimlStart = Date.now();
      
      const twiml = this.createContinuationTwiML(audioUrlResponse, naturalResponse, clientData);
      
      const twimlTime = Date.now() - twimlStart;
      const totalTime = Date.now() - startTime;
      
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] TwiML creado en ${twimlTime}ms`);
      logger.info(`‚úÖ [PROCESS-DEBUG-${processId}] TwiML length: ${twiml?.length || 0} caracteres`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] PROCESAMIENTO COMPLETADO en ${totalTime}ms`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] ===== TIEMPOS DETALLADOS =====`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] - Cliente: ${clientDataTime}ms`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] - Transcripci√≥n: ${transcriptionTime}ms`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] - IA: ${aiTime}ms`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] - Naturalidad: ${naturalTime}ms`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] - TTS: ${ttsTime}ms`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] - TwiML: ${twimlTime}ms`);
      logger.info(`üéâ [PROCESS-DEBUG-${processId}] - TOTAL: ${totalTime}ms`);
      
      return twiml;
      
    } catch (error) {
      const totalTime = Date.now() - startTime;
      logger.error(`‚ùå [PROCESS-DEBUG-${processId}] Error despu√©s de ${totalTime}ms`);
      logger.error(`‚ùå [PROCESS-DEBUG-${processId}] Error tipo: ${error.constructor.name}`);
      logger.error(`‚ùå [PROCESS-DEBUG-${processId}] Error mensaje: ${error.message}`);
      logger.error(`‚ùå [PROCESS-DEBUG-${processId}] Error stack: ${error.stack}`);
      
      return this.generateErrorTwiML('Disculpa, ha ocurrido un problema t√©cnico. ¬øPuedes repetir tu pregunta?');
    }
  }

  /**
   * Obtener datos del cliente con cach√©
   */
  async getClientDataCached(clientId) {
    const cacheKey = `client_${clientId}`;
    const cached = clientCache.get(cacheKey);
    
    if (cached && (Date.now() - cached.timestamp) < CACHE_DURATION) {
      logger.info(`üìã Usando datos cacheados para cliente ${clientId}`);
      return cached.data;
    }
    
    logger.info(`üîÑ Obteniendo datos frescos para cliente ${clientId}`);
    const clientData = await prisma.client.findUnique({
      where: { id: clientId },
      select: {
        id: true,
        companyName: true,
        email: true,
        industry: true,
        businessHoursConfig: true,
        botName: true,
        botPersonality: true,
        welcomeMessage: true,
        language: true,
        // Configuraci√≥n de voz personalizada
        emailConfig: true,  // Contiene voiceSettings
        
        // üè¢ CONTEXTO EMPRESARIAL COMPLETO
        companyDescription: true,  // Descripci√≥n de la empresa
        phone: true,              // Tel√©fono de contacto
        address: true,            // Direcci√≥n f√≠sica
        website: true,            // Sitio web
        faqs: true,              // Preguntas frecuentes
        contextFiles: true       // Archivos de contexto/documentos
      }
    });
    
    // Guardar en cach√©
    clientCache.set(cacheKey, {
      data: clientData,
      timestamp: Date.now()
    });
    
    return clientData;
  }

  /**
   * Verificar horarios comerciales
   */
  checkBusinessHours(businessHoursConfig) {
    if (!businessHoursConfig || !businessHoursConfig.enabled) {
      return true; // Siempre abierto si no hay configuraci√≥n
    }
    
    const now = new Date();
    const currentDay = now.toLocaleDateString('en-US', { weekday: 'long' }).toLowerCase();
    const currentTime = now.toTimeString().slice(0, 5);
    
    const isWorkingDay = businessHoursConfig.workingDays && businessHoursConfig.workingDays[currentDay];
    const isWithinHours = currentTime >= businessHoursConfig.openingTime && 
                         currentTime <= businessHoursConfig.closingTime;
    
    return isWorkingDay && isWithinHours;
  }

  /**
   * üé≠ Generar saludo ULTRA-REALISTA usando datos de la base de datos
   */
  generateNaturalGreeting(clientData, isOpen) {
    let greeting;
    
    // üéØ USAR EL welcomeMessage CONFIGURADO EN LA BD
    if (clientData.welcomeMessage) {
      logger.info(`üé≠ Usando mensaje de bienvenida configurado: ${clientData.welcomeMessage}`);
      greeting = clientData.welcomeMessage;
    } else {
      // üîÑ FALLBACK: Generar saludo b√°sico SIN frases hardcodeadas
      logger.warn(`‚ö†Ô∏è Cliente ${clientData.companyName} no tiene welcomeMessage configurado. Generando fallback simple.`);
      
      // Saludo simple sin muletillas hardcodeadas (la IA las a√±adir√° seg√∫n las pautas)
      greeting = `Hola, has llamado a ${clientData.companyName}. Soy tu asistente.`;
      
      if (isOpen) {
        greeting += ` ¬øEn qu√© puedo ayudarte?`;
      } else {
        greeting += " Ahora mismo estamos cerrados. ¬øQuieres dejar alg√∫n mensaje?";
      }
    }
    
    // üéµ APLICAR SOLO SONIDOS DE OFICINA (las pautas van a la IA)
    greeting = this.makeResponseNatural(greeting, clientData);
    
    return greeting;
  }

  /**
   * Generar audio con Azure TTS (optimizado) - CON RECONOCIMIENTO DIN√ÅMICO
   */
  async generateAzureAudio(text, clientData) {
    const ttsId = `TTS-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
    const startTime = Date.now();
    
    logger.info(`üéµ [TTS-DEBUG-${ttsId}] ===== INICIANDO GENERACI√ìN DE AUDIO =====`);
    logger.info(`üéµ [TTS-DEBUG-${ttsId}] Texto a sintetizar: "${text}"`);
    logger.info(`üéµ [TTS-DEBUG-${ttsId}] Longitud del texto: ${text.length} caracteres`);
    logger.info(`üéµ [TTS-DEBUG-${ttsId}] Cliente: ${clientData.companyName}`);
    
    try {
      // Obtener voz apropiada para el idioma del cliente
      const language = clientData.language || 'es-ES';
      const azureVoice = this.getAzureVoiceForLanguage(language);
      
      logger.info(`üéµ [TTS-DEBUG-${ttsId}] Idioma detectado: ${language}`);
      logger.info(`üéµ [TTS-DEBUG-${ttsId}] Voz Azure seleccionada: ${azureVoice}`);
      
      // Verificar que Azure TTS est√© disponible
      if (!azureTTSService) {
        logger.error(`‚ùå [TTS-DEBUG-${ttsId}] Azure TTS Service no disponible`);
        return null;
      }
      
      logger.info(`üîÑ [TTS-DEBUG-${ttsId}] Enviando a Azure TTS...`);
      const azureStart = Date.now();
      
      const audioUrl = await azureTTSService.generateSpeech(text, {
        voice: azureVoice,
        language: language,
        rate: '0.95',
        pitch: '0',
        volume: '0'
      });
      
      const azureTime = Date.now() - azureStart;
      const totalTime = Date.now() - startTime;
      
      if (audioUrl) {
        logger.info(`‚úÖ [TTS-DEBUG-${ttsId}] Audio Azure TTS generado en ${azureTime}ms`);
        logger.info(`‚úÖ [TTS-DEBUG-${ttsId}] URL generada: ${audioUrl}`);
        logger.info(`‚úÖ [TTS-DEBUG-${ttsId}] Tiempo total: ${totalTime}ms`);
        return audioUrl;
      } else {
        logger.warn(`‚ö†Ô∏è [TTS-DEBUG-${ttsId}] Azure TTS retorn√≥ null despu√©s de ${azureTime}ms`);
        logger.warn(`‚ö†Ô∏è [TTS-DEBUG-${ttsId}] Usando fallback a Polly`);
        return null;
      }
      
    } catch (error) {
      const totalTime = Date.now() - startTime;
      logger.error(`‚ùå [TTS-DEBUG-${ttsId}] Error despu√©s de ${totalTime}ms`);
      logger.error(`‚ùå [TTS-DEBUG-${ttsId}] Error tipo: ${error.constructor.name}`);
      logger.error(`‚ùå [TTS-DEBUG-${ttsId}] Error mensaje: ${error.message}`);
      logger.error(`‚ùå [TTS-DEBUG-${ttsId}] Error stack: ${error.stack}`);
      
      return null;
    }
  }

  /**
   * Validar y obtener voz permitida (solo Lola o Dario)
   */
  validateAndGetVoice(requestedVoice) {
    const allowedVoices = {
      'lola': 'es-ES-LolaNeural',
      'dario': 'es-ES-DarioNeural',
      'es-ES-LolaNeural': 'es-ES-LolaNeural',
      'es-ES-DarioNeural': 'es-ES-DarioNeural'
    };
    
    // Normalizar entrada a min√∫sculas
    const normalizedVoice = requestedVoice?.toLowerCase();
    
    // Validar si la voz est√° permitida
    if (allowedVoices[normalizedVoice]) {
      return allowedVoices[normalizedVoice];
    }
    
    // Fallback por defecto: Lola
    logger.warn(`‚ö†Ô∏è Voz no permitida: ${requestedVoice}. Usando Lola por defecto.`);
    return 'es-ES-LolaNeural';
  }

  /**
   * Mapear idioma a voz Azure TTS apropiada (SOLO LOLA Y DARIO)
   */
  getAzureVoiceForLanguage(language) {
    // Solo permitimos Lola y Dario - por defecto Lola
    return 'es-ES-LolaNeural';
  }

  /**
   * Crear TwiML para continuar la conversaci√≥n (despu√©s de respuesta IA)
   */
  createContinuationTwiML(audioUrl, response, clientData) {
    const VoiceResponse = twilio.twiml.VoiceResponse;
    const twiml = new VoiceResponse();
    
    // Reproducir respuesta de IA
    if (audioUrl) {
      twiml.play(audioUrl);
      logger.info('üîä Reproduciendo audio generado por Azure TTS');
    } else {
      const voice = this.validateAndGetVoice(clientData.language || 'es-ES');
      twiml.say({ voice: voice, language: 'es-ES' }, response);
      logger.info('üîÑ Fallback a Polly');
    }
    
    // Verificar si debe continuar la conversaci√≥n
    if (!this.isEndingConversation(response)) {
      twiml.record({
        maxLength: 30,
        playBeep: false,
        timeout: 5,
        finishOnKey: '#',
        action: '/api/twilio/webhook/audio',
        method: 'POST'
      });
      
      // Mensaje de timeout si no hay respuesta
      twiml.say({ 
        voice: this.validateAndGetVoice(clientData.language || 'es-ES'), 
        language: 'es-ES' 
      }, 'Si necesitas algo m√°s, puedes llamarnos en nuestro horario de atenci√≥n. ¬°Hasta pronto!');
    }
    
    // Colgar al final
    twiml.hangup();
    
    return twiml.toString();
  }

  /**
   * Crear TwiML optimizado para respuesta inicial
   */
  createOptimizedTwiML(audioUrl, greeting, clientData) {
    const VoiceResponse = twilio.twiml.VoiceResponse;
    const twiml = new VoiceResponse();
    
    if (audioUrl) {
      // Usar Azure TTS
      twiml.play(audioUrl);
      logger.info('üéµ Usando Azure TTS para respuesta');
    } else {
      // Fallback a Polly
      twiml.say({
        voice: 'Polly.Conchita',
        language: 'es-ES'
      }, greeting);
      logger.info('üîÑ Fallback a Polly');
    }
    
    // Grabar respuesta del usuario para OpenAI Whisper
    twiml.record({
      maxLength: 30,
      playBeep: false,
      timeout: 5,
      finishOnKey: '#',
      action: '/api/twilio/webhook/audio',
      method: 'POST'
    });
    
    // Mensaje si no responde
    twiml.say({
      voice: 'Polly.Conchita',
      language: 'es-ES'
    }, 'Si necesitas algo m√°s, puedes llamarnos en nuestro horario de atenci√≥n. ¬°Hasta pronto!');
    
    return twiml.toString();
  }

  /**
   * Crear TwiML para continuaci√≥n de conversaci√≥n
   */
  createContinuationTwiML(audioUrl, response, clientData) {
    const VoiceResponse = twilio.twiml.VoiceResponse;
    const twiml = new VoiceResponse();
    
    if (audioUrl) {
      twiml.play(audioUrl);
    } else {
      twiml.say({
        voice: 'Polly.Conchita',
        language: 'es-ES'
      }, response);
    }
    
    // Verificar si debe continuar la conversaci√≥n
    if (!this.isEndingConversation(response)) {
      twiml.record({
        maxLength: 30,
        playBeep: false,
        timeout: 5,
        finishOnKey: '#',
        action: '/api/twilio/webhook/audio',
        method: 'POST'
      });
      
      twiml.say({
        voice: 'Polly.Conchita',
        language: 'es-ES'
      }, '¬øHay algo m√°s en lo que pueda ayudarte?');
    } else {
      twiml.hangup();
    }
    
    return twiml.toString();
  }

  /**
   * üé≠ APLICAR SOLO SONIDOS DE OFICINA (Las pautas ya est√°n en el contexto de IA)
   */
  makeResponseNatural(aiResponse, clientData, userInput = '') {
    // 1. Validar que aiResponse sea un string
    if (!aiResponse || typeof aiResponse !== 'string') {
      logger.error(`‚ùå aiResponse inv√°lido: ${typeof aiResponse}, valor: ${aiResponse}`);
      aiResponse = "Disculpa, ha ocurrido un error. ¬øPuedes repetir tu pregunta?";
    }
    
    // 2. Detectar idioma del cliente
    const language = clientData.language || 'es-ES';
    
    logger.info(`üé≠ Aplicando sonidos de oficina para idioma: ${language}`);
    logger.info(`üé≠ Las pautas de comportamiento y naturalidad ya fueron enviadas a la IA`);
    
    // 3. Aplicar SOLO sonidos de oficina (NO muletillas - eso lo hace la IA)
    aiResponse = this.addNaturalness(aiResponse, clientData, language);
    
    // 4. Personalizar por empresa
    aiResponse = aiResponse.replace(/\[EMPRESA\]/g, clientData.companyName || 'la empresa');
    
    logger.info(`üéµ Respuesta con sonidos de oficina: "${aiResponse.substring(0, 100)}..."`);
    
    return aiResponse;
  }
  
  /**
   * ü§ñ Detectar si preguntan sobre IA
   */
  isAskingAboutAI(userInput) {
    const aiKeywords = [
      'inteligencia artificial', 'ia', 'ai', 'robot', 'bot', 'chatbot', 
      'artificial', 'm√°quina', 'algoritmo', 'eres una ia', 'eres un robot',
      'eres artificial', 'eres humano', 'persona real'
    ];
    
    const input = userInput.toLowerCase();
    return aiKeywords.some(keyword => input.includes(keyword));
  }
  
  /**
   * üéØ Detectar si preguntan sobre objetivos/prop√≥sitos (NUNCA RESPONDER)
   */
  isAskingAboutObjective(userInput) {
    const objectiveKeywords = [
      'objetivo', 'prop√≥sito', 'para qu√©', 'por qu√©', 'cu√°l es tu funci√≥n',
      'para que sirves', 'qu√© haces', 'tu trabajo', 'tu misi√≥n', 'creado para',
      'dise√±ado para', 'programado para', 'entrenado para'
    ];
    
    const input = userInput.toLowerCase();
    return objectiveKeywords.some(keyword => input.includes(keyword));
  }
  
  /**
   * üîç Detectar consulta compleja que requiere "b√∫squeda"
   */
  isComplexQuery(userInput) {
    const complexTriggers = this.globalPersonality.conversationPatterns.complexQuery.triggers;
    const input = userInput.toLowerCase();
    return complexTriggers.some(trigger => input.includes(trigger));
  }
  
  /**
   * ‚úÖ Detectar respuesta directa (info b√°sica)
   */
  isDirectResponse(userInput) {
    const directTriggers = this.globalPersonality.conversationPatterns.directResponse.triggers;
    const input = userInput.toLowerCase();
    return directTriggers.some(trigger => input.includes(trigger));
  }
  
  /**
   * üéµ A√±adir naturalidad usando SOLO sonidos de oficina (las pautas van a la IA)
   */
  addNaturalness(response, clientData, language) {
    const probabilities = this.globalPersonality.naturalnessProbabilities;
    
    // SOLO a√±adir sonidos de fondo de oficina (NO muletillas - eso lo hace la IA)
    if (this.globalPersonality.backgroundSounds.enabled && Math.random() < probabilities.backgroundSounds) {
      response = this.addBackgroundSounds(response, language);
    }
    
    // SOLO a√±adir pausas y respiraci√≥n natural
    if (Math.random() < probabilities.breathing) {
      const breathSound = this.globalPersonality.backgroundSounds.naturalBreathing.sounds[
        Math.floor(Math.random() * this.globalPersonality.backgroundSounds.naturalBreathing.sounds.length)
      ];
      response = `${breathSound} ${response}`;
    }
    
    return response;
  }
  
  /**
   * üéµ A√±adir naturalidad b√°sica (SIN sonidos de oficina) - Solo para negaciones de IA
   */
  addBasicNaturalness(response, naturalness, language) {
    // üö´ NO a√±adir sonidos de oficina (tecleo, papel, etc.)
    
    // A√±adir muletillas naturales por idioma
    if (Math.random() < 0.4) {
      const muletilla = naturalness.muletillas[Math.floor(Math.random() * naturalness.muletillas.length)];
      response = `${muletilla} ${response}`;
    }
    
    // A√±adir pausas y respiraci√≥n natural
    if (Math.random() < this.globalPersonality.backgroundSounds.naturalBreathing.probability) {
      const breathSound = this.globalPersonality.backgroundSounds.naturalBreathing.sounds[
        Math.floor(Math.random() * this.globalPersonality.backgroundSounds.naturalBreathing.sounds.length)
      ];
      response = `${breathSound} ${response}`;
    }
    
    // A√±adir transiciones naturales
    if (response.includes('.') && Math.random() < 0.3) {
      const transicion = naturalness.transiciones[Math.floor(Math.random() * naturalness.transiciones.length)];
      response = response.replace('.', `, ${transicion},`);
    }
    
    // NO a√±adir rellenos en negaciones de IA (ser√≠a raro)
    
    return response;
  }
  
  /**
   * üéµ A√±adir sonidos de fondo de oficina realistas
   */
  addBackgroundSounds(response, language) {
    const { officeAmbient } = this.globalPersonality.backgroundSounds;
    
    // Probabilidad de a√±adir sonido de fondo
    if (Math.random() > officeAmbient.probability) {
      return response;
    }
    
    // Seleccionar tipo de sonido aleatorio
    const soundTypes = ['keyboardTyping', 'paperSounds', 'chairSounds'];
    const randomType = soundTypes[Math.floor(Math.random() * soundTypes.length)];
    const sounds = officeAmbient[randomType];
    const selectedSound = sounds[Math.floor(Math.random() * sounds.length)];
    
    // Posici√≥n aleatoria en la respuesta
    const words = response.split(' ');
    const insertPosition = Math.floor(Math.random() * words.length);
    
    words.splice(insertPosition, 0, selectedSound);
    
    logger.info(`üéµ Sonido de fondo a√±adido: ${selectedSound}`);
    
    return words.join(' ');
  }
  
  /**
   * üéØ Obtener configuraci√≥n de naturalidad por idioma
   */
  getNaturalnessForLanguage(language) {
    return this.globalPersonality.naturalness[language] || this.globalPersonality.naturalness['es-ES'];
  }

  /**
   * Limpiar cach√© de cliente (cuando se actualiza)
   */
  clearClientCache(clientId) {
    const cacheKey = `client_${clientId}`;
    clientCache.delete(cacheKey);
    logger.info(`üóëÔ∏è Cach√© limpiado para cliente ${clientId}`);
  }

  // Generar audio premium con Azure TTS (voces espa√±olas)
  async generatePremiumAudio(text, botConfig) {
    try {
      // Verificar si Azure TTS est√° configurado
      const hasAzure = azureTTSService.isConfigured();
      
      logger.info(`üîç DEBUG - Azure TTS configurado: ${hasAzure}`);
      
      if (hasAzure) {
        try {
          // Obtener y validar voz preferida del usuario (solo Lola o Dario)
          const requestedVoice = botConfig?.voiceSettings?.azureVoice || 'lola';
          const preferredVoice = this.validateAndGetVoice(requestedVoice);
          
          logger.info(`‚úÖ Generando audio con Azure TTS (${preferredVoice} - espa√±ol peninsular)...`);
          const result = await azureTTSService.generateBotResponse(text, preferredVoice);
          
          if (result.success) {
            logger.info('üéµ Audio Azure TTS generado exitosamente');
            return {
              success: true,
              audioUrl: result.audioUrl,
              provider: 'azure-tts',
              voice: preferredVoice,
              voiceInfo: result.voiceUsed,
              duration: result.durationEstimate
            };
          } else {
            throw new Error(result.error);
          }
        } catch (error) {
          logger.error(`Error generando audio Azure TTS: ${error.message}`);
          // Continuar con fallback a Polly
        }
      }
      
      // Fallback final: usar Polly (TwiML nativo)
      logger.info('üîä Usando Polly como fallback para bienvenida');
      return null; // Esto har√° que se use Polly en el TwiML
    } catch (error) {
      logger.error(`Error en generatePremiumAudio: ${error.message}`);
      return null;
    }
  }

  /**
   * DEPRECATED: Generar TwiML para dar la bienvenida al llamante
   * ‚ö†Ô∏è ESTA FUNCI√ìN EST√Å DEPRECATED - USAR generateCallResponse EN SU LUGAR
   */
  async generateWelcomeTwiml(botConfig) {
    logger.warn('‚ö†Ô∏è generateWelcomeTwiml est√° deprecated. Usar generateCallResponse con OpenAI Whisper.');
    return this.generateErrorTwiML('Funci√≥n deprecated. Contacta con soporte t√©cnico.');
    try {
      const VoiceResponse = twilio.twiml.VoiceResponse;
      const twiml = new VoiceResponse();
      
      // Obtener mensaje de bienvenida de la configuraci√≥n o usar uno predeterminado
      const welcomeMessage = botConfig?.greeting || botConfig?.welcomeMessage || 
        'Gracias por llamar. Por favor, indique su nombre y el motivo de su llamada.';
      
      // Configurar voiceSettings para Polly (siempre disponible como fallback)
      const voiceSettings = {
        voice: botConfig?.voice || 'Polly.Conchita',
        language: botConfig?.language || 'es-ES'
      };
      
      // Intentar generar audio premium primero
      const premiumAudioUrl = await this.generatePremiumAudio(welcomeMessage, botConfig);
      
      if (premiumAudioUrl) {
        // Usar audio premium de ElevenLabs
        twiml.play(premiumAudioUrl);
        logger.info('üé§ Usando voz premium de ElevenLabs para bienvenida');
      } else {
        // Fallback a Polly
        twiml.say(voiceSettings, welcomeMessage);
        logger.info('üîä Usando Polly como fallback para bienvenida');
      }
      
      // Recopilar la entrada del usuario (usando reconocimiento de voz)
      const gather = twiml.gather({
        input: 'speech dtmf',
        timeout: '5',
        speechTimeout: 'auto',
        language: botConfig?.language || 'es-ES',
        action: '/webhooks/gather',
        method: 'POST'
      });
      
      gather.say(voiceSettings, botConfig?.gatherPrompt || 
        'Por favor, indique su nombre y el motivo de su llamada despu√©s del tono.');
      
      // Si no hay respuesta, grabar mensaje
      twiml.record({
        action: '/webhooks/recording',
        method: 'POST',
        maxLength: '120',
        playBeep: true,
        transcribe: false,
        timeout: 5
      });
      
      twiml.say(voiceSettings, 'Gracias por su mensaje. Nos pondremos en contacto con usted lo antes posible.');
      twiml.hangup();
      
      return twiml;
    } catch (error) {
      logger.error(`Error generando Welcome TwiML: ${error.message}`);
      return this.generateErrorTwiml('Lo sentimos, ha ocurrido un error en el sistema.');
    }
  }
  
  // Generar respuesta basada en la entrada del usuario
  async generateGatherResponse(input, botConfig) {
    try {
      const VoiceResponse = twilio.twiml.VoiceResponse;
      const twiml = new VoiceResponse();
      
      // Configurar voz
      const voiceSettings = {
        voice: botConfig?.voice || 'Polly.Conchita',
        language: botConfig?.language || 'es-ES'
      };
      
      // Si tenemos entrada, agradecer y seguir con m√°s preguntas seg√∫n el flujo configurado
      if (input && input.trim().length > 0) {
        twiml.say(voiceSettings, 'Gracias por la informaci√≥n.');
        
        // Obtener el siguiente paso del flujo de la llamada
        const nextPrompt = botConfig?.followUpPrompt || 
          '¬øHay algo m√°s que le gustar√≠a a√±adir? Por favor, indique un n√∫mero de contacto si desea que nos comuniquemos con usted.';
        
        const gather = twiml.gather({
          input: 'speech dtmf',
          timeout: '5',
          speechTimeout: 'auto',
          language: botConfig?.language || 'es-ES',
          action: '/webhooks/gather',
          method: 'POST'
        });
        
        gather.say(voiceSettings, nextPrompt);
      } else {
        // Si no se detect√≥ entrada, volver a intentarlo
        const retryPrompt = botConfig?.retryPrompt || 
          'No he podido entenderle. Por favor, intente de nuevo.';
        
        const gather = twiml.gather({
          input: 'speech dtmf',
          timeout: '5',
          speechTimeout: 'auto',
          language: botConfig?.language || 'es-ES',
          action: '/webhooks/gather',
          method: 'POST'
        });
        
        gather.say(voiceSettings, retryPrompt);
      }
      
      // Si no hay respuesta despu√©s de los reintentos
      twiml.record({
        action: '/webhooks/recording',
        method: 'POST',
        maxLength: '120',
        playBeep: true,
        transcribe: false,
        timeout: 5
      });
      
      twiml.say(voiceSettings, botConfig?.goodbyeMessage || 
        'Gracias por contactar con nosotros. Su mensaje ha sido registrado y nos pondremos en contacto con usted lo antes posible.');
      twiml.hangup();
      
      return twiml;
    } catch (error) {
      logger.error(`Error generando Gather Response TwiML: ${error.message}`);
      return this.generateErrorTwiml('Lo sentimos, ha ocurrido un error en el sistema.');
    }
  }
  
  // Generar TwiML para errores
  generateErrorTwiml(message) {
    const VoiceResponse = twilio.twiml.VoiceResponse;
    const twiml = new VoiceResponse();
    
    twiml.say({
      voice: 'Polly.Conchita',
      language: 'es-ES'
    }, message || 'Ha ocurrido un error. Por favor, int√©ntelo de nuevo m√°s tarde.');
    
    twiml.hangup();
    return twiml;
  }
  
  // Comprar nuevo n√∫mero para un cliente
  async purchaseNumber(clientId, areaCode, capabilities) {
    try {
      // Buscar n√∫meros disponibles
      const searchParams = {
        areaCode: areaCode || '34', // Espa√±a por defecto
        capabilities: capabilities || { voice: true },
        limit: 1
      };
      
      const availableNumbers = await this.client.availablePhoneNumbers('ES')
                                               .local.list(searchParams);
      
      if (!availableNumbers || availableNumbers.length === 0) {
        throw new Error('No hay n√∫meros disponibles con los criterios especificados');
      }
      
      // Comprar el primer n√∫mero disponible
      const phoneNumberToBuy = availableNumbers[0].phoneNumber;
      const purchasedNumber = await this.client.incomingPhoneNumbers.create({
        phoneNumber: phoneNumberToBuy,
        friendlyName: `Cliente ${clientId}`,
        voiceUrl: `${process.env.TWILIO_WEBHOOK_BASE_URL}/webhooks/call/natural/${clientId}`,
        voiceMethod: 'POST',
        voiceFallbackUrl: `${process.env.TWILIO_WEBHOOK_BASE_URL}/webhooks/fallback`,
        voiceFallbackMethod: 'POST'
      });
      
      return {
        success: true,
        phoneNumber: purchasedNumber.phoneNumber,
        twilioSid: purchasedNumber.sid,
        friendlyName: purchasedNumber.friendlyName
      };
    } catch (error) {
      logger.error(`Error comprando n√∫mero Twilio: ${error.message}`);
      return {
        success: false,
        error: error.message
      };
    }
  }
  
  // Configurar webhooks para un n√∫mero existente
  async configureNumberWebhooks(twilioSid) {
    try {
      await this.client.incomingPhoneNumbers(twilioSid).update({
        voiceUrl: `${process.env.TWILIO_WEBHOOK_BASE_URL}/webhooks/call`,
        voiceMethod: 'POST',
        voiceFallbackUrl: `${process.env.TWILIO_WEBHOOK_BASE_URL}/webhooks/fallback`,
        voiceFallbackMethod: 'POST'
      });
      
      return {
        success: true,
        message: 'Webhooks configurados correctamente'
      };
    } catch (error) {
      logger.error(`Error configurando webhooks: ${error.message}`);
      return {
        success: false,
        error: error.message
      };
    }
  }
  
  // Liberar un n√∫mero (cuando un cliente cancela)
  async releaseNumber(twilioSid) {
    try {
      await this.client.incomingPhoneNumbers(twilioSid).remove();
      return {
        success: true,
        message: 'N√∫mero liberado correctamente'
      };
    } catch (error) {
      logger.error(`Error liberando n√∫mero: ${error.message}`);
      return {
        success: false,
        error: error.message
      };
    }
  }

  // ==========================================
  // SISTEMA DE IA NATURAL PARA LLAMADAS
  // ==========================================

  /**
   * Procesar llamada entrante con IA natural
   */
  async handleIncomingCallWithAI(clientId, callSid, from) {
    try {
      logger.info(`üìû Llamada entrante con IA - Cliente: ${clientId}, From: ${from}`);
      
      // Obtener configuraci√≥n del cliente
      const { PrismaClient } = require('@prisma/client');
      const prisma = new PrismaClient();
      
      const client = await prisma.client.findUnique({
        where: { id: parseInt(clientId) },
        select: {
          companyName: true,
          businessHoursConfig: true,
          voiceSettings: true,
          greetingMessage: true
        }
      });
      
      if (!client) {
        throw new Error('Cliente no encontrado');
      }
      
      // Generar mensaje de bienvenida natural
      const greetingMessage = client.callConfig?.greetingMessage || 
        `Hola, has llamado a ${client.companyName || 'nuestra empresa'}. Soy tu asistente, ¬øen qu√© puedo ayudarte?`;
      
      const naturalGreeting = makeTextNatural(greetingMessage, {
        sessionId: callSid,
        isGreeting: true
      });
      
      logger.info(`üéµ Mensaje de bienvenida natural: ${naturalGreeting}`);
      
      return {
        success: true,
        greeting: naturalGreeting,
        voiceSettings: getVoiceSettings(),
        clientConfig: client
      };
      
    } catch (error) {
      logger.error(`‚ùå Error procesando llamada con IA: ${error.message}`);
      return {
        success: false,
        error: error.message,
        greeting: "Hola, gracias por llamar. ¬øEn qu√© puedo ayudarte?",
        voiceSettings: getVoiceSettings()
      };
    }
  }

  /**
   * Procesar respuesta del usuario durante la llamada
   */
  async processCallResponse(clientId, callSid, userInput, context = {}) {
    try {
      logger.info(`üó£Ô∏è Procesando respuesta del usuario - Cliente: ${clientId}`);
      logger.info(`üë§ Usuario dijo: ${userInput}`);
      
      // A√±adir informaci√≥n del contexto de la llamada
      const enhancedContext = {
        ...context,
        from: context.from || context.phoneNumber,
        phoneNumber: context.from || context.phoneNumber
      };
      
      // Procesar con IA natural
      const aiResult = await processUserMessage(clientId, callSid, userInput, enhancedContext);
      
      if (!aiResult.success) {
        throw new Error(aiResult.error);
      }
      
      logger.info(`ü§ñ IA responde: ${aiResult.response}`);
      
      // Determinar si debe colgar autom√°ticamente
      const shouldHangup = aiResult.shouldHangup || this.isEndingConversation(aiResult.response);
      
      if (shouldHangup) {
        logger.info(`üìû Despedida detectada - La llamada se colgar√° autom√°ticamente`);
      }
      
      return {
        success: true,
        response: aiResult.response,
        voiceSettings: aiResult.voiceSettings,
        shouldContinue: !shouldHangup,
        shouldHangup: shouldHangup
      };
      
    } catch (error) {
      logger.error(`‚ùå Error procesando respuesta: ${error.message}`);
      
      const fallbackResponse = makeTextNatural(
        "Disculpa, no he entendido bien. ¬øPodr√≠as repetir lo que necesitas?",
        { sessionId: callSid, userInput: userInput }
      );
      
      return {
        success: false,
        response: fallbackResponse,
        voiceSettings: getVoiceSettings(),
        shouldContinue: true,
        shouldHangup: false,
        error: error.message
      };
    }
  }

  /**
   * DEPRECATED: Generar TwiML con personalidad natural y configuraci√≥n avanzada
   * ‚ö†Ô∏è ESTA FUNCI√ìN EST√Å DEPRECATED - USAR processUserAudio CON OPENAI WHISPER
   */
  async generateNaturalTwiML(clientId, message, context = {}) {
    logger.warn('‚ö†Ô∏è generateNaturalTwiML est√° deprecated. Usar processUserAudio con OpenAI Whisper.');
    return this.generateErrorTwiML('Funci√≥n deprecated. Contacta con soporte t√©cnico.');
    try {
      const twiml = new twilio.twiml.VoiceResponse();
      
      // Obtener configuraci√≥n del cliente
      const { PrismaClient } = require('@prisma/client');
      const prisma = new PrismaClient();
      
      const client = await prisma.client.findUnique({
        where: { id: parseInt(clientId) },
        select: {
          callConfig: true,
          language: true,
          companyName: true
        }
      });
      
      const voiceConfig = client?.callConfig?.voiceSettings || {};
      const language = client?.language || 'es-ES';
      
      // Procesar mensaje con personalidad natural
      const naturalMessage = makeTextNatural(message, {
        sessionId: context.callSid,
        needsConsulting: context.needsConsulting || false
      });
      
      logger.info(`üé≠ Mensaje natural generado: ${naturalMessage}`);
      
      // FORZAR uso de Azure TTS - NO usar OpenAI
      logger.info(`üéµ FORZANDO uso de Azure TTS para voz natural espa√±ola`);
      
      // Obtener voz preferida del usuario (por defecto: lola - voz femenina espa√±ola)
      const requestedVoice = voiceConfig?.azureVoice || 'lola';
      const preferredVoice = this.validateAndGetVoice(requestedVoice);
      logger.info(`üé≠ Usando voz Azure: ${preferredVoice}`);
      
      const audioResult = await this.generatePremiumAudio(naturalMessage, {
        voiceSettings: { azureVoice: preferredVoice },
        language: language
      });
      
      if (audioResult && audioResult.success) {
        // Usar audio premium de Azure TTS
        twiml.play(audioResult.audioUrl);
        logger.info(`üéµ ‚úÖ Audio Azure TTS generado: ${audioResult.provider} - ${audioResult.voice}`);
      } else {
        // Fallback a Polly SOLO si Azure falla
        const voiceSettings = getVoiceSettings();
        twiml.say({
          voice: this.getPollyVoiceForLanguage(language),
          language: language,
          rate: voiceSettings.rate || '0.9'
        }, naturalMessage);
        logger.info(`üîÑ Fallback a Polly (Azure no disponible)`);
      }
      
      // Continuar conversaci√≥n - SIEMPRE activa para interacci√≥n natural
      twiml.gather({
        input: 'speech',
        language: language,
        speechTimeout: 5,        // M√°s tiempo para responder
        timeout: 15,             // M√°s tiempo total
        action: `/webhooks/call/response/${clientId}`,
        method: 'POST',
        finishOnKey: '#'         // Permitir terminar con #
      });
      
      // Mensaje si no responde
      twiml.say({
        voice: this.getPollyVoiceForLanguage(language),
        language: language
      }, 'Si necesitas algo m√°s, puedes dec√≠rmelo. Estoy aqu√≠ para ayudarte.');
      
      return twiml;
      
    } catch (error) {
      logger.error(`‚ùå Error generando TwiML natural: ${error.message}`);
      return this.generateErrorTwiML(message);
    }
  }

  /**
   * Determinar si la conversaci√≥n deber√≠a terminar
   */
  isEndingConversation(response) {
    const endingKeywords = [
      'adi√≥s', 'hasta luego', 'gracias por llamar', 'que tengas buen d√≠a',
      'nos vemos', 'hasta pronto', 'fin de la llamada', 'colgar'
    ];
    
    const lowerResponse = response.toLowerCase();
    return endingKeywords.some(keyword => lowerResponse.includes(keyword));
  }

  /**
   * Obtener voz de Polly seg√∫n el idioma
   */
  getPollyVoiceForLanguage(language) {
    const voiceMap = {
      'es-ES': 'Polly.Conchita',
      'en-US': 'Polly.Joanna',
      'fr-FR': 'Polly.Celine',
      'de-DE': 'Polly.Marlene'
    };
    
    return voiceMap[language] || 'Polly.Conchita';
  }

  /**
   * Generar TwiML de error para manejo de fallos
   */
  generateErrorTwiML(errorMessage = 'Lo siento, ha ocurrido un error t√©cnico. Por favor, int√©ntalo de nuevo m√°s tarde.') {
    const twiml = new twilio.twiml.VoiceResponse();
    
    // Mensaje de error con voz natural
    twiml.say({
      voice: 'Polly.Conchita',
      language: 'es-ES'
    }, errorMessage);
    
    // Colgar despu√©s del mensaje
    twiml.hangup();
    
    logger.info(`üö® TwiML de error generado: ${errorMessage}`);
    return twiml.toString();
  }
}

module.exports = new TwilioService();
