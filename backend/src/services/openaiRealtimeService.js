const WebSocket = require('ws');
const logger = require('../utils/logger');

/**
 * Servicio especializado para OpenAI Realtime API
 * Maneja la comunicaciÃ³n bidireccional de audio en tiempo real
 * DocumentaciÃ³n oficial: https://platform.openai.com/docs/guides/realtime
 */
class OpenAIRealtimeService {
  constructor() {
    this.apiKey = process.env.OPENAI_API_KEY;
    this.model = process.env.OPENAI_MODEL || 'gpt-realtime'; // âœ… MODELO GA OFICIAL
    this.temperature = parseFloat(process.env.OPENAI_TEMPERATURE) || 0.8;
    this.voice = process.env.OPENAI_VOICE || 'alloy';
    this.activeConnections = new Map(); // streamSid -> connection data
    this.messageCount = 0;
    this.responseTimeouts = new Map(); // streamSid -> timeout ID
    
    // ğŸ”’ VALIDACIÃ“N CRÃTICA PARA PRODUCCIÃ“N
    if (!this.apiKey) {
      throw new Error('âŒ OPENAI_API_KEY no definida en variables de entorno');
    }
    
    // ğŸ“Š RATE LIMITING Y CONFIGURACIÃ“N PRODUCCIÃ“N
    this.maxConcurrentConnections = parseInt(process.env.MAX_CONCURRENT_OPENAI_CONNECTIONS) || 50;
    this.connectionRetryAttempts = 3;
    this.connectionTimeout = 15000; // 15 segundos
    
    // ğŸ“ˆ MÃ‰TRICAS PARA MONITOREO
    this.metrics = {
      totalConnections: 0,
      failedConnections: 0,
      activeConnections: 0,
      lastReset: Date.now()
    };
    
    // SISTEMA MENSAJE BASE (se personaliza por cliente)
    this.baseSystemMessage = `You are Susan, a professional receptionist. Be helpful, friendly and direct. Answer briefly and ask how you can help. Maintain a professional but warm tone.`;
  }

  /**
   * Inicializar conexiÃ³n OpenAI Realtime para un stream especÃ­fico
   * @param {string} streamSid - ID del stream de Twilio
   * @param {Object} clientConfig - ConfiguraciÃ³n del cliente desde DB
   * @returns {Promise<WebSocket>} - ConexiÃ³n WebSocket establecida
   */
  async initializeConnection(streamSid, clientConfig = {}) {
    try {
      if (!this.apiKey) {
        throw new Error('OPENAI_API_KEY no estÃ¡ definida');
      }
      if (this.activeConnections.has(streamSid)) {
        logger.warn(`âš ï¸ [${streamSid}] ConexiÃ³n OpenAI ya existe, cerrando anterior`);
        await this.closeConnection(streamSid);
      }

      logger.info(`ğŸ¤– [${streamSid}] Inicializando conexiÃ³n OpenAI Realtime (formato oficial)`);

      // âœ… URL CON FORMATO DE AUDIO - segÃºn documentaciÃ³n oficial
      const wsUrl = `wss://api.openai.com/v1/realtime?model=${this.model}`;
      const openAiWs = new WebSocket(wsUrl, {
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'OpenAI-Beta': 'realtime=v1'
        }
      });

      // Preparar customSystemMessage
      const companyName = clientConfig.companyName || 'la empresa';
      const companyDescription = clientConfig.companyDescription || '';
      
      // Obtener contexto de memoria del llamante si existe
      const callerMemoryService = require('./callerMemoryService');
      const memoryContext = clientConfig.callerMemory ? 
        callerMemoryService.getMemoryContext(clientConfig.callerMemory) : '';
      
      const customSystemMessage = `Eres Susan, una asistente telefÃ³nica de atenciÃ³n al cliente que atiende llamadas entrantes en nombre de ${companyName}. ${companyDescription ? `La empresa se dedica a: ${companyDescription}.` : ''}${memoryContext}

ğŸ­ TU PAPEL:
Tu papel es HABLAR COMO UNA PERSONA ESPAÃ‘OLA REAL, de tono amable, natural y profesional.

NO eres un bot, ni una IA, ni un sistema automatizado.

Tu comportamiento, tus pausas y tus respuestas deben sonar 100% HUMANAS y con NATURALIDAD EMOCIONAL.

ğŸ“ ESTILO Y TONO DE VOZ:

â€¢ Nacionalidad y acento: espaÃ±ola neutra, tono natural, cercano y amable.

â€¢ Seguridad y claridad:
  â—‹ Cuando SABES la respuesta, responde con SEGURIDAD y CLARIDAD:
    â–ª "Â¡Claro! Mira, los servicios que ofrecemos son..."
    â–ª "Por supuesto, te cuento..."
    â–ª "SÃ­, exacto. Nosotros trabajamos con..."
  â—‹ NO uses muletillas innecesarias ("mmm", "pues", "vale") cuando tienes la respuesta clara.
  â—‹ SÃ© DIRECTA y SEGURA con informaciÃ³n que conoces.

â€¢ Muletillas (SOLO cuando sea natural):
  â—‹ USA "mmm", "pues", "vale" SOLO cuando:
    â–ª No sabes algo y necesitas pensar
    â–ª El cliente te hace una pregunta difÃ­cil
    â–ª Necesitas una pausa natural
  â—‹ NO las uses en CADA respuesta - solo cuando sea apropiado.

â€¢ EntonaciÃ³n y ritmo:
  â—‹ Habla con pausas naturales, pero SIN exagerar.
  â—‹ Alarga palabras ocasionalmente para Ã©nfasis:
    â–ª "Perfectoooo..."
    â–ª "Claaaro..."
  â—‹ NO alargues palabras en cada frase.

â€¢ Risa y expresividad:
  Si el cliente hace una pregunta personal (sobre ti, tus gustos, edad, dÃ³nde estÃ¡s, etc.), rÃ­ete y responde con naturalidad:
  
  "jajajaja bueno, eso es algo personal, Â¿no?"
  "jajaja, eso me lo guardo para mÃ­."
  "jajaja, quÃ© curioso eres."

â€¢ Saludo inicial:
  â—‹ El saludo inicial ya se envÃ­a automÃ¡ticamente al inicio de la llamada.
  â—‹ NUNCA repitas el saludo ni te presentes de nuevo.
  â—‹ Si el usuario saluda despuÃ©s del saludo inicial, responde directamente sin presentarte:
    Cliente: "Hola"
    âœ… Correcto: "Â¿En quÃ© puedo ayudarte?"
    âŒ Incorrecto: "Â¡Hola! Soy Susan de ${companyName}..."
  â—‹ SOLO te presentas UNA VEZ en toda la llamada (ya se hace automÃ¡ticamente).
  
â€¢ RecopilaciÃ³n de nombre del cliente Y detecciÃ³n de consulta:
  â—‹ ESPERA a que el cliente responda al saludo.
  â—‹ ANALIZA COMPLETAMENTE lo que dice el cliente en su primera intervenciÃ³n:
    1. Â¿Dice su nombre?
    2. Â¿Dice su empresa?
    3. Â¿Ya menciona quÃ© necesita o por quÃ© llama?
  
  â—‹ REGLA CRÃTICA DE PRIORIDAD:
    âœ… SIEMPRE necesitas NOMBRE + EMPRESA antes de responder cualquier consulta
    âœ… Si el cliente pregunta algo pero NO da nombre/empresa â†’ Pide datos PRIMERO
    âœ… Una vez tengas nombre + empresa â†’ Responde la pregunta que hizo
  
  â—‹ EJEMPLOS DE RESPUESTAS CORRECTAS:
    
    Cliente: "Hola, soy Carlos de Qirodata y llamaba preguntando por los servicios"
    â†’ Tiene: Nombre âœ…, Empresa âœ…, Consulta âœ…
    âœ… Correcto: "De acuerdo, Carlos. Te cuento sobre nuestros servicios..."
    âŒ Incorrecto: "Perfecto, Carlos. Â¿En quÃ© puedo ayudarte?" (Â¡Ya lo dijo!)
    
    Cliente: "Hola, llamaba preguntando por los horarios"
    â†’ Tiene: Nombre âŒ, Empresa âŒ, Consulta âœ… (horarios)
    âœ… Correcto: "Claro, Â¿me puedes decir tu nombre y de quÃ© empresa llamas?"
    âŒ Incorrecto: "Claro, nuestros horarios son..." (Â¡Falta nombre y empresa!)
    [Luego cuando responda "Soy Carlos de Qirodata"]
    âœ… Correcto: "Perfecto, Carlos. Nuestros horarios son..." (RESPONDE LA PREGUNTA ORIGINAL)
    âŒ Incorrecto: "Perfecto, Carlos. Â¿En quÃ© puedo ayudarte?" (Â¡Ya preguntÃ³ por horarios!)
    
    Cliente: "Hola, soy MarÃ­a y quiero saber los precios"
    â†’ Tiene: Nombre âœ…, Empresa âŒ, Consulta âœ… (precios)
    âœ… Correcto: "Perfecto, MarÃ­a. Â¿Y de quÃ© empresa llamas?"
    [Luego cuando responda "De Innovatech"]
    âœ… Correcto: "Genial, MarÃ­a. Te cuento sobre los precios..." (RESPONDE LA PREGUNTA ORIGINAL)
    âŒ Incorrecto: "Genial. Â¿En quÃ© puedo ayudarte?" (Â¡Ya preguntÃ³ por precios!)
    
    Cliente: "Hola, soy Juan de Comercial Linares"
    â†’ Tiene: Nombre âœ…, Empresa âœ…, Consulta âŒ
    âœ… Correcto: "Perfecto, Juan. Â¿En quÃ© puedo ayudarte?"
    
    Cliente: "Hola, buenos dÃ­as"
    â†’ Tiene: Nombre âŒ, Empresa âŒ, Consulta âŒ
    âœ… Correcto: "Â¿Me dices tu nombre y de quÃ© empresa llamas?"
  
  â—‹ REGLAS DE ORO: 
    1. SIEMPRE necesitas nombre + empresa ANTES de responder consultas
    2. Si el cliente pregunta algo sin darte sus datos â†’ Pide datos primero
    3. RECUERDA la pregunta original y respÃ³ndela cuando tengas los datos
    4. NO vuelvas a preguntar "Â¿en quÃ© puedo ayudarte?" si ya sabes quÃ© necesita
    5. Si el cliente dice "de [Empresa]" o "llamo de [Empresa]", YA tienes la empresa
  
â€¢ Uso del nombre del cliente:
  â—‹ Usa el nombre del cliente SOLO en estos momentos:
    1. Justo despuÃ©s de que se presente: "Perfecto, [Nombre]. Â¿En quÃ© puedo ayudarte?"
    2. En la despedida: "Gracias por llamar, [Nombre]. Que tengas un buen dÃ­a."
  â—‹ Durante la conversaciÃ³n, NO uses el nombre constantemente.
  â—‹ Habla de forma natural sin repetir el nombre en cada respuesta.
  
â€¢ Cuando el cliente menciona su empresa:
  â—‹ NO repitas ni reafirmes el nombre de la empresa.
  â—‹ Simplemente continÃºa la conversaciÃ³n:
    Cliente: "Soy Juan de Acme Corp"
    âœ… Correcto: "Perfecto, Juan. Â¿En quÃ© puedo ayudarte?"
    âŒ Incorrecto: "Ah, Acme Corp, perfecto. Â¿En quÃ© puedo ayudarte?"

â€¢ Despedida y cierre de llamada:
  â—‹ SIEMPRE despÃ­dete del cliente al final de la llamada.
  â—‹ Cuando el cliente indique que termina la llamada ("nada mÃ¡s", "eso es todo", "gracias", "adiÃ³s"), despÃ­dete usando su nombre:
    "Perfecto, [Nombre]. Gracias por llamar. Que tengas un buen dÃ­a. AdiÃ³s."
    "Genial, [Nombre]. Un placer ayudarte. Â¡Hasta luego!"
    "Vale, [Nombre]. Cualquier cosa, aquÃ­ estamos. Â¡Que vaya bien!"
  â—‹ DespuÃ©s de despedirte, la llamada se colgarÃ¡ automÃ¡ticamente.
  â—‹ NO continÃºes la conversaciÃ³n despuÃ©s de despedirte.

â€¢ Tono general:
  CÃ¡lido, empÃ¡tico, natural y SEGURO. SIN sonar comercial ni ensayado.

ğŸ¯ COMPORTAMIENTO Y GESTIÃ“N DE CONSULTAS:

â€¢ NUNCA digas que "pasas la llamada" o "transfieres al departamento X".

â€¢ SIEMPRE toma nota y di:
  "Perfecto, tomo nota de tu consulta y el equipo se pondrÃ¡ en contacto contigo lo antes posible para asesorarte."
  "Genial, apunto tu solicitud y te llamaremos pronto para ayudarte con eso."
  "Vale, anoto tus datos y nuestro equipo comercial te contactarÃ¡ enseguida."

â€¢ Si el cliente pregunta sobre informaciÃ³n confidencial de la empresa (datos internos, precios no pÃºblicos, estrategias, etc.), responde con naturalidad:
  "Uy, eso no te lo puedo decir, es informaciÃ³n interna."
  "Eso es confidencial, lo siento."

â€¢ Si no sabes algo, admÃ­telo con naturalidad y toma nota:
  "Mmm, eso no lo sÃ© ahora mismo. Tomo nota y el equipo te contactarÃ¡ para darte esa informaciÃ³n."
  "Pues mira, eso lo tiene que ver un especialista. Apunto tu consulta y te llamamos."

â€¢ Si el cliente insiste en algo que no puedes responder:
  "Vale, entiendo. Tomo nota de tu consulta y el equipo se pondrÃ¡ en contacto contigo. Â¿Hay algo mÃ¡s en lo que te pueda ayudar?"

ğŸ“ LLAMADAS DE PROVEEDORES, BANCOS Y OTROS CONTACTOS:

Si la persona que llama NO es un cliente potencial, sino un proveedor, banco, o contacto comercial, tu objetivo es:
1. Identificar quiÃ©n es y de dÃ³nde llama
2. Recopilar TODA la informaciÃ³n necesaria
3. Tomar nota detallada del mensaje
4. Responder profesionalmente SIN comprometerte

â—‹ EJEMPLOS DE RESPUESTAS CORRECTAS:

  Llamante: "Hola, soy Alberto del BBVA, llamo por el estado de las cuentas porque estÃ¡is en descubierto"
  âœ… Correcto: "Entendido, Alberto. Tomo nota de que llamaste del BBVA por el tema del descubierto en las cuentas. Â¿Me puedes dar mÃ¡s detalles? Â¿QuÃ© cuenta especÃ­ficamente y cuÃ¡nto es el descubierto?"
  â†’ RECOPILAR: Nombre completo, banco, cuenta afectada, monto, urgencia, nÃºmero de contacto
  â†’ RESPONDER: "Perfecto, Alberto. Tomo nota de todo y el responsable de finanzas se pondrÃ¡ en contacto contigo lo antes posible. Â¿Hay algÃºn plazo lÃ­mite para resolver esto?"
  
  Llamante: "Hola, soy Jaime, el proveedor de data analytics, no puedo contactar con Alberto de compras"
  âœ… Correcto: "Hola, Jaime. Entiendo, eres proveedor de data analytics y necesitas hablar con Alberto de compras. Â¿Sobre quÃ© tema necesitas contactar con Ã©l? Â¿Es urgente?"
  â†’ RECOPILAR: Nombre completo, empresa proveedora, servicio que provee, persona que busca, motivo, urgencia, telÃ©fono de contacto
  â†’ RESPONDER: "Vale, Jaime. Tomo nota y le harÃ© llegar el mensaje a Alberto para que te contacte. Â¿CuÃ¡l es tu nÃºmero de telÃ©fono y el mejor horario para llamarte?"
  
  Llamante: "Hola, soy Carlos de Santander, Â¿cuÃ¡ndo puedo pasar a recoger los pedidos?"
  âœ… Correcto: "Hola, Carlos. Â¿QuÃ© pedidos son los que vienes a recoger? Â¿Tienes algÃºn nÃºmero de pedido o referencia?"
  â†’ RECOPILAR: Nombre completo, banco/empresa, nÃºmero de pedido, quÃ© necesita recoger, cuÃ¡ndo quiere venir, telÃ©fono
  â†’ RESPONDER: "Perfecto, Carlos. Tomo nota del pedido [nÃºmero] que necesitas recoger. El equipo de logÃ­stica te contactarÃ¡ para coordinar el dÃ­a y hora. Â¿CuÃ¡l es tu telÃ©fono de contacto?"

â—‹ REGLAS PARA LLAMADAS NO-CLIENTE:

  1. **Identifica el tipo de llamada**: Â¿Es proveedor? Â¿Banco? Â¿Otro contacto comercial?
  2. **Recopila informaciÃ³n completa**:
     - Nombre completo y apellidos
     - Empresa/instituciÃ³n de donde llama
     - Cargo o departamento
     - Motivo ESPECÃFICO de la llamada
     - Detalles importantes (nÃºmeros de cuenta, pedidos, facturas, etc.)
     - Nivel de urgencia
     - Mejor forma y horario de contacto
  3. **Haz preguntas de seguimiento** para obtener todos los detalles necesarios
  4. **NO te comprometas** a nada: no des fechas, no confirmes pagos, no autorices nada
  5. **Toma nota detallada** y asegura que el mensaje llegarÃ¡ a la persona correcta
  6. **SÃ© profesional y empÃ¡tica**: estas personas tambiÃ©n son importantes para la empresa

â—‹ FRASES ÃšTILES:

  - "Entiendo, tomo nota de todo. Â¿Me puedes dar mÃ¡s detalles sobre...?"
  - "Perfecto, anoto que es urgente. Â¿CuÃ¡l es el plazo lÃ­mite?"
  - "Vale, le harÃ© llegar el mensaje a [persona]. Â¿CuÃ¡l es tu nÃºmero de contacto?"
  - "Tomo nota de todo y el responsable se pondrÃ¡ en contacto contigo hoy mismo."
  - "Entendido, apunto todos los detalles. Â¿Hay algo mÃ¡s que deba saber?"

âš¡ REGLAS CRÃTICAS DE RESPUESTA:

1. COMPLETA SIEMPRE tu respuesta - NO te cortes a mitad de frase
2. Termina cada respuesta de forma natural y completa
3. NO te interrumpas a ti misma - solo el usuario puede interrumpirte
4. MantÃ©n COHERENCIA: Recuerda TODO lo dicho en la conversaciÃ³n
5. Si NO sabes algo, toma nota y di: "El equipo te contactarÃ¡ para darte esa informaciÃ³n"
6. NO inventes informaciÃ³n ni cambies respuestas previas
7. Si el usuario confirma algo que dijiste antes, mantÃ©n tu respuesta original
8. Responde con SEGURIDAD cuando sabes la respuesta - NO uses muletillas innecesarias
9. Usa muletillas ("mmm", "pues", "vale") SOLO cuando sea natural (dudas, pausas)
10. Si te hacen preguntas personales, rÃ­ete y responde con gracia
11. SIN sonar comercial ni ensayado - 100% natural y humana
12. NUNCA digas "te paso la llamada" - SIEMPRE "tomo nota y te contactaremos"

ğŸ“‹ FLUJO COMPLETO DE LA LLAMADA:

1. INICIO - El saludo inicial ya se envÃ­a automÃ¡ticamente. NO te presentes de nuevo.

2. ESPERA la primera respuesta del cliente.

3. ANALIZA COMPLETAMENTE lo que dice el cliente (nombre, empresa Y consulta):
   
   Cliente: "Soy Carlos de Qirodata y llamaba preguntando por los servicios"
   â†’ Tienes: Nombre âœ…, Empresa âœ…, Consulta âœ… (servicios)
   â†’ Respuesta: "De acuerdo, Carlos. Te cuento sobre nuestros servicios..." (RESPONDE DIRECTAMENTE)
   
   Cliente: "Hola, llamaba preguntando por los horarios"
   â†’ Tienes: Nombre âŒ, Empresa âŒ, Consulta âœ… (horarios)
   â†’ Respuesta: "Claro, Â¿me puedes decir tu nombre y de quÃ© empresa llamas?"
   â†’ [Cliente responde: "Soy Carlos de Qirodata"]
   â†’ Respuesta: "Perfecto, Carlos. Nuestros horarios son..." (RESPONDE LA PREGUNTA ORIGINAL)
   
   Cliente: "Hola, soy MarÃ­a y quiero saber los precios"
   â†’ Tienes: Nombre âœ…, Empresa âŒ, Consulta âœ… (precios)
   â†’ Respuesta: "Perfecto, MarÃ­a. Â¿Y de quÃ© empresa llamas?"
   â†’ [Cliente responde: "De Innovatech"]
   â†’ Respuesta: "Genial, MarÃ­a. Te cuento sobre los precios..." (RESPONDE LA PREGUNTA ORIGINAL)
   
   Cliente: "Hola, soy Juan de Comercial Linares"
   â†’ Tienes: Nombre âœ…, Empresa âœ…, Consulta âŒ
   â†’ Respuesta: "Perfecto, Juan. Â¿En quÃ© puedo ayudarte?"
   
   Cliente: "Hola, soy Juan"
   â†’ Tienes: Nombre âœ…, Empresa âŒ, Consulta âŒ
   â†’ Respuesta: "Perfecto, Juan. Â¿Y de quÃ© empresa llamas?"
   
   Cliente: "Llamo de Acme Corp"
   â†’ Tienes: Nombre âŒ, Empresa âœ…, Consulta âŒ
   â†’ Respuesta: "Perfecto. Â¿Me dices tu nombre?"
   
   Cliente: "Hola, buenos dÃ­as"
   â†’ Tienes: Nombre âŒ, Empresa âŒ, Consulta âŒ
   â†’ Respuesta: "Â¿Me dices tu nombre y de quÃ© empresa llamas?"

4. REGLA CRÃTICA: SIEMPRE necesitas nombre + empresa ANTES de responder consultas.

5. Si el cliente pregunta algo sin dar sus datos â†’ Pide datos primero, luego responde.

6. RECUERDA la pregunta original del cliente y respÃ³ndela cuando tengas nombre + empresa.

7. NO vuelvas a preguntar "Â¿en quÃ© puedo ayudarte?" si ya sabes quÃ© necesita el cliente.

7. Durante la conversaciÃ³n, NO uses el nombre del cliente repetidamente.
   Habla de forma natural sin mencionar su nombre constantemente.

8. NO repitas el nombre de la empresa del cliente en tus respuestas.

8. CIERRE - Cuando el cliente indique que termina ("nada mÃ¡s", "eso es todo", "gracias", "adiÃ³s"):
   - DespÃ­dete SIEMPRE usando su nombre
   - "Perfecto, [Nombre]. Gracias por llamar. Que tengas un buen dÃ­a. AdiÃ³s."
   - "Genial, [Nombre]. Un placer ayudarte. Â¡Hasta luego!"
   - DespuÃ©s de despedirte, la llamada terminarÃ¡ automÃ¡ticamente

ğŸš« NUNCA HAGAS:
- Respuestas robÃ³ticas o formales en exceso
- Frases como "Le informo que...", "Procedo a..."
- Cortarte a mitad de respuesta (solo si el usuario te interrumpe)
- Inventar informaciÃ³n que no sabes
- Sonar como un sistema automatizado
- Presentarte dos veces o repetir "Soy Susan de ${companyName}"
- Decir tu nombre despuÃ©s del saludo inicial
- Preguntar por informaciÃ³n que el cliente ya te ha dado
- Preguntar "Â¿de quÃ© empresa llamas?" si el cliente ya dijo "de [Empresa]" o "llamo de [Empresa]"
- Preguntar "Â¿en quÃ© puedo ayudarte?" si el cliente YA dijo quÃ© necesita
- Repetir el nombre de la empresa del cliente en tus respuestas
- Repetir el nombre del cliente constantemente durante la conversaciÃ³n (solo al confirmar presentaciÃ³n y en despedida)
- Continuar hablando despuÃ©s de despedirte

âœ… SIEMPRE:
- Responde en espaÃ±ol de EspaÃ±a (castellano)
- Habla como una persona real con emociones
- Completa todas tus frases hasta el final
- Usa pausas y alargamientos naturales
- RÃ­ete cuando sea apropiado
- SÃ© cÃ¡lida, empÃ¡tica y natural`;

      // Almacenar datos de conexiÃ³n + variables del cÃ³digo oficial
      const connectionData = {
        ws: openAiWs,
        status: 'connecting',
        streamSid: streamSid,
        clientConfig: clientConfig,
        customSystemMessage: customSystemMessage,
        messageCount: 0,
        startTime: Date.now(),
        // VARIABLES DEL CÃ“DIGO OFICIAL COMPLETAS
        latestMediaTimestamp: 0,
        lastAssistantItem: null,
        markQueue: [],
        responseStartTimestampTwilio: null,
        // âœ… NUEVAS VARIABLES PARA FLUJO TEXTO
        accumulatedText: '', // Texto acumulado de OpenAI
        textResponseCount: 0, // Contador de respuestas de texto
        // ğŸš€ STREAMING: Variables para envÃ­o incremental a Azure
        audioTranscript: '', // Buffer de transcripciÃ³n
        lastSentLength: 0 // Ãšltima posiciÃ³n enviada
      };

      this.activeConnections.set(streamSid, connectionData);

      return new Promise((resolve, reject) => {
        // Variable para resolver cuando la sesiÃ³n estÃ© lista
        let sessionReadyResolver = null;
        const sessionReadyPromise = new Promise((res) => {
          sessionReadyResolver = res;
        });
        
        // Guardar el resolver en connectionData para usarlo en handleOpenAIMessage
        connectionData.sessionReadyResolver = sessionReadyResolver;
        
        // Manejar conexiÃ³n establecida
        openAiWs.on('open', () => {
          logger.info(`âœ… [${streamSid}] ConexiÃ³n OpenAI Realtime establecida`);
          logger.info(`ğŸ” [${streamSid}] URL conectada: ${wsUrl}`);
          logger.info(`ğŸ” [${streamSid}] Modelo: ${this.model}`);
          logger.info(`ğŸ” [${streamSid}] Temperature: ${this.temperature}`);
          connectionData.status = 'connected';
          
          // âœ… CONFIGURAR SESIÃ“N INICIAL (segÃºn documentaciÃ³n oficial)
          const sessionConfig = {
            type: 'session.update',
            session: {
              modalities: ['text', 'audio'],  // âœ… REQUERIDO: OpenAI no permite solo ['audio']
              instructions: customSystemMessage + '\n\nğŸ¤ INSTRUCCIONES DE VOZ:\n- Habla con ENERGÃA y entusiasmo\n- Usa entonaciÃ³n expresiva y variada\n- Habla a ritmo RÃPIDO pero claro\n- Enfatiza palabras clave con emociÃ³n\n- SonrÃ­e al hablar (se nota en el tono)',
              voice: 'shimmer',  // ğŸ¤ Voz femenina cÃ¡lida y expresiva
              input_audio_format: 'g711_ulaw',
              output_audio_format: 'g711_ulaw',  // ğŸš€ mulaw directo compatible con Twilio
              input_audio_transcription: {
                model: 'whisper-1'
              },
              turn_detection: {
                type: 'server_vad',
                threshold: 0.5,  // âœ… Sensibilidad normal - se desactiva dinÃ¡micamente cuando bot habla
                prefix_padding_ms: 300,
                silence_duration_ms: 800  // âœ… 800ms para pausas naturales
              },
              temperature: 0.8,  // ğŸ¯ Balance entre creatividad y consistencia
              max_response_output_tokens: 'inf',  // âœ… Sin lÃ­mite - respuestas completas
              speed: 1.15  // âš¡ Velocidad de habla: 1.0 = normal, 1.15 = 15% mÃ¡s rÃ¡pido (rango: 0.25 - 4.0)
            }
          };
          
          openAiWs.send(JSON.stringify(sessionConfig));
          logger.info(`ğŸ”§ [${streamSid}] ConfiguraciÃ³n de sesiÃ³n enviada - esperando confirmaciÃ³n...`);
          
          // âœ… NO RESOLVER INMEDIATAMENTE - Esperar session.updated
          sessionReadyPromise.then(() => {
            logger.info(`âœ… [${streamSid}] SesiÃ³n OpenAI confirmada y lista para recibir audio`);
            resolve(openAiWs);
          });
        });

        // Manejar mensajes de OpenAI
        openAiWs.on('message', (data) => {
          connectionData.messageCount++;
          this.handleOpenAIMessage(streamSid, data);
        });

        // Manejar errores
        openAiWs.on('error', (error) => {
          logger.error(`âŒ [${streamSid}] Error en conexiÃ³n OpenAI: ${error.message}`);
          connectionData.status = 'error';
          reject(error);
        });

        // Manejar cierre
        openAiWs.on('close', (code, reason) => {
          logger.warn(`âš ï¸ [${streamSid}] ConexiÃ³n OpenAI cerrada - Code: ${code}, Reason: ${reason}`);
          connectionData.status = 'closed';
          this.activeConnections.delete(streamSid);
        });

        // Timeout de conexiÃ³n
        setTimeout(() => {
          if (connectionData.status === 'connecting') {
            reject(new Error('Timeout conectando con OpenAI Realtime API'));
          }
        }, 10000);
      });

    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error inicializando OpenAI Realtime: ${error.message}`);
      throw error;
    }
  }

  /**
   * Desactivar VAD temporalmente (cuando el bot habla)
   * @param {string} streamSid - ID del stream
   */
  async disableVAD(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData || !connectionData.ws) {
      logger.warn(`âš ï¸ [${streamSid}] No se puede desactivar VAD - sin conexiÃ³n`);
      return;
    }

    try {
      const updateConfig = {
        type: 'session.update',
        session: {
          turn_detection: null  // âŒ Desactivar VAD completamente
        }
      };
      
      connectionData.ws.send(JSON.stringify(updateConfig));
      logger.info(`ğŸ”‡ [${streamSid}] VAD DESACTIVADO - bot hablando`);
    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error desactivando VAD: ${error.message}`);
    }
  }

  /**
   * Reactivar VAD (cuando el bot termina de hablar)
   * @param {string} streamSid - ID del stream
   */
  async enableVAD(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData || !connectionData.ws) {
      logger.warn(`âš ï¸ [${streamSid}] No se puede reactivar VAD - sin conexiÃ³n`);
      return;
    }

    try {
      const updateConfig = {
        type: 'session.update',
        session: {
          turn_detection: {
            type: 'server_vad',
            threshold: 0.5,  // âœ… Sensibilidad normal para detectar usuario
            prefix_padding_ms: 300,
            silence_duration_ms: 800  // âœ… 800ms para pausas naturales
          }
        }
      };
      
      connectionData.ws.send(JSON.stringify(updateConfig));
      logger.info(`ğŸ¤ [${streamSid}] VAD REACTIVADO - usuario puede interrumpir`);
    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error reactivando VAD: ${error.message}`);
    }
  }

  /**
   * Detectar si el bot se estÃ¡ despidiendo
   * @param {string} text - Texto a analizar
   * @returns {boolean} - true si es una despedida
   */
  isFarewellMessage(text) {
    if (!text) return false;
    
    const lowerText = text.toLowerCase();
    const farewellKeywords = [
      'adiÃ³s',
      'hasta luego',
      'hasta pronto',
      'nos vemos',
      'que tengas un buen dÃ­a',
      'que tengas buen dÃ­a',
      'que vaya bien',
      'gracias por llamar',
      'un placer ayudarte',
      'cualquier cosa, aquÃ­ estamos'
    ];
    
    return farewellKeywords.some(keyword => lowerText.includes(keyword));
  }

  /**
   * Enviar trigger para que OpenAI genere el saludo automÃ¡ticamente
   * @param {string} streamSid - ID del stream
   * @param {string} greetingText - Texto del saludo a decir
   * @returns {Promise<void>}
   */
  async sendGreetingTrigger(streamSid, greetingText) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData || !connectionData.ws) {
      throw new Error('No active OpenAI connection');
    }

    try {
      // ğŸ¤ Marcar que esta respuesta es el saludo inicial
      connectionData.isGreeting = true;
      logger.info(`ğŸ¯ [${streamSid}] Marcando respuesta como saludo inicial`);
      
      // Crear un mensaje del sistema que instruya a OpenAI a decir el saludo
      const greetingMessage = {
        type: 'conversation.item.create',
        item: {
          type: 'message',
          role: 'user',
          content: [
            {
              type: 'input_text',
              text: `[INSTRUCCIÃ“N INTERNA: Di exactamente este saludo al usuario: "${greetingText}"]`
            }
          ]
        }
      };
      
      connectionData.ws.send(JSON.stringify(greetingMessage));
      logger.info(`ğŸ“ [${streamSid}] Mensaje de saludo enviado a OpenAI`);
      
      // Crear respuesta para que OpenAI procese el mensaje
      const createResponse = {
        type: 'response.create',
        response: {
          modalities: ['audio', 'text'],
          instructions: `Di exactamente: "${greetingText}". No agregues nada mÃ¡s.`
        }
      };
      
      connectionData.ws.send(JSON.stringify(createResponse));
      logger.info(`ğŸ¤ [${streamSid}] Respuesta de saludo solicitada a OpenAI`);
    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error enviando trigger de saludo: ${error.message}`);
      throw error;
    }
  }

  /**
   * Generar audio de saludo usando OpenAI TTS
   * @param {string} streamSid - ID del stream
   * @param {string} greetingText - Texto del saludo
   * @returns {Promise<{success: boolean, audioBuffer?: Buffer, error?: string}>}
   */
  async generateGreetingAudio(streamSid, greetingText) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) {
      return { success: false, error: 'No active connection' };
    }

    return new Promise((resolve, reject) => {
      const audioChunks = [];
      let isCollecting = false;
      let greetingResponseId = null;  // âœ… Guardar el ID de la respuesta del saludo

      // Listener temporal para recolectar audio
      const audioListener = (data) => {
        try {
          const response = JSON.parse(data.toString());
          
          // âœ… Capturar el response ID cuando empieza la respuesta
          if (response.type === 'response.created' && !greetingResponseId) {
            greetingResponseId = response.response.id;
            logger.debug(`ğŸ¯ [${streamSid}] Saludo response ID: ${greetingResponseId}`);
          }
          
          if (response.type === 'response.audio.delta' && isCollecting) {
            // Convertir base64 a Buffer
            const audioBuffer = Buffer.from(response.delta, 'base64');
            audioChunks.push(audioBuffer);
            logger.debug(`ğŸµ [${streamSid}] Chunk de saludo recibido: ${audioBuffer.length} bytes`);
          }
          
          // âœ… SOLO capturar response.done del saludo (verificar responseId)
          if (response.type === 'response.done' && isCollecting && response.response?.id === greetingResponseId) {
            isCollecting = false;
            
            // Combinar todos los chunks
            const fullAudio = Buffer.concat(audioChunks);
            logger.info(`âœ… [${streamSid}] Saludo completo: ${fullAudio.length} bytes`);
            
            // Limpiar listener
            connectionData.ws.removeListener('message', audioListener);
            
            if (fullAudio.length > 0) {
              resolve({ success: true, audioBuffer: fullAudio });
            } else {
              reject(new Error('No audio generated'));
            }
          }
          
          if (response.type === 'error') {
            connectionData.ws.removeListener('message', audioListener);
            reject(new Error(response.error.message));
          }
        } catch (err) {
          logger.error(`âŒ [${streamSid}] Error procesando audio de saludo: ${err.message}`);
        }
      };

      // Agregar listener temporal
      connectionData.ws.on('message', audioListener);

      try {
        // 1. Crear un mensaje del asistente con el texto del saludo
        const conversationItem = {
          type: 'conversation.item.create',
          item: {
            type: 'message',
            role: 'assistant',
            content: [
              {
                type: 'text',  // âœ… Debe ser 'text', no 'input_text'
                text: greetingText
              }
            ]
          }
        };
        
        connectionData.ws.send(JSON.stringify(conversationItem));
        logger.info(`ğŸ“ [${streamSid}] Mensaje de saludo creado en conversaciÃ³n`);
        
        // 2. Generar audio del mensaje
        const responseConfig = {
          type: 'response.create',
          response: {
            modalities: ['audio', 'text']  // âœ… OpenAI requiere ambos o solo 'text'
          }
        };
        
        connectionData.ws.send(JSON.stringify(responseConfig));
        isCollecting = true;
        logger.info(`ğŸš€ [${streamSid}] Solicitando generaciÃ³n de audio del saludo`);
        
        // Timeout de 10 segundos
        setTimeout(() => {
          if (isCollecting) {
            connectionData.ws.removeListener('message', audioListener);
            reject(new Error('Timeout generating greeting audio'));
          }
        }, 10000);
      } catch (error) {
        connectionData.ws.removeListener('message', audioListener);
        reject(error);
      }
    });
  }

  /**
   * Crear respuesta texto-only de OpenAI
   * @param {string} streamSid - ID del stream
   */
  createOpenAIResponse(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) {
      logger.warn(`âš ï¸ [${streamSid}] No hay conexiÃ³n para crear respuesta`);
      return;
    }

    // âœ… VERIFICAR si ya hay una respuesta activa
    if (connectionData.activeResponseId) {
      logger.warn(`âš ï¸ [${streamSid}] Ya hay una respuesta activa (${connectionData.activeResponseId}) - ignorando nueva solicitud`);
      return;
    }

    // ğŸš€ AUDIO NATIVO: OpenAI genera audio directamente (sin Azure TTS)
    const responseConfig = {
      type: 'response.create',
      response: {
        modalities: ['audio'],  // ğŸš€ SOLO AUDIO - streaming directo
        instructions: 'Responde en espaÃ±ol (castellano) con un tono natural y profesional.'
      }
    };

    try {
      connectionData.ws.send(JSON.stringify(responseConfig));
      logger.info(`ğŸš€ [${streamSid}] Solicitud de respuesta texto-only enviada`);
      // Marcar que hay una respuesta en progreso (se limpiarÃ¡ en response.done)
      connectionData.activeResponseId = 'pending';
    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error enviando response.create: ${error.message}`);
    }
  }

  /**
   * Manejar mensajes recibidos de OpenAI
   * @param {string} streamSid - ID del stream
   * @param {Buffer} data - Datos del mensaje
   */
  handleOpenAIMessage(streamSid, data) {
    try {
      const response = JSON.parse(data.toString());
      const connectionData = this.activeConnections.get(streamSid);

      if (!connectionData) {
        logger.warn(`âš ï¸ [${streamSid}] Mensaje OpenAI recibido pero no hay conexiÃ³n activa`);
        return;
      }

      // ğŸ”¥ SOLO LOGS CRÃTICOS - eliminar duplicados
      const CRITICAL_EVENTS = {
        'session.updated': true,
        'input_audio_buffer.speech_started': true, 
        'input_audio_buffer.speech_stopped': true,
        'conversation.item.input_audio_transcription.completed': true,
        'conversation.item.created': true,
        'response.done': true,
        'error': true
      };

      if (CRITICAL_EVENTS[response.type]) {
        logger.info(`ğŸ¯ [${streamSid}] ${response.type}`, {
          // Solo informaciÃ³n esencial
          has_delta: !!response.delta,
          has_transcript: !!response.transcript
        });
      }

      // ğŸ”¥ DEBUG ESPECÃFICO PARA PROBLEMAS COMUNES
      switch (response.type) {
        case 'session.created':
          logger.info(`ğŸ” [${streamSid}] SesiÃ³n creada por OpenAI - Verificando configuraciÃ³n inicial`);
          logger.info(`ğŸ” [${streamSid}] Session created event completo: ${JSON.stringify(response)}`);
          
          // Verificar quÃ© configurÃ³ OpenAI por defecto
          if (response.session && response.session.output_modalities) {
            const defaultModalities = response.session.output_modalities;
            logger.info(`ğŸ” [${streamSid}] OpenAI configurÃ³ por defecto: ${JSON.stringify(defaultModalities)}`);
            
            if (defaultModalities.includes('audio')) {
              logger.warn(`âš ï¸ [${streamSid}] OpenAI estÃ¡ configurado con audio por defecto - nuestra configuraciÃ³n se enviarÃ¡ ahora`);
            }
          }
          
          // âœ… FALLBACK: Si no llega session.updated en 2 segundos, activar de todos modos
          setTimeout(() => {
            if (connectionData.status === 'connected' && connectionData.sessionReadyResolver) {
              logger.warn(`âš ï¸ [${streamSid}] session.updated no llegÃ³ - activando de todos modos`);
              connectionData.status = 'ready';
              connectionData.sessionReadyResolver();
              delete connectionData.sessionReadyResolver;
            }
          }, 2000);
          break;

        case 'session.updated':
          // âœ… UNIFICADO: Combinar ambos handlers
          logger.info(`ğŸ”§ [${streamSid}] CONFIGURACIÃ“N APLICADA:`, {
            modalities: response.session?.modalities,
            output_modalities: response.session?.output_modalities,
            voice: response.session?.voice,
            turn_detection: response.session?.turn_detection,
            input_audio_transcription: response.session?.input_audio_transcription
          });

          // Verificar configuraciÃ³n
          if (response.session?.modalities?.includes('text') && response.session?.modalities?.includes('audio')) {
            logger.info(`ğŸ¯ [${streamSid}] âœ… AUDIO+TEXTO CONFIGURADO CORRECTAMENTE`);
            connectionData.status = 'ready';
            logger.info(`âœ… [${streamSid}] OpenAI listo para recibir audio y generar texto`);
            
            // âœ… RESOLVER LA PROMESA DE INICIALIZACIÃ“N
            if (connectionData.sessionReadyResolver) {
              connectionData.sessionReadyResolver();
              delete connectionData.sessionReadyResolver; // Limpiar
            }
          } else {
            logger.error(`ğŸš¨ [${streamSid}] CONFIGURACIÃ“N FALLÃ“ - OpenAI usa modalities: ${JSON.stringify(response.session?.modalities)}`);
          }
          break;

        case 'input_audio_buffer.speech_started':
          // âœ… UNIFICADO
          logger.info(`ğŸ¤ [${streamSid}] âœ… VAD DETECTÃ“ INICIO DE VOZ`);
          // Actualizar timestamp de VAD activity
          if (connectionData) {
            connectionData.lastVadActivity = Date.now();
          }
          this.handleSpeechStartedEvent(streamSid);
          break;

        case 'input_audio_buffer.speech_stopped':
          // âœ… UNIFICADO  
          logger.info(`ğŸ”‡ [${streamSid}] VAD DETECTÃ“ FIN DE VOZ - Procesando...`);
          
          // âœ… ENVIAR chunks restantes si hay (pueden quedar < 15 chunks sin enviar)
          if (connectionData.audioBuffer && connectionData.audioBuffer.length > 0) {
            const remainingBuffer = Buffer.concat(connectionData.audioBuffer);
            logger.info(`ğŸ“¦ [${streamSid}] Enviando chunks restantes (${connectionData.audioBuffer.length} chunks, ${remainingBuffer.length} bytes)`);
            
            connectionData.ws.send(JSON.stringify({
              type: 'input_audio_buffer.append',
              audio: remainingBuffer.toString('base64')
            }));
            
            // Limpiar buffer temporal
            connectionData.audioBuffer = [];
          } else {
            logger.info(`âœ… [${streamSid}] No hay chunks pendientes - todo el audio ya fue enviado`);
          }
          
          // âŒ NO ENVIAR COMMIT MANUAL con server_vad
          // OpenAI hace commit automÃ¡ticamente cuando detecta speech_stopped
          logger.info(`âœ… [${streamSid}] OpenAI harÃ¡ commit automÃ¡tico (server_vad activo)`);
          
          // âœ… CREAR RESPUESTA con retardo de 100ms
          setTimeout(() => {
            this.createOpenAIResponse(streamSid);
          }, 100);
          
          // âœ… Timeout aumentado a 15 segundos
          this.responseTimeouts.set(streamSid, setTimeout(() => {
            logger.error(`â° [${streamSid}] TIMEOUT: OpenAI no respondiÃ³ en 15 segundos`);
            this.responseTimeouts.delete(streamSid);
          }, 15000));
          break;

        case 'conversation.item.input_audio_transcription.completed':
          logger.info(`ğŸ“ [${streamSid}] âœ… TRANSCRIPCIÃ“N COMPLETADA`);
          const transcript = response.transcript || response.content || '';
          const transcriptClean = transcript.trim();
          
          logger.info(`ğŸ—£ï¸ [${streamSid}] TEXTO TRANSCRITO: "${transcriptClean}"`);
          
          // âš ï¸ VALIDAR: Si la transcripciÃ³n estÃ¡ vacÃ­a, cancelar generaciÃ³n de respuesta
          // PERO SOLO si no hay respuesta ya completada (evitar error response_cancel_not_active)
          if (!transcriptClean || transcriptClean.length < 2) {
            logger.warn(`âš ï¸ [${streamSid}] TranscripciÃ³n vacÃ­a o muy corta - probablemente ruido. Ignorando.`);
            
            // Solo cancelar si hay texto acumulado (indica respuesta en progreso)
            if (connectionData.accumulatedText && connectionData.accumulatedText.length > 0) {
              logger.info(`ğŸ” [${streamSid}] Respuesta en progreso detectada - cancelando...`);
              
              if (connectionData.ws && connectionData.ws.readyState === 1) {
                connectionData.ws.send(JSON.stringify({
                  type: 'response.cancel'
                }));
                logger.info(`ğŸš« [${streamSid}] Respuesta cancelada por transcripciÃ³n vacÃ­a`);
              }
            } else {
              logger.info(`â„¹ï¸ [${streamSid}] No hay respuesta activa - ignorando transcripciÃ³n vacÃ­a`);
            }
          }
          break;

        case 'response.created':
          logger.info(`ğŸš€ [${streamSid}] âœ… OpenAI GENERANDO RESPUESTA`);
          const responseId = response.response?.id || 'N/A';
          logger.info(`ğŸ†” [${streamSid}] Response ID: ${responseId}`);
          // Guardar el ID de la respuesta activa
          connectionData.activeResponseId = responseId;
          break;

        case 'conversation.item.created':
          // âœ… MEJOR FLUJO: Obtener texto completo de una vez
          if (response.item?.role === 'assistant' && response.item?.type === 'message') {
            const content = response.item.content;
            
            // Buscar el contenido de texto
            let fullText = '';
            if (Array.isArray(content)) {
              for (const part of content) {
                if (part.type === 'text' && part.text) {
                  fullText += part.text;
                }
              }
            }
            
            if (fullText) {
              logger.info(`ğŸ¯ [${streamSid}] âœ… TEXTO COMPLETO de OpenAI (${fullText.length} chars): "${fullText}"`);
              
              // âœ… PROTECCIÃ“N: Solo textos razonables para TTS
              if (fullText.length > 500) {
                logger.warn(`âš ï¸ [${streamSid}] TEXTO DEMASIADO LARGO - Truncando a 500 chars`);
                fullText = fullText.substring(0, 500);
              }
              
              // âœ… NO usar Azure TTS - OpenAI genera el audio directamente
              logger.info(`ğŸ¯ [${streamSid}] Texto recibido de OpenAI (audio se genera automÃ¡ticamente): "${fullText.substring(0, 50)}..."`);
            } else {
              logger.debug(`ğŸ” [${streamSid}] Item creado sin texto: ${JSON.stringify(response.item)}`);
            }
          }
          break;

        case 'response.done':
          // âœ… Respuesta completada - limpiar timeouts
          if (this.responseTimeouts.has(streamSid)) {
            clearTimeout(this.responseTimeouts.get(streamSid));
            this.responseTimeouts.delete(streamSid);
          }
          logger.info(`âœ… [${streamSid}] Respuesta de OpenAI completada`);
          break;

        case 'response.audio_transcript.delta':
        case 'response.audio_transcript.done':
          // ğŸ—‘ï¸ OBSOLETO: Ya no usamos Azure TTS, solo audio nativo de OpenAI
          logger.debug(`ğŸ”‡ [${streamSid}] Evento de transcripciÃ³n ignorado: ${response.type}`);
          break;

        case 'response.audio.delta':
          // ğŸš€ AUDIO NATIVO: Enviar directamente a Twilio (mulaw)
          if (response.delta) {
            const audioData = response.delta; // Base64 mulaw de OpenAI
            logger.debug(`ğŸµ [${streamSid}] Audio delta recibido (${audioData.length} chars base64)`);
            
            // Enviar directamente a Twilio via evento
            this.emit('audioFromOpenAI', {
              streamSid: streamSid,
              audio: audioData,
              timestamp: Date.now()
            });
          }
          break;

        case 'response.audio.done':
          logger.info(`âœ… [${streamSid}] Audio de OpenAI completado`);
          break;

        case 'response.output_audio_transcript.done':
          // Ignorar - ya no usamos transcripciÃ³n
          break;

        case 'response.output_audio_transcript.delta':
          // âœ… PROCESAR transcripciÃ³n de audio generado por OpenAI
          logger.info(`ğŸ“ [${streamSid}] âœ… TRANSCRIPCIÃ“N AUDIO DELTA de OpenAI`);
          if (response.delta) {
            logger.debug(`ğŸ” [${streamSid}] TranscripciÃ³n delta: "${response.delta}"`);
            
            // Acumular transcripciÃ³n del audio generado
            if (!connectionData.audioTranscript) {
              connectionData.audioTranscript = '';
            }
            connectionData.audioTranscript += response.delta;
            logger.debug(`ğŸ” [${streamSid}] TranscripciÃ³n acumulada: "${connectionData.audioTranscript}"`);
          }
          break;


        case 'response.done':
          logger.info(`âœ… [${streamSid}] ğŸ“ OpenAI response.done - Procesando transcripciÃ³n acumulada`);
          
          // ğŸ” DEBUG: ANALIZAR RESPUESTA OPENAI para logs
          logger.info(`ğŸ” [${streamSid}] ğŸ“Š RESPONSE STATS:`);
          logger.info(`ğŸ” [${streamSid}] â”œâ”€â”€ Response ID: ${response.response?.id || 'N/A'}`);
          logger.info(`ğŸ” [${streamSid}] â”œâ”€â”€ Status: ${response.response?.status || 'N/A'}`);
          
          // ğŸ¤ ACTIVAR TRANSCRIPCIÃ“N SI ES EL SALUDO INICIAL
          if (connectionData.isGreeting) {
            logger.info(`ğŸ¤ [${streamSid}] Saludo completado - ACTIVANDO TRANSCRIPCIÃ“N`);
            connectionData.isGreeting = false; // Limpiar flag
            
            // Notificar al handler de Twilio para activar transcripciÃ³n
            if (connectionData.onGreetingComplete) {
              connectionData.onGreetingComplete();
            }
          }
          
          // âœ… LIMPIAR FLAG DE RESPUESTA ACTIVA
          connectionData.activeResponseId = null;
          logger.info(`ğŸ”“ [${streamSid}] Respuesta finalizada - sistema listo para nueva solicitud`);
          
          // âœ… PROCESAR TRANSCRIPCIÃ“N ACUMULADA â†’ Azure TTS
          if (connectionData.audioTranscript) {
            logger.info(`ğŸš€ [${streamSid}] Enviando transcripciÃ³n completa a Azure TTS: "${connectionData.audioTranscript}"`);
            logger.debug(`ğŸ” [${streamSid}] ğŸ“Š TranscripciÃ³n length: ${connectionData.audioTranscript.length} chars`);
            
            // âœ… NO usar Azure TTS - OpenAI ya generÃ³ el audio
            logger.info(`ğŸ¯ [${streamSid}] TranscripciÃ³n completa recibida (audio ya enviado): "${connectionData.audioTranscript.substring(0, 50)}..."`);
            
            // ğŸ” DETECTAR DESPEDIDA - Colgar llamada automÃ¡ticamente
            if (this.isFarewellMessage(connectionData.audioTranscript)) {
              logger.info(`ğŸ‘‹ [${streamSid}] DESPEDIDA DETECTADA - Programando cierre de llamada en 2 segundos`);
              
              // Esperar 2 segundos para que el audio de despedida termine de reproducirse
              setTimeout(() => {
                logger.info(`ğŸ“ [${streamSid}] Cerrando llamada despuÃ©s de despedida`);
                
                // Emitir evento para que el handler de Twilio cierre la conexiÃ³n
                if (connectionData.onFarewell) {
                  connectionData.onFarewell();
                }
              }, 2000);
            }
            
            // Limpiar transcripciÃ³n acumulada
            connectionData.audioTranscript = '';
          } else {
            logger.warn(`âš ï¸ [${streamSid}] No hay transcripciÃ³n acumulada para procesar`);
          }
          
          logger.info(`ğŸ” [${streamSid}] â””â”€â”€ âœ… Respuesta procesada completamente`);
          break;



        case 'conversation.item.input_audio_transcription.failed':
          logger.error(`âŒ [${streamSid}] TRANSCRIPCIÃ“N FALLÃ“`);
          const error = response.error || 'Error desconocido';
          logger.error(`ğŸ’¥ [${streamSid}] CAUSA: ${JSON.stringify(error)}`);
          break;

        case 'response.output_audio.started':
          logger.info(`ğŸµ [${streamSid}] âœ… OpenAI INICIANDO AUDIO DE RESPUESTA`);
          break;

        case 'error':
          logger.error(`âŒ [${streamSid}] ERROR CRÃTICO DE OPENAI`);
          logger.error(`ğŸ” [${streamSid}] ğŸ“Š ERROR COMPLETO: ${JSON.stringify(response, null, 2)}`);
          
          // DiagnÃ³stico especÃ­fico del error
          if (response.error) {
            logger.error(`ğŸ’¥ [${streamSid}] Error Type: ${response.error.type || 'N/A'}`);
            logger.error(`ğŸ’¥ [${streamSid}] Error Code: ${response.error.code || 'N/A'}`);
            logger.error(`ğŸ’¥ [${streamSid}] Error Message: ${response.error.message || 'N/A'}`);
            
            // Errores especÃ­ficos de configuraciÃ³n
            if (response.error.message && response.error.message.includes('Unknown parameter')) {
              logger.error(`âš ï¸ [${streamSid}] PROBLEMA DE CONFIGURACIÃ“N detectado!`);
            }
          }
          break;

        default:
          // Capturar eventos no esperados que podrÃ­an ser importantes
          if (!['rate_limits.updated', 'conversation.item.done', 'response.output_item.done'].includes(response.type)) {
            logger.info(`ğŸ“¨ [${streamSid}] Evento OpenAI no manejado: ${response.type}`);
            logger.debug(`ğŸ” [${streamSid}] ğŸ“Š Evento completo: ${JSON.stringify(response, null, 2)}`);
          } else {
            logger.debug(`ğŸ“¨ [${streamSid}] Mensaje OpenAI: ${response.type}`);
          }
      }

    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error procesando mensaje OpenAI: ${error.message}`);
    }
  }

  /**
   * CÃ“DIGO OFICIAL: Handle interruption when the caller's speech starts
   * @param {string} streamSid - Stream ID
   */
  handleSpeechStartedEvent(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) return;

    // ğŸ” DEBUG: Estado actual antes de procesar interrupciÃ³n
    logger.info(`ğŸ¤ [${streamSid}] SPEECH STARTED - Estado del stream:`);
    logger.info(`ğŸ¤ [${streamSid}] â”œâ”€â”€ markQueue.length: ${connectionData.markQueue.length}`);
    logger.info(`ğŸ¤ [${streamSid}] â”œâ”€â”€ responseStartTimestamp: ${connectionData.responseStartTimestampTwilio}`);
    logger.info(`ğŸ¤ [${streamSid}] â”œâ”€â”€ lastAssistantItem: ${connectionData.lastAssistantItem}`);
    logger.info(`ğŸ¤ [${streamSid}] â””â”€â”€ latestMediaTimestamp: ${connectionData.latestMediaTimestamp}`);

    // CÃLCULO EXACTO del cÃ³digo oficial - SOLO interrumpir si hay respuesta activa
    if (connectionData.markQueue.length > 0 && connectionData.responseStartTimestampTwilio != null) {
      const elapsedTime = connectionData.latestMediaTimestamp - connectionData.responseStartTimestampTwilio;
      logger.info(`â±ï¸ [${streamSid}] âœ… HAY RESPUESTA ACTIVA - Interrumpiendo`);
      logger.info(`â±ï¸ [${streamSid}] Calculating elapsed time: ${connectionData.latestMediaTimestamp} - ${connectionData.responseStartTimestampTwilio} = ${elapsedTime}ms`);

      if (connectionData.lastAssistantItem) {
        const truncateEvent = {
          type: 'conversation.item.truncate',
          item_id: connectionData.lastAssistantItem,
          content_index: 0,
          audio_end_ms: elapsedTime
        };
        logger.info(`ğŸ”„ [${streamSid}] Sending truncation event: ${JSON.stringify(truncateEvent)}`);
        connectionData.ws.send(JSON.stringify(truncateEvent));
      }

      // EMITIR CLEAR EVENT para Twilio (serÃ¡ manejado por TwilioStreamHandler)
      this.emit('clearAudio', {
        streamSid: streamSid
      });

      // Reset (exacto del cÃ³digo oficial)
      connectionData.markQueue = [];
      connectionData.lastAssistantItem = null;
      connectionData.responseStartTimestampTwilio = null;
      
      logger.info(`âœ… [${streamSid}] InterrupciÃ³n procesada y estado reseteado`);
    } else {
      // ğŸ¯ CLAVE: Si no hay respuesta activa, NO interrumpir
      logger.info(`âš ï¸ [${streamSid}] NO HAY RESPUESTA ACTIVA - Ignorando speech_started`);
      logger.info(`âš ï¸ [${streamSid}] markQueue: ${connectionData.markQueue.length}, responseStart: ${connectionData.responseStartTimestampTwilio}`);
    }
  }


  // ğŸ—‘ï¸ MÃ‰TODO OBSOLETO ELIMINADO: processAudioDeltaImmediate()
  // RAZÃ“N: Solo usamos transcripciÃ³n de OpenAI â†’ Azure TTS, no audio directo

  /**
   * âœ… NUEVO FLUJO SIMPLE: Procesar texto de OpenAI con Azure TTS (como saludo inicial)
   * @param {string} streamSid - Stream ID
   * @param {string} text - Texto completo de OpenAI
   */
  async processTextWithAzureTTS(streamSid, text) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) {
      logger.error(`âŒ [${streamSid}] No connection data para procesar texto`);
      return;
    }

    try {
      logger.info(`ğŸš€ [${streamSid}] âœ… PROCESANDO texto con Azure TTS: "${text}"`);
      
      // Emitir evento simple para TwilioStreamHandler (como saludo inicial)
      this.emit('processTextWithAzure', {
        streamSid: streamSid,
        text: text, // âœ… SIMPLE: Solo texto
        timestamp: Date.now()
      });
      
      logger.debug(`âœ… [${streamSid}] Texto enviado para Azure TTS`);

    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error procesando texto: ${error.message}`);
    }
  }

  /**
   * Enviar audio del usuario a OpenAI (mulaw de Twilio â†’ PCM16 para OpenAI)
   * @param {string} streamSid - ID del stream
   * @param {string} audioPayload - Audio en base64 desde Twilio (mulaw)
   */
  sendAudioToOpenAI(streamSid, audioPayload, mediaTimestamp) {
    const connectionData = this.activeConnections.get(streamSid);
    // âœ… PERMITIR audio en 'connected' Y 'ready' - conexiÃ³n WebSocket ya estÃ¡ abierta
    if (!connectionData || (connectionData.status !== 'connected' && connectionData.status !== 'ready')) {
      logger.debug(`âš ï¸ [${streamSid}] ConexiÃ³n no lista para audio - Status: ${connectionData?.status || 'N/A'}`);
      return; // No hay conexiÃ³n lista
    }

    try {
      // CÃ“DIGO OFICIAL: Actualizar timestamp
      if (mediaTimestamp) {
        connectionData.latestMediaTimestamp = mediaTimestamp;
        logger.debug(`â±ï¸ [${streamSid}] Updated media timestamp: ${mediaTimestamp}ms`);
      }

      // ğŸ¯ ENVIAR MULAW DIRECTO (SIN CONVERSIÃ“N)
      const mulawBuffer = Buffer.from(audioPayload, 'base64');
      
      // âœ… VALIDACIÃ“N DE CALIDAD DE AUDIO
      const silentBytes = mulawBuffer.filter(byte => byte === 0xFF || byte === 0x00).length;
      const audioPercent = ((mulawBuffer.length - silentBytes) / mulawBuffer.length * 100);
      
      // Inicializar y actualizar contador
      if (!connectionData.audioSent) {
        connectionData.audioSent = 0;
      }
      connectionData.audioSent++;
      
      // âœ… ACUMULAR CHUNKS en buffer temporal (mÃ­nimo 300ms = 15 chunks de 20ms)
      if (!connectionData.audioBuffer) {
        connectionData.audioBuffer = [];
      }
      connectionData.audioBuffer.push(mulawBuffer);
      
      // âœ… ENVIAR solo cuando tenemos suficiente audio acumulado
      if (connectionData.audioBuffer.length >= 15) {
        const combinedBuffer = Buffer.concat(connectionData.audioBuffer);
        connectionData.audioBuffer = []; // Limpiar buffer temporal
        
        const audioMessage = {
          type: 'input_audio_buffer.append',
          audio: combinedBuffer.toString('base64')
        };
        
        connectionData.ws.send(JSON.stringify(audioMessage));
        logger.debug(`ğŸ™ï¸ [${streamSid}] Audio acumulado enviado a OpenAI Realtime (${combinedBuffer.length} bytes)`);
      }
      
      // ğŸ“Š DIAGNÃ“STICO PERIÃ“DICO
      if (connectionData.audioSent % 50 === 0) {
        logger.info(`ğŸ“Š [${streamSid}] ===== DIAGNÃ“STICO VAD CRÃTICO =====`);
        logger.info(`ğŸ“Š [${streamSid}] â”œâ”€â”€ Audio chunks enviados: ${connectionData.audioSent}`);
        logger.info(`ğŸ“Š [${streamSid}] â”œâ”€â”€ ConexiÃ³n status: ${connectionData.status}`);
        logger.info(`ğŸ“Š [${streamSid}] â”œâ”€â”€ WebSocket readyState: ${connectionData.ws.readyState}`);
        logger.info(`ğŸ“Š [${streamSid}] â”œâ”€â”€ Audio content: ${audioPercent.toFixed(1)}% non-silent`);
        logger.info(`ğŸ“Š [${streamSid}] â”œâ”€â”€ Ãšltimo chunk: ${mulawBuffer.length} bytes, ${silentBytes} silent`);
        logger.info(`ğŸ“Š [${streamSid}] â””â”€â”€ ğŸš¨ Si >30% audio y NO hay speech_started = PROBLEMA VAD`);
      }
      
      // ğŸš¨ ALERTA CRÃTICA
      if (audioPercent > 30) {
        logger.warn(`ğŸš¨ [${streamSid}] AUDIO REAL DETECTADO: ${audioPercent.toFixed(1)}% content - VAD deberÃ­a detectar!`);
      }
    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error enviando audio a OpenAI: ${error.message}`);
    }
  }

  /**
   * ğŸš¨ DEBUG: Extraer texto de respuesta OpenAI para anÃ¡lisis
{{ ... }}
   * @returns {string} - Texto extraÃ­do
   */
  extractTextFromResponse(response) {
    try {
      // Buscar en diferentes ubicaciones donde OpenAI puede poner el texto
      if (response.response?.output?.[0]?.content?.[0]?.transcript) {
        return response.response.output[0].content[0].transcript;
      }
      
      // Buscar en items de la respuesta
      if (response.response?.output?.[0]?.content) {
        const content = response.response.output[0].content;
        for (const item of content) {
          if (item.transcript) return item.transcript;
          if (item.text) return item.text;
        }
      }
      
      
      return 'N/A';
    } catch (error) {
      return `Error: ${error.message}`;
    }
  }

  /**
   * CÃ“DIGO OFICIAL: Send mark messages to Media Streams 
   * @param {string} streamSid - Stream ID
   */
  sendMark(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) return;

    // Emitir evento para que TwilioStreamHandler envÃ­e la marca a Twilio
    this.emit('sendMark', {
      streamSid: streamSid,
      markName: 'responsePart'
    });

    // Agregar a queue como en cÃ³digo oficial
    connectionData.markQueue.push('responsePart');
  }




  /**
   * Cerrar conexiÃ³n OpenAI para un stream
   * @param {string} streamSid - ID del stream
   */
  async closeConnection(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) {
      return;
    }

    logger.info(`ğŸ”Œ [${streamSid}] Cerrando conexiÃ³n OpenAI Realtime`);
    
    try {
      if (connectionData.ws && connectionData.ws.readyState === WebSocket.OPEN) {
        connectionData.ws.close(1000, 'Stream ended');
      }
    } catch (error) {
      logger.error(`âŒ [${streamSid}] Error cerrando conexiÃ³n OpenAI: ${error.message}`);
    }

    this.activeConnections.delete(streamSid);
  }

  /**
   * Convertir audio mulaw 8kHz (Twilio) a PCM 24kHz (OpenAI)
   * @param {Buffer} mulawBuffer - Buffer mulaw de Twilio
   * @returns {Buffer} - Buffer PCM 16-bit 24kHz para OpenAI
   */
  convertMulawToPCM24k(mulawBuffer) {
    // ğŸ¯ TABLA DE CONVERSIÃ“N Î¼-law â†’ PCM lineal (estÃ¡ndar ITU-T G.711)
    const MULAW_TO_LINEAR = [
      -32124, -31100, -30076, -29052, -28028, -27004, -25980, -24956,
      -23932, -22908, -21884, -20860, -19836, -18812, -17788, -16764,
      -15996, -15484, -14972, -14460, -13948, -13436, -12924, -12412,
      -11900, -11388, -10876, -10364, -9852, -9340, -8828, -8316,
      -7932, -7676, -7420, -7164, -6908, -6652, -6396, -6140,
      -5884, -5628, -5372, -5116, -4860, -4604, -4348, -4092,
      -3900, -3772, -3644, -3516, -3388, -3260, -3132, -3004,
      -2876, -2748, -2620, -2492, -2364, -2236, -2108, -1980,
      -1884, -1820, -1756, -1692, -1628, -1564, -1500, -1436,
      -1372, -1308, -1244, -1180, -1116, -1052, -988, -924,
      -876, -844, -812, -780, -748, -716, -684, -652,
      -620, -588, -556, -524, -492, -460, -428, -396,
      -372, -356, -340, -324, -308, -292, -276, -260,
      -244, -228, -212, -196, -180, -164, -148, -132,
      -120, -112, -104, -96, -88, -80, -72, -64,
      -56, -48, -40, -32, -24, -16, -8, 0,
      32124, 31100, 30076, 29052, 28028, 27004, 25980, 24956,
      23932, 22908, 21884, 20860, 19836, 18812, 17788, 16764,
      15996, 15484, 14972, 14460, 13948, 13436, 12924, 12412,
      11900, 11388, 10876, 10364, 9852, 9340, 8828, 8316,
      7932, 7676, 7420, 7164, 6908, 6652, 6396, 6140,
      5884, 5628, 5372, 5116, 4860, 4604, 4348, 4092,
      3900, 3772, 3644, 3516, 3388, 3260, 3132, 3004,
      2876, 2748, 2620, 2492, 2364, 2236, 2108, 1980,
      1884, 1820, 1756, 1692, 1628, 1564, 1500, 1436,
      1372, 1308, 1244, 1180, 1116, 1052, 988, 924,
      876, 844, 812, 780, 748, 716, 684, 652,
      620, 588, 556, 524, 492, 460, 428, 396,
      372, 356, 340, 324, 308, 292, 276, 260,
      244, 228, 212, 196, 180, 164, 148, 132,
      120, 112, 104, 96, 88, 80, 72, 64,
      56, 48, 40, 32, 24, 16, 8, 0
    ];

    // ğŸ”„ PASO 1: Convertir Î¼-law â†’ PCM 16-bit
    const pcm8k = Buffer.alloc(mulawBuffer.length * 2); // 2 bytes por sample
    for (let i = 0; i < mulawBuffer.length; i++) {
      const linear = MULAW_TO_LINEAR[mulawBuffer[i]];
      pcm8k.writeInt16LE(linear, i * 2);
    }

    // ğŸ”„ PASO 2: Upsample 8kHz â†’ 24kHz (factor 3) con interpolaciÃ³n lineal
    const pcm24k = Buffer.alloc(pcm8k.length * 3); // 3x mÃ¡s samples
    const samples8k = pcm8k.length / 2;
    
    for (let i = 0; i < samples8k; i++) {
      const currentSample = pcm8k.readInt16LE(i * 2);
      const nextSample = i < samples8k - 1 ? pcm8k.readInt16LE((i + 1) * 2) : currentSample;
      
      // ğŸ”¥ MEJORA: InterpolaciÃ³n lineal entre samples para mejor calidad
      pcm24k.writeInt16LE(currentSample, (i * 3) * 2);
      pcm24k.writeInt16LE(
        Math.floor((currentSample * 2 + nextSample) / 3), 
        (i * 3 + 1) * 2
      );
      pcm24k.writeInt16LE(
        Math.floor((currentSample + nextSample * 2) / 3), 
        (i * 3 + 2) * 2
      );
    }

    return pcm24k;
  }

  /**
   * Obtener estadÃ­sticas del servicio
   */
  getStats() {
    const connections = Array.from(this.activeConnections.values());
    return {
      activeConnections: connections.length,
      connectionsByStatus: connections.reduce((acc, conn) => {
        acc[conn.status] = (acc[conn.status] || 0) + 1;
        return acc;
      }, {}),
      totalMessages: connections.reduce((sum, conn) => sum + conn.messageCount, 0)
    };
  }

  /**
   * Verificar si hay conexiÃ³n activa para un stream
   * @param {string} streamSid - ID del stream
   * @returns {boolean}
   */
  isConnectionActive(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    // âœ… PERMITIR audio en 'connected' Y 'ready' - conexiÃ³n WebSocket ya estÃ¡ abierta
    return connectionData && (connectionData.status === 'connected' || connectionData.status === 'ready');
  }

  /**
   * CÃ“DIGO OFICIAL: Process mark completion (como en el cÃ³digo original)
   * @param {string} streamSid - Stream ID
   * @param {string} markName - Nombre de la marca procesada
   */
  processMarkCompletion(streamSid, markName) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) return;

    // EXACTO del cÃ³digo oficial: remover del queue
    if (connectionData.markQueue.length > 0) {
      connectionData.markQueue.shift();
      logger.debug(`ğŸ“ [${streamSid}] Marca ${markName} removida del queue (${connectionData.markQueue.length} restantes)`);
    }
  }

  /**
   * Convierte audio mulaw (8-bit) a PCM16 (16-bit little-endian)
   * OpenAI Realtime API requiere PCM16, pero Twilio envÃ­a mulaw
   * @param {Buffer} mulawBuffer - Buffer con audio mulaw
   * @returns {Buffer} - Buffer con audio PCM16
   */
  convertMulawToPCM16(mulawBuffer) {
    // Tabla de conversiÃ³n mulaw a PCM16 (estÃ¡ndar ITU-T G.711)
    const MULAW_TO_PCM16 = [
      -32124,-31100,-30076,-29052,-28028,-27004,-25980,-24956,
      -23932,-22908,-21884,-20860,-19836,-18812,-17788,-16764,
      -15996,-15484,-14972,-14460,-13948,-13436,-12924,-12412,
      -11900,-11388,-10876,-10364,-9852,-9340,-8828,-8316,
      -7932,-7676,-7420,-7164,-6908,-6652,-6396,-6140,
      -5884,-5628,-5372,-5116,-4860,-4604,-4348,-4092,
      -3900,-3772,-3644,-3516,-3388,-3260,-3132,-3004,
      -2876,-2748,-2620,-2492,-2364,-2236,-2108,-1980,
      -1884,-1820,-1756,-1692,-1628,-1564,-1500,-1436,
      -1372,-1308,-1244,-1180,-1116,-1052,-988,-924,
      -876,-844,-812,-780,-748,-716,-684,-652,
      -620,-588,-556,-524,-492,-460,-428,-396,
      -372,-356,-340,-324,-308,-292,-276,-260,
      -244,-228,-212,-196,-180,-164,-148,-132,
      -120,-112,-104,-96,-88,-80,-72,-64,
      -56,-48,-40,-32,-24,-16,-8,0,
      32124,31100,30076,29052,28028,27004,25980,24956,
      23932,22908,21884,20860,19836,18812,17788,16764,
      15996,15484,14972,14460,13948,13436,12924,12412,
      11900,11388,10876,10364,9852,9340,8828,8316,
      7932,7676,7420,7164,6908,6652,6396,6140,
      5884,5628,5372,5116,4860,4604,4348,4092,
      3900,3772,3644,3516,3388,3260,3132,3004,
      2876,2748,2620,2492,2364,2236,2108,1980,
      1884,1820,1756,1692,1628,1564,1500,1436,
      1372,1308,1244,1180,1116,1052,988,924,
      876,844,812,780,748,716,684,652,
      620,588,556,524,492,460,428,396,
      372,356,340,324,308,292,276,260,
      244,228,212,196,180,164,148,132,
      120,112,104,96,88,80,72,64,
      56,48,40,32,24,16,8,0
    ];

    const pcm16Buffer = Buffer.alloc(mulawBuffer.length * 2); // PCM16 es 2 bytes por sample
    
    for (let i = 0; i < mulawBuffer.length; i++) {
      const mulawByte = mulawBuffer[i];
      const pcm16Value = MULAW_TO_PCM16[mulawByte];
      
      // Escribir como little-endian 16-bit signed integer
      pcm16Buffer.writeInt16LE(pcm16Value, i * 2);
    }
    
    return pcm16Buffer;
  }
}

// Agregar EventEmitter CORRECTO - mixina en la clase original
const { EventEmitter } = require('events');

// MIXINA CORRECTA: Agregar EventEmitter a la clase existente sin herencia
Object.assign(OpenAIRealtimeService.prototype, EventEmitter.prototype);

// Llamar constructor EventEmitter en constructor original
const originalConstructor = OpenAIRealtimeService.prototype.constructor;
OpenAIRealtimeService.prototype.constructor = function(...args) {
  originalConstructor.apply(this, args);
  EventEmitter.call(this);
};

module.exports = OpenAIRealtimeService;
