const WebSocket = require('ws');
const logger = require('../utils/logger');

/**
 * Servicio especializado para OpenAI Realtime API
 * Maneja la comunicaci√≥n bidireccional de audio en tiempo real
 * Documentaci√≥n oficial: https://platform.openai.com/docs/guides/realtime
 */
class OpenAIRealtimeService {
  constructor() {
    this.apiKey = process.env.OPENAI_API_KEY;
    this.model = 'gpt-4o-realtime-preview-2024-10-01'; // MODELO OFICIAL CORRECTO
    this.temperature = 0.8; // Del c√≥digo oficial
    this.voice = 'alloy'; // Del c√≥digo oficial
    this.activeConnections = new Map(); // streamSid -> connection data
    
    // üîí VALIDACI√ìN CR√çTICA PARA PRODUCCI√ìN
    if (!this.apiKey) {
      throw new Error('‚ùå OPENAI_API_KEY no definida en variables de entorno');
    }
    
    // üìä RATE LIMITING Y CONFIGURACI√ìN PRODUCCI√ìN
    this.maxConcurrentConnections = parseInt(process.env.MAX_CONCURRENT_OPENAI_CONNECTIONS) || 50;
    this.connectionRetryAttempts = 3;
    this.connectionTimeout = 15000; // 15 segundos
    
    // üìà M√âTRICAS PARA MONITOREO
    this.metrics = {
      totalConnections: 0,
      failedConnections: 0,
      activeConnections: 0,
      lastReset: Date.now()
    };
    
    // SISTEMA MENSAJE BASE (se personaliza por cliente)
    this.baseSystemMessage = `You are Susan, a professional receptionist. Be helpful, friendly and direct. Answer briefly and ask how you can help. Maintain a professional but warm tone.`;
  }

  /**
   * Inicializar conexi√≥n OpenAI Realtime para un stream espec√≠fico
   * @param {string} streamSid - ID del stream de Twilio
   * @param {Object} clientConfig - Configuraci√≥n del cliente desde DB
   * @returns {Promise<WebSocket>} - Conexi√≥n WebSocket establecida
   */
  async initializeConnection(streamSid, clientConfig = {}) {
    try {
      if (!this.apiKey) {
        throw new Error('OPENAI_API_KEY no est√° definida');
      }
      if (this.activeConnections.has(streamSid)) {
        logger.warn(`‚ö†Ô∏è [${streamSid}] Conexi√≥n OpenAI ya existe, cerrando anterior`);
        await this.closeConnection(streamSid);
      }

      logger.info(`ü§ñ [${streamSid}] Inicializando conexi√≥n OpenAI Realtime (formato oficial)`);

      // ‚úÖ URL SIMPLE OFICIAL - configuraci√≥n por session.update
      const wsUrl = `wss://api.openai.com/v1/realtime?model=${this.model}`;
      const openAiWs = new WebSocket(wsUrl, {
        headers: {
          'Authorization': `Bearer ${this.apiKey}`
        }
      });

      // Almacenar datos de conexi√≥n + variables del c√≥digo oficial
      const connectionData = {
        ws: openAiWs,
        status: 'connecting',
        streamSid: streamSid,
        clientConfig: clientConfig,
        messageCount: 0,
        startTime: Date.now(),
        // VARIABLES DEL C√ìDIGO OFICIAL COMPLETAS
        latestMediaTimestamp: 0,
        lastAssistantItem: null,
        markQueue: [],
        responseStartTimestampTwilio: null,
        // ‚úÖ NUEVAS VARIABLES PARA FLUJO TEXTO
        accumulatedText: '', // Texto acumulado de OpenAI
        textResponseCount: 0 // Contador de respuestas de texto
      };

      this.activeConnections.set(streamSid, connectionData);

      return new Promise((resolve, reject) => {
        // Manejar conexi√≥n establecida
        openAiWs.on('open', () => {
          logger.info(`‚úÖ [${streamSid}] Conexi√≥n OpenAI Realtime establecida`);
          logger.info(`üîç [${streamSid}] URL conectada: ${wsUrl}`);
          logger.info(`üîç [${streamSid}] Modelo: ${this.model}`);
          logger.info(`üîç [${streamSid}] Temperature: ${this.temperature}`);
          connectionData.status = 'connected';
          
          // Enviar inicializaci√≥n de sesi√≥n (formato oficial)
          setTimeout(() => this.initializeSession(streamSid, clientConfig), 100);
          
          resolve(openAiWs);
        });

        // Manejar mensajes de OpenAI
        openAiWs.on('message', (data) => {
          connectionData.messageCount++;
          this.handleOpenAIMessage(streamSid, data);
        });

        // Manejar errores
        openAiWs.on('error', (error) => {
          logger.error(`‚ùå [${streamSid}] Error en conexi√≥n OpenAI: ${error.message}`);
          connectionData.status = 'error';
          reject(error);
        });

        // Manejar cierre
        openAiWs.on('close', (code, reason) => {
          logger.warn(`‚ö†Ô∏è [${streamSid}] Conexi√≥n OpenAI cerrada - Code: ${code}, Reason: ${reason}`);
          connectionData.status = 'closed';
          this.activeConnections.delete(streamSid);
        });

        // Timeout de conexi√≥n
        setTimeout(() => {
          if (connectionData.status === 'connecting') {
            reject(new Error('Timeout conectando con OpenAI Realtime API'));
          }
        }, 10000);
      });

    } catch (error) {
      logger.error(`‚ùå [${streamSid}] Error inicializando OpenAI Realtime: ${error.message}`);
      throw error;
    }
  }

  /**
   * Inicializar sesi√≥n OpenAI con par√°metros v√°lidos de la API
   * @param {string} streamSid - ID del stream
   * @param {Object} clientConfig - Configuraci√≥n del cliente
   */
  initializeSession(streamSid, clientConfig) {
    logger.info(`üî• [${streamSid}] INICIO initializeSession() - CONFIG M√çNIMA`);
    
    const connectionData = this.activeConnections.get(streamSid);
    
    if (!connectionData || connectionData.status !== 'connected') {
      logger.error(`‚ùå [${streamSid}] No hay conexi√≥n OpenAI activa para configurar`);
      return;
    }

    // Personalizar mensaje del sistema seg√∫n el cliente
    const companyName = clientConfig.companyName || 'la empresa';
    const companyDescription = clientConfig.companyDescription || '';
    
    const customSystemMessage = `Eres Susan, la recepcionista profesional de ${companyName}. ${companyDescription ? `La empresa se dedica a: ${companyDescription}.` : ''} S√© √∫til, amigable y directa. Responde brevemente y pregunta en qu√© puedes ayudar. Mant√©n un tono profesional pero c√°lido. Tu objetivo es ayudar al cliente y dirigirlo correctamente. Si te preguntan sobre servicios espec√≠ficos, informaci√≥n de contacto u horarios, proporciona la informaci√≥n disponible. SIEMPRE responde en espa√±ol y √öNICAMENTE con texto, nunca con audio.`;

    // ‚úÖ CONFIGURACI√ìN M√çNIMA ABSOLUTA - SOLO LO QUE FUNCIONA
    const sessionUpdate = {
      type: 'session.update',
      session: {
        type: 'realtime',
        instructions: customSystemMessage
        // üö´ NADA M√ÅS - solo type e instructions
      }
    };

    logger.info(`‚öôÔ∏è [${streamSid}] Enviando configuraci√≥n M√çNIMA ABSOLUTA`);
    logger.info(`üîß [${streamSid}] Config: SOLO type + instructions`);
    
    connectionData.ws.send(JSON.stringify(sessionUpdate));
    logger.info(`‚úÖ [${streamSid}] session.update m√≠nimo enviado`);

    // ‚úÖ FORZAR SOLO TEXTO mediante response.create
    const forceTextResponse = {
      type: 'response.create',
      response: {
        instructions: "Debes responder √öNICAMENTE con texto, nunca con audio. Siempre proporciona respuestas solo de texto en espa√±ol. OBLIGATORIO: Solo texto, nunca audio.",
        max_output_tokens: 150
      }
    };

    logger.info(`üîß [${streamSid}] Enviando response.create para forzar solo texto`);
    connectionData.ws.send(JSON.stringify(forceTextResponse));
    logger.info(`‚úÖ [${streamSid}] Configuraci√≥n completada - SOLO TEXTO forzado`);
    
    // ‚úÖ EXPLICACI√ìN: C√≥mo funciona ahora
    logger.info(`üìã [${streamSid}] ‚ÑπÔ∏è  CONFIGURACI√ìN ACTUAL:`);
    logger.info(`üìã [${streamSid}] ‚ÑπÔ∏è  - Transcripci√≥n autom√°tica con Whisper (por defecto)`);
    logger.info(`üìã [${streamSid}] ‚ÑπÔ∏è  - Respuesta en texto forzada por instructions`);
    logger.info(`üìã [${streamSid}] ‚ÑπÔ∏è  - VAD autom√°tico del servidor (por defecto)`);
  }

  /**
   * Manejar mensajes recibidos de OpenAI
   * @param {string} streamSid - ID del stream
   * @param {Buffer} data - Datos del mensaje
   */
  handleOpenAIMessage(streamSid, data) {
    try {
      const response = JSON.parse(data.toString());
      const connectionData = this.activeConnections.get(streamSid);

      if (!connectionData) {
        logger.warn(`‚ö†Ô∏è [${streamSid}] Mensaje OpenAI recibido pero no hay conexi√≥n activa`);
        return;
      }

      // ‚úÖ EVENTOS PARA DIAGN√ìSTICO COMPLETO
      const LOG_EVENT_TYPES = [
        'error',
        'response.content.done',
        'response.text.done',        
        'response.text.delta',       
        'rate_limits.updated',
        'response.done',
        'input_audio_buffer.committed',
        'input_audio_buffer.speech_stopped',
        'input_audio_buffer.speech_started',
        'session.created',
        'session.updated',
        'conversation.item.input_audio_transcription.completed',
        'conversation.item.input_audio_transcription.failed',
        'response.created',
        'input_audio_buffer.cleared',
        'conversation.item.created',
        'response.output_item.added',
        'response.output_item.done'
      ];

      if (LOG_EVENT_TYPES.includes(response.type)) {
        logger.info(`üì® [${streamSid}] OpenAI Event: ${response.type}`, response);
      }

      // üîç LOG TODOS LOS EVENTOS PARA DIAGN√ìSTICO
      if (!LOG_EVENT_TYPES.includes(response.type)) {
        logger.debug(`üîç [${streamSid}] OpenAI Event (no filtrado): ${response.type}`);
      }

      // Procesar diferentes tipos de mensajes
      switch (response.type) {
        case 'session.updated':
          logger.info(`‚úÖ [${streamSid}] Sesi√≥n OpenAI configurada correctamente`);
          logger.info(`üîç [${streamSid}] üìä SESSION.UPDATED COMPLETO: ${JSON.stringify(response, null, 2)}`);
          
          // DEBUG: Verificar configuraci√≥n aplicada OFICIAL
          if (response.session) {
            logger.info(`üîç [${streamSid}] ‚úÖ CONFIGURACI√ìN APLICADA POR OPENAI:`);
            logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Session Type: ${response.session.type || 'N/A'}`);
            logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Model aplicado: ${response.session.model || 'N/A'}`);
            logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Instructions aplicadas: ${response.session.instructions ? 'SI' : 'NO'}`);
            if (response.session.audio) {
              logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Audio config: DEFAULTS aplicados por OpenAI`);
              logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ VAD: ${response.session.audio.input?.turn_detection?.type || 'default'}`);
            }
            logger.info(`üîç [${streamSid}] ‚îî‚îÄ‚îÄ ‚úÖ CONFIGURACI√ìN OFICIAL APLICADA CORRECTAMENTE`);
          }
          
          connectionData.status = 'ready';
          logger.info(`üöÄ [${streamSid}] ‚úÖ OpenAI LISTO para recibir audio - Status: ready`);
          break;

        case 'input_audio_buffer.speech_started':
          logger.info(`üé§ [${streamSid}] ‚úÖ VAD DETECT√ì VOZ - Speech started!`);
          break;

        case 'input_audio_buffer.speech_stopped':
          logger.info(`üîá [${streamSid}] ‚úÖ VAD TERMIN√ì VOZ - Speech stopped!`);
          break;

        case 'conversation.item.input_audio_transcription.completed':
          logger.info(`üìù [${streamSid}] ‚úÖ TRANSCRIPCI√ìN COMPLETADA: ${response.transcript || 'N/A'}`);
          break;

        case 'response.created':
          logger.info(`üöÄ [${streamSid}] ‚úÖ OPENAI CREANDO RESPUESTA`);
          break;

        case 'response.text.delta':
          // ‚úÖ NUEVO FLUJO: Acumular texto de OpenAI para Azure TTS
          if (response.delta) {
            logger.info(`üìù [${streamSid}] ‚úÖ RECIBIENDO texto delta de OpenAI`);
            logger.debug(`üîç [${streamSid}] Texto delta: "${response.delta}"`);
            
            // Acumular texto (como c√≥digo oficial acumula audio)
            if (!connectionData.accumulatedText) {
              connectionData.accumulatedText = '';
            }
            
            // ‚úÖ PROTECCI√ìN ANTI-BUCLE: L√≠mite de texto por respuesta
            if (connectionData.accumulatedText.length > 1500) {
              logger.warn(`‚ö†Ô∏è [${streamSid}] L√çMITE DE TEXTO ALCANZADO - Interrumpiendo respuesta (${connectionData.accumulatedText.length} chars)`);
              // Forzar finalizaci√≥n de respuesta inmediata
              this.processTextWithAzureTTS(streamSid, connectionData.accumulatedText);
              connectionData.accumulatedText = '';
              break;
            }
            
            connectionData.accumulatedText += response.delta;
            
            if (response.item_id) {
              connectionData.lastAssistantItem = response.item_id;
              logger.debug(`üÜî [${streamSid}] Assistant item ID: ${response.item_id}`);
            }
          }
          break;

        case 'session.updated':
          // ‚úÖ CONFIRMAR que configuraci√≥n fue aceptada
          logger.info(`‚öôÔ∏è [${streamSid}] ‚úÖ SESSION UPDATED - Configuraci√≥n aplicada exitosamente`);
          logger.info(`‚öôÔ∏è [${streamSid}] üìä Modalities: ${JSON.stringify(response.session.modalities)}`);
          logger.info(`‚öôÔ∏è [${streamSid}] üìä Max tokens: ${response.session.max_response_output_tokens}`);
          logger.info(`‚öôÔ∏è [${streamSid}] üìä Input transcription: ${response.session.input_audio_transcription ? 'enabled' : 'disabled'}`);
          
          // Marcar sesi√≥n como lista para recibir audio
          connectionData.status = 'ready';
          logger.info(`‚úÖ [${streamSid}] OpenAI listo para recibir audio del usuario`);
          break;

        case 'response.text.done':
          // ‚úÖ NUEVO FLUJO: Texto completo listo para Azure TTS
          logger.info(`üìù [${streamSid}] ‚úÖ TEXTO COMPLETO de OpenAI - Enviando a Azure TTS`);
          logger.debug(`üîç [${streamSid}] üìä Text.done DETAILS: ${JSON.stringify(response)}`);
          
          if (connectionData.accumulatedText) {
            logger.info(`üéØ [${streamSid}] üìù RESPUESTA OPENAI COMPLETA (${connectionData.accumulatedText.length} chars):`);
            logger.info(`üéØ [${streamSid}] "${connectionData.accumulatedText}"`);
            
            // ‚úÖ PROTECCI√ìN: Solo textos razonables para TTS
            if (connectionData.accumulatedText.length > 500) {
              logger.warn(`‚ö†Ô∏è [${streamSid}] TEXTO DEMASIADO LARGO - Truncando a 500 chars`);
              connectionData.accumulatedText = connectionData.accumulatedText.substring(0, 500);
            }
            
            logger.info(`üöÄ [${streamSid}] Texto final para Azure TTS: "${connectionData.accumulatedText}"`);
            logger.debug(`üîç [${streamSid}] üìä AccumulatedText length: ${connectionData.accumulatedText.length} chars`);
            
            // Enviar texto completo a Azure TTS (como saludo inicial)
            this.processTextWithAzureTTS(streamSid, connectionData.accumulatedText);
            
            // Limpiar texto acumulado
            connectionData.accumulatedText = '';
          } else {
            logger.warn(`‚ö†Ô∏è [${streamSid}] No hay texto acumulado para Azure TTS`);
            logger.debug(`üîç [${streamSid}] üìä ConnectionData keys: ${Object.keys(connectionData)}`);
          }
          break;

        case 'response.audio.delta':
        case 'response.audio.done':
        case 'response.audio_transcript.delta':
        case 'response.audio_transcript.done':
        case 'response.output_audio.delta':
          // ‚úÖ SOLUCI√ìN OFICIAL: Ignorar audio seg√∫n documentaci√≥n 
          logger.warn(`‚ö†Ô∏è [${streamSid}] Audio detectado (bug OpenAI conocido) - Ignorando: ${response.type}`);
          logger.debug(`üîç [${streamSid}] Audio ignorado - Solo procesamos texto con response.create`);
          // Descartamos cualquier respuesta de audio para forzar solo texto
          break;

        case 'response.output_audio_transcript.delta':
          // ‚úÖ PROCESAR transcripci√≥n de audio generado por OpenAI
          logger.info(`üìù [${streamSid}] ‚úÖ TRANSCRIPCI√ìN AUDIO DELTA de OpenAI`);
          if (response.delta) {
            logger.debug(`üîç [${streamSid}] Transcripci√≥n delta: "${response.delta}"`);
            
            // Acumular transcripci√≥n del audio generado
            if (!connectionData.audioTranscript) {
              connectionData.audioTranscript = '';
            }
            connectionData.audioTranscript += response.delta;
            logger.debug(`üîç [${streamSid}] Transcripci√≥n acumulada: "${connectionData.audioTranscript}"`);
          }
          break;


        case 'response.done':
          logger.info(`‚úÖ [${streamSid}] üìù OpenAI response.done - Procesando transcripci√≥n acumulada`);
          
          // üîç DEBUG: ANALIZAR RESPUESTA OPENAI para logs
          logger.info(`üîç [${streamSid}] üìä RESPONSE STATS:`);
          logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Response ID: ${response.response?.id || 'N/A'}`);
          logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Status: ${response.response?.status || 'N/A'}`);
          
          // ‚úÖ PROCESAR TRANSCRIPCI√ìN ACUMULADA ‚Üí Azure TTS
          if (connectionData.audioTranscript) {
            logger.info(`üöÄ [${streamSid}] Enviando transcripci√≥n completa a Azure TTS: "${connectionData.audioTranscript}"`);
            logger.debug(`üîç [${streamSid}] üìä Transcripci√≥n length: ${connectionData.audioTranscript.length} chars`);
            
            // Enviar transcripci√≥n completa a Azure TTS (como texto normal)
            this.processTextWithAzureTTS(streamSid, connectionData.audioTranscript);
            
            // Limpiar transcripci√≥n acumulada
            connectionData.audioTranscript = '';
          } else {
            logger.warn(`‚ö†Ô∏è [${streamSid}] No hay transcripci√≥n acumulada para procesar`);
          }
          
          logger.info(`üîç [${streamSid}] ‚îî‚îÄ‚îÄ ‚úÖ Respuesta procesada completamente`);
          break;

        case 'input_audio_buffer.speech_started':
          logger.info(`üé§ [${streamSid}] OpenAI detect√≥ inicio de habla del usuario`);
          logger.info(`üîç [${streamSid}] üìä SPEECH_STARTED COMPLETO: ${JSON.stringify(response, null, 2)}`);
          // C√ìDIGO OFICIAL: Manejar interrupciones
          this.handleSpeechStartedEvent(streamSid);
          break;

        case 'input_audio_buffer.speech_stopped':
          logger.info(`üé§ [${streamSid}] OpenAI detect√≥ fin de habla del usuario`);
          logger.info(`üöÄ [${streamSid}] ESPERANDO respuesta autom√°tica de OpenAI...`);
          logger.info(`üîç [${streamSid}] üìä SPEECH_STOPPED COMPLETO: ${JSON.stringify(response, null, 2)}`);
          
          // DEBUG CR√çTICO: Estado de la sesi√≥n cuando se detecta fin de habla
          logger.info(`üîç [${streamSid}] ‚úÖ ESTADO ESPERADO DESPU√âS DE SPEECH_STOPPED:`);
          logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Deber√≠a llegar: conversation.item.input_audio_transcription.completed`);
          logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Luego deber√≠a llegar: response.created`);
          logger.info(`üîç [${streamSid}] ‚îú‚îÄ‚îÄ Luego deber√≠a llegar: response.text.delta(s)`);
          logger.info(`üîç [${streamSid}] ‚îî‚îÄ‚îÄ Finalmente: response.text.done`);
          break;

        case 'conversation.item.input_audio_transcription.completed':
          logger.info(`üìù [${streamSid}] ‚úÖ TRANSCRIPCI√ìN COMPLETADA - √âXITO!`);
          logger.info(`üîç [${streamSid}] üìä TRANSCRIPTION COMPLETA: ${JSON.stringify(response, null, 2)}`);
          
          // Extraer texto transcrito
          const transcript = response.transcript || response.content || 'N/A';
          logger.info(`üó£Ô∏è [${streamSid}] TEXTO TRANSCRITO: "${transcript}"`);
          break;

        case 'conversation.item.input_audio_transcription.failed':
          logger.error(`‚ùå [${streamSid}] TRANSCRIPCI√ìN FALL√ì - ERROR CR√çTICO!`);
          logger.error(`üîç [${streamSid}] üìä TRANSCRIPTION ERROR: ${JSON.stringify(response, null, 2)}`);
          
          // Diagn√≥stico del error
          const error = response.error || 'Error desconocido';
          logger.error(`üí• [${streamSid}] CAUSA DEL ERROR: ${JSON.stringify(error)}`);
          break;

        case 'response.created':
          logger.info(`üöÄ [${streamSid}] ‚úÖ OpenAI GENERANDO RESPUESTA - √âXITO!`);
          logger.info(`üîç [${streamSid}] üìä RESPONSE.CREATED COMPLETO: ${JSON.stringify(response, null, 2)}`);
          
          // Debug del response ID
          const responseId = response.response?.id || 'N/A';
          logger.info(`üÜî [${streamSid}] Response ID: ${responseId}`);
          break;

        case 'response.output_audio.started':
          logger.info(`üéµ [${streamSid}] ‚úÖ OpenAI INICIANDO AUDIO DE RESPUESTA`);
          break;

        case 'error':
          logger.error(`‚ùå [${streamSid}] ERROR CR√çTICO DE OPENAI`);
          logger.error(`üîç [${streamSid}] üìä ERROR COMPLETO: ${JSON.stringify(response, null, 2)}`);
          
          // Diagn√≥stico espec√≠fico del error
          if (response.error) {
            logger.error(`üí• [${streamSid}] Error Type: ${response.error.type || 'N/A'}`);
            logger.error(`üí• [${streamSid}] Error Code: ${response.error.code || 'N/A'}`);
            logger.error(`üí• [${streamSid}] Error Message: ${response.error.message || 'N/A'}`);
            
            // Errores espec√≠ficos de configuraci√≥n
            if (response.error.message && response.error.message.includes('Unknown parameter')) {
              logger.error(`‚ö†Ô∏è [${streamSid}] PROBLEMA DE CONFIGURACI√ìN detectado!`);
            }
          }
          break;

        default:
          // Capturar eventos no esperados que podr√≠an ser importantes
          if (!['rate_limits.updated', 'conversation.item.done', 'response.output_item.done'].includes(response.type)) {
            logger.info(`üì® [${streamSid}] Evento OpenAI no manejado: ${response.type}`);
            logger.debug(`üîç [${streamSid}] üìä Evento completo: ${JSON.stringify(response, null, 2)}`);
          } else {
            logger.debug(`üì® [${streamSid}] Mensaje OpenAI: ${response.type}`);
          }
      }

    } catch (error) {
      logger.error(`‚ùå [${streamSid}] Error procesando mensaje OpenAI: ${error.message}`);
    }
  }

  /**
   * C√ìDIGO OFICIAL: Handle interruption when the caller's speech starts
   * @param {string} streamSid - Stream ID
   */
  handleSpeechStartedEvent(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) return;

    // üîç DEBUG: Estado actual antes de procesar interrupci√≥n
    logger.info(`üé§ [${streamSid}] SPEECH STARTED - Estado del stream:`);
    logger.info(`üé§ [${streamSid}] ‚îú‚îÄ‚îÄ markQueue.length: ${connectionData.markQueue.length}`);
    logger.info(`üé§ [${streamSid}] ‚îú‚îÄ‚îÄ responseStartTimestamp: ${connectionData.responseStartTimestampTwilio}`);
    logger.info(`üé§ [${streamSid}] ‚îú‚îÄ‚îÄ lastAssistantItem: ${connectionData.lastAssistantItem}`);
    logger.info(`üé§ [${streamSid}] ‚îî‚îÄ‚îÄ latestMediaTimestamp: ${connectionData.latestMediaTimestamp}`);

    // C√ÅLCULO EXACTO del c√≥digo oficial - SOLO interrumpir si hay respuesta activa
    if (connectionData.markQueue.length > 0 && connectionData.responseStartTimestampTwilio != null) {
      const elapsedTime = connectionData.latestMediaTimestamp - connectionData.responseStartTimestampTwilio;
      logger.info(`‚è±Ô∏è [${streamSid}] ‚úÖ HAY RESPUESTA ACTIVA - Interrumpiendo`);
      logger.info(`‚è±Ô∏è [${streamSid}] Calculating elapsed time: ${connectionData.latestMediaTimestamp} - ${connectionData.responseStartTimestampTwilio} = ${elapsedTime}ms`);

      if (connectionData.lastAssistantItem) {
        const truncateEvent = {
          type: 'conversation.item.truncate',
          item_id: connectionData.lastAssistantItem,
          content_index: 0,
          audio_end_ms: elapsedTime
        };
        logger.info(`üîÑ [${streamSid}] Sending truncation event: ${JSON.stringify(truncateEvent)}`);
        connectionData.ws.send(JSON.stringify(truncateEvent));
      }

      // EMITIR CLEAR EVENT para Twilio (ser√° manejado por TwilioStreamHandler)
      this.emit('clearAudio', {
        streamSid: streamSid
      });

      // Reset (exacto del c√≥digo oficial)
      connectionData.markQueue = [];
      connectionData.lastAssistantItem = null;
      connectionData.responseStartTimestampTwilio = null;
      
      logger.info(`‚úÖ [${streamSid}] Interrupci√≥n procesada y estado reseteado`);
    } else {
      // üéØ CLAVE: Si no hay respuesta activa, NO interrumpir
      logger.info(`‚ö†Ô∏è [${streamSid}] NO HAY RESPUESTA ACTIVA - Ignorando speech_started`);
      logger.info(`‚ö†Ô∏è [${streamSid}] markQueue: ${connectionData.markQueue.length}, responseStart: ${connectionData.responseStartTimestampTwilio}`);
    }
  }


  // üóëÔ∏è M√âTODO OBSOLETO ELIMINADO: processAudioDeltaImmediate()
  // RAZ√ìN: Solo usamos transcripci√≥n de OpenAI ‚Üí Azure TTS, no audio directo

  /**
   * ‚úÖ NUEVO FLUJO SIMPLE: Procesar texto de OpenAI con Azure TTS (como saludo inicial)
   * @param {string} streamSid - Stream ID
   * @param {string} text - Texto completo de OpenAI
   */
  async processTextWithAzureTTS(streamSid, text) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) {
      logger.error(`‚ùå [${streamSid}] No connection data para procesar texto`);
      return;
    }

    try {
      logger.info(`üöÄ [${streamSid}] ‚úÖ PROCESANDO texto con Azure TTS: "${text}"`);
      
      // Emitir evento simple para TwilioStreamHandler (como saludo inicial)
      this.emit('processTextWithAzure', {
        streamSid: streamSid,
        text: text, // ‚úÖ SIMPLE: Solo texto
        timestamp: Date.now()
      });
      
      logger.debug(`‚úÖ [${streamSid}] Texto enviado para Azure TTS`);

    } catch (error) {
      logger.error(`‚ùå [${streamSid}] Error procesando texto: ${error.message}`);
    }
  }

  /**
   * Enviar audio del usuario a OpenAI (mulaw de Twilio ‚Üí PCM16 para OpenAI)
   * @param {string} streamSid - ID del stream
   * @param {string} audioPayload - Audio en base64 desde Twilio (mulaw)
   */
  sendAudioToOpenAI(streamSid, audioPayload, mediaTimestamp) {
    const connectionData = this.activeConnections.get(streamSid);
    // ‚úÖ PERMITIR audio en 'connected' Y 'ready' - conexi√≥n WebSocket ya est√° abierta
    if (!connectionData || (connectionData.status !== 'connected' && connectionData.status !== 'ready')) {
      logger.debug(`‚ö†Ô∏è [${streamSid}] Conexi√≥n no lista para audio - Status: ${connectionData?.status || 'N/A'}`);
      return; // No hay conexi√≥n lista
    }

    try {
      // C√ìDIGO OFICIAL: Actualizar timestamp
      if (mediaTimestamp) {
        connectionData.latestMediaTimestamp = mediaTimestamp;
        logger.debug(`‚è±Ô∏è [${streamSid}] Updated media timestamp: ${mediaTimestamp}ms`);
      }

      // üéØ CONVERSI√ìN CR√çTICA: mulaw (Twilio) ‚Üí PCM (OpenAI)
      const mulawBuffer = Buffer.from(audioPayload, 'base64');
      logger.debug(`üîç [${streamSid}] Twilio mulaw: ${mulawBuffer.length} bytes ‚Üí Convirtiendo a PCM para OpenAI`);
      
      // ‚úÖ CONVERSI√ìN: mulaw 8kHz ‚Üí PCM 24kHz (formato requerido por OpenAI)
      const pcmBuffer = this.convertMulawToPCM24k(mulawBuffer);
      const pcmBase64 = pcmBuffer.toString('base64');
      
      const audioMessage = {
        type: 'input_audio_buffer.append',
        audio: pcmBase64  // PCM convertido para OpenAI
      };

      connectionData.ws.send(JSON.stringify(audioMessage));
      logger.debug(`‚úÖ [${streamSid}] Audio PCM enviado (${pcmBase64.length} chars base64, ${pcmBuffer.length} bytes PCM)`);
      logger.debug(`üéôÔ∏è [${streamSid}] Audio enviado a OpenAI Realtime`);
      
      // DEBUG ADICIONAL: Estado de la conexi√≥n y contadores
      connectionData.audioSent = (connectionData.audioSent || 0) + 1;
      
      // üîç AN√ÅLISIS CR√çTICO: Detectar si audio tiene contenido real
      const mulawBytes = Buffer.from(audioPayload, 'base64');
      const silentBytes = mulawBytes.filter(byte => byte === 0xFF).length;
      const audioPercent = ((mulawBytes.length - silentBytes) / mulawBytes.length * 100).toFixed(1);
      
      if (connectionData.audioSent % 50 === 0) {  // Log cada 50 chunks
        logger.info(`üìä [${streamSid}] ===== DIAGN√ìSTICO VAD CR√çTICO =====`);
        logger.info(`üìä [${streamSid}] ‚îú‚îÄ‚îÄ Audio chunks enviados: ${connectionData.audioSent}`);
        logger.info(`üìä [${streamSid}] ‚îú‚îÄ‚îÄ Conexi√≥n status: ${connectionData.status}`);
        logger.info(`üìä [${streamSid}] ‚îú‚îÄ‚îÄ WebSocket readyState: ${connectionData.ws.readyState}`);
        logger.info(`üìä [${streamSid}] ‚îú‚îÄ‚îÄ Audio content: ${audioPercent}% non-silent`);
        logger.info(`üìä [${streamSid}] ‚îú‚îÄ‚îÄ √öltimo chunk: ${mulawBytes.length} bytes, ${silentBytes} silent`);
        logger.info(`üìä [${streamSid}] ‚îî‚îÄ‚îÄ üö® Si >30% audio y NO hay speech_started = PROBLEMA VAD`);
      }
      
      // üö® ALERTA CR√çTICA: Si hay mucho contenido pero no speech_started
      if (audioPercent > 30) {
        logger.warn(`üö® [${streamSid}] AUDIO REAL DETECTADO: ${audioPercent}% content - VAD deber√≠a detectar!`);
      }
    } catch (error) {
      logger.error(`‚ùå [${streamSid}] Error enviando audio a OpenAI: ${error.message}`);
    }
  }

  /**
   * üö® DEBUG: Extraer texto de respuesta OpenAI para an√°lisis
{{ ... }}
   * @returns {string} - Texto extra√≠do
   */
  extractTextFromResponse(response) {
    try {
      // Buscar en diferentes ubicaciones donde OpenAI puede poner el texto
      if (response.response?.output?.[0]?.content?.[0]?.transcript) {
        return response.response.output[0].content[0].transcript;
      }
      
      // Buscar en items de la respuesta
      if (response.response?.output?.[0]?.content) {
        const content = response.response.output[0].content;
        for (const item of content) {
          if (item.transcript) return item.transcript;
          if (item.text) return item.text;
        }
      }
      
      
      return 'N/A';
    } catch (error) {
      return `Error: ${error.message}`;
    }
  }

  /**
   * C√ìDIGO OFICIAL: Send mark messages to Media Streams 
   * @param {string} streamSid - Stream ID
   */
  sendMark(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) return;

    // Emitir evento para que TwilioStreamHandler env√≠e la marca a Twilio
    this.emit('sendMark', {
      streamSid: streamSid,
      markName: 'responsePart'
    });

    // Agregar a queue como en c√≥digo oficial
    connectionData.markQueue.push('responsePart');
  }




  /**
   * Cerrar conexi√≥n OpenAI para un stream
   * @param {string} streamSid - ID del stream
   */
  async closeConnection(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) {
      return;
    }

    logger.info(`üîå [${streamSid}] Cerrando conexi√≥n OpenAI Realtime`);
    
    try {
      if (connectionData.ws && connectionData.ws.readyState === WebSocket.OPEN) {
        connectionData.ws.close(1000, 'Stream ended');
      }
    } catch (error) {
      logger.error(`‚ùå [${streamSid}] Error cerrando conexi√≥n OpenAI: ${error.message}`);
    }

    this.activeConnections.delete(streamSid);
  }

  /**
   * Convertir audio mulaw 8kHz (Twilio) a PCM 24kHz (OpenAI)
   * @param {Buffer} mulawBuffer - Buffer mulaw de Twilio
   * @returns {Buffer} - Buffer PCM 16-bit 24kHz para OpenAI
   */
  convertMulawToPCM24k(mulawBuffer) {
    // üéØ TABLA DE CONVERSI√ìN Œº-law ‚Üí PCM lineal (est√°ndar ITU-T G.711)
    const MULAW_TO_LINEAR = [
      -32124, -31100, -30076, -29052, -28028, -27004, -25980, -24956,
      -23932, -22908, -21884, -20860, -19836, -18812, -17788, -16764,
      -15996, -15484, -14972, -14460, -13948, -13436, -12924, -12412,
      -11900, -11388, -10876, -10364, -9852, -9340, -8828, -8316,
      -7932, -7676, -7420, -7164, -6908, -6652, -6396, -6140,
      -5884, -5628, -5372, -5116, -4860, -4604, -4348, -4092,
      -3900, -3772, -3644, -3516, -3388, -3260, -3132, -3004,
      -2876, -2748, -2620, -2492, -2364, -2236, -2108, -1980,
      -1884, -1820, -1756, -1692, -1628, -1564, -1500, -1436,
      -1372, -1308, -1244, -1180, -1116, -1052, -988, -924,
      -876, -844, -812, -780, -748, -716, -684, -652,
      -620, -588, -556, -524, -492, -460, -428, -396,
      -372, -356, -340, -324, -308, -292, -276, -260,
      -244, -228, -212, -196, -180, -164, -148, -132,
      -120, -112, -104, -96, -88, -80, -72, -64,
      -56, -48, -40, -32, -24, -16, -8, 0,
      32124, 31100, 30076, 29052, 28028, 27004, 25980, 24956,
      23932, 22908, 21884, 20860, 19836, 18812, 17788, 16764,
      15996, 15484, 14972, 14460, 13948, 13436, 12924, 12412,
      11900, 11388, 10876, 10364, 9852, 9340, 8828, 8316,
      7932, 7676, 7420, 7164, 6908, 6652, 6396, 6140,
      5884, 5628, 5372, 5116, 4860, 4604, 4348, 4092,
      3900, 3772, 3644, 3516, 3388, 3260, 3132, 3004,
      2876, 2748, 2620, 2492, 2364, 2236, 2108, 1980,
      1884, 1820, 1756, 1692, 1628, 1564, 1500, 1436,
      1372, 1308, 1244, 1180, 1116, 1052, 988, 924,
      876, 844, 812, 780, 748, 716, 684, 652,
      620, 588, 556, 524, 492, 460, 428, 396,
      372, 356, 340, 324, 308, 292, 276, 260,
      244, 228, 212, 196, 180, 164, 148, 132,
      120, 112, 104, 96, 88, 80, 72, 64,
      56, 48, 40, 32, 24, 16, 8, 0
    ];

    // üîÑ PASO 1: Convertir Œº-law ‚Üí PCM 16-bit
    const pcm8k = Buffer.alloc(mulawBuffer.length * 2); // 2 bytes por sample
    for (let i = 0; i < mulawBuffer.length; i++) {
      const linear = MULAW_TO_LINEAR[mulawBuffer[i]];
      pcm8k.writeInt16LE(linear, i * 2);
    }

    // üîÑ PASO 2: Upsample 8kHz ‚Üí 24kHz (factor 3)
    const pcm24k = Buffer.alloc(pcm8k.length * 3); // 3x m√°s samples
    for (let i = 0; i < pcm8k.length / 2; i++) {
      const sample = pcm8k.readInt16LE(i * 2);
      // Interpolaci√≥n simple: repetir cada sample 3 veces
      pcm24k.writeInt16LE(sample, (i * 3) * 2);
      pcm24k.writeInt16LE(sample, (i * 3 + 1) * 2);
      pcm24k.writeInt16LE(sample, (i * 3 + 2) * 2);
    }

    return pcm24k;
  }

  /**
   * Obtener estad√≠sticas del servicio
   */
  getStats() {
    const connections = Array.from(this.activeConnections.values());
    return {
      activeConnections: connections.length,
      connectionsByStatus: connections.reduce((acc, conn) => {
        acc[conn.status] = (acc[conn.status] || 0) + 1;
        return acc;
      }, {}),
      totalMessages: connections.reduce((sum, conn) => sum + conn.messageCount, 0)
    };
  }

  /**
   * Verificar si hay conexi√≥n activa para un stream
   * @param {string} streamSid - ID del stream
   * @returns {boolean}
   */
  isConnectionActive(streamSid) {
    const connectionData = this.activeConnections.get(streamSid);
    // ‚úÖ PERMITIR audio en 'connected' Y 'ready' - conexi√≥n WebSocket ya est√° abierta
    return connectionData && (connectionData.status === 'connected' || connectionData.status === 'ready');
  }

  /**
   * C√ìDIGO OFICIAL: Process mark completion (como en el c√≥digo original)
   * @param {string} streamSid - Stream ID
   * @param {string} markName - Nombre de la marca procesada
   */
  processMarkCompletion(streamSid, markName) {
    const connectionData = this.activeConnections.get(streamSid);
    if (!connectionData) return;

    // EXACTO del c√≥digo oficial: remover del queue
    if (connectionData.markQueue.length > 0) {
      connectionData.markQueue.shift();
      logger.debug(`üìç [${streamSid}] Marca ${markName} removida del queue (${connectionData.markQueue.length} restantes)`);
    }
  }
}

// Agregar EventEmitter CORRECTO - mixina en la clase original
const { EventEmitter } = require('events');

// MIXINA CORRECTA: Agregar EventEmitter a la clase existente sin herencia
Object.assign(OpenAIRealtimeService.prototype, EventEmitter.prototype);

// Llamar constructor EventEmitter en constructor original
const originalConstructor = OpenAIRealtimeService.prototype.constructor;
OpenAIRealtimeService.prototype.constructor = function(...args) {
  originalConstructor.apply(this, args);
  EventEmitter.call(this);
};

module.exports = OpenAIRealtimeService;
