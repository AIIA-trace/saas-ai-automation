const axios = require('axios');
const logger = require('../utils/logger');

class OpenAIService {
  constructor() {
    this.apiKey = process.env.OPENAI_API_KEY;
    this.baseUrl = 'https://api.openai.com/v1';
    this.headers = {
      'Authorization': `Bearer ${this.apiKey}`,
      'Content-Type': 'application/json'
    };
  }

  // Transcribir audio usando Whisper API
  async transcribeAudio(audioUrl) {
    try {
      // Primero descargamos el audio de la URL
      const audioResponse = await axios.get(audioUrl, { responseType: 'arraybuffer' });
      const audioBuffer = Buffer.from(audioResponse.data);
      
      // Crear un FormData para la API de Whisper
      const formData = new FormData();
      const audioBlob = new Blob([audioBuffer], { type: 'audio/wav' });
      formData.append('file', audioBlob, 'audio.wav');
      formData.append('model', 'whisper-1');
      formData.append('language', 'es');
      
      // Enviar a la API de Whisper
      const response = await axios.post(
        `${this.baseUrl}/audio/transcriptions`,
        formData,
        { headers: { ...this.headers, 'Content-Type': 'multipart/form-data' } }
      );
      
      return {
        success: true,
        transcription: response.data.text
      };
    } catch (error) {
      logger.error(`Error transcribiendo audio: ${error.message}`);
      return {
        success: false,
        error: error.message
      };
    }
  }
  
  // Analizar texto (transcripci√≥n o email) para extraer informaci√≥n clave
  async analyzeText(text, companyInfo, type = 'call') {
    try {
      let systemPrompt = '';
      
      if (type === 'call') {
        systemPrompt = `Eres un asistente encargado de analizar transcripciones de llamadas telef√≥nicas para la empresa ${companyInfo.companyName}. 
        Tu tarea es extraer la siguiente informaci√≥n en formato JSON:
        1. Nombre del llamante (si se menciona)
        2. N√∫mero de tel√©fono de contacto (si se menciona)
        3. Motivo principal de la llamada
        4. Nivel de urgencia (bajo, medio, alto)
        5. Clasificaci√≥n del tipo de llamada (consulta, queja, solicitud de informaci√≥n, etc.)
        6. Resumen breve y conciso de la llamada (m√°ximo 2 frases)
        
        Informaci√≥n sobre la empresa: ${companyInfo.description || ''}`;
      } else if (type === 'email') {
        systemPrompt = `Eres un asistente encargado de analizar emails recibidos para la empresa ${companyInfo.companyName}. 
        Tu tarea es extraer la siguiente informaci√≥n en formato JSON:
        1. Nombre del remitente
        2. Informaci√≥n de contacto proporcionada
        3. Motivo principal del email
        4. Nivel de urgencia (bajo, medio, alto)
        5. Clasificaci√≥n del tipo de email (consulta, queja, solicitud de informaci√≥n, etc.)
        6. Resumen breve y conciso del email (m√°ximo 3 frases)
        7. Palabras clave importantes para clasificaci√≥n
        
        Informaci√≥n sobre la empresa: ${companyInfo.description || ''}`;
      }
      
      // Llamar a la API de GPT
      const response = await axios.post(
        `${this.baseUrl}/chat/completions`,
        {
          model: 'gpt-4',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: text }
          ],
          temperature: 0.3,
          max_tokens: 500
        },
        { headers: this.headers }
      );
      
      // Intentar parsear la respuesta como JSON
      try {
        const content = response.data.choices[0].message.content;
        // Extraer JSON si est√° entre comillas
        const jsonMatch = content.match(/```json([\s\S]*?)```/) || content.match(/```([\s\S]*?)```/);
        const jsonString = jsonMatch ? jsonMatch[1].trim() : content;
        const result = JSON.parse(jsonString);
        
        return {
          success: true,
          analysis: result,
          rawResponse: content
        };
      } catch (parseError) {
        logger.error(`Error parseando respuesta JSON: ${parseError.message}`);
        return {
          success: true,
          analysis: null,
          rawResponse: response.data.choices[0].message.content
        };
      }
    } catch (error) {
      logger.error(`Error analizando texto: ${error.message}`);
      return {
        success: false,
        error: error.message
      };
    }
  }
  
  // Determinar a qui√©n reenviar un email basado en reglas de cliente
  async determineEmailForwarding(emailData, emailConfig) {
    try {
      const forwardingRules = emailConfig.forwardingRules || [];
      
      if (forwardingRules.length === 0) {
        return {
          success: true,
          recipients: emailConfig.defaultRecipients || []
        };
      }
      
      // Crear prompt para evaluar reglas
      const systemPrompt = `Eres un asistente encargado de determinar a qu√© direcciones de email debe reenviarse un correo entrante.
      Evaluar√°s el contenido del correo contra un conjunto de reglas y devolver√°s la lista de direcciones a las que debe reenviarse.
      
      Reglas de reenv√≠o (en formato JSON):
      ${JSON.stringify(forwardingRules)}
      
      Debes analizar el asunto y cuerpo del email, y determinar qu√© reglas se cumplen.
      Si se cumplen varias reglas, incluye todas las direcciones correspondientes.
      Si no se cumple ninguna regla, utiliza los destinatarios por defecto.
      
      Responde √∫nicamente con un objeto JSON con la siguiente estructura:
      { "recipients": ["email1@dominio.com", "email2@dominio.com"] }`;
      
      // Llamar a la API de GPT
      const response = await axios.post(
        `${this.baseUrl}/chat/completions`,
        {
          model: 'gpt-4',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: `
              Asunto: ${emailData.subject}
              Cuerpo: ${emailData.body}
            `}
          ],
          temperature: 0.1,
          max_tokens: 300
        },
        { headers: this.headers }
      );
      
      // Intentar parsear la respuesta como JSON
      try {
        const content = response.data.choices[0].message.content;
        // Extraer JSON si est√° entre comillas
        const jsonMatch = content.match(/```json([\s\S]*?)```/) || content.match(/```([\s\S]*?)```/);
        const jsonString = jsonMatch ? jsonMatch[1].trim() : content;
        const result = JSON.parse(jsonString);
        
        if (!result.recipients || !Array.isArray(result.recipients)) {
          throw new Error('Formato de respuesta inv√°lido');
        }
        
        return {
          success: true,
          recipients: result.recipients
        };
      } catch (parseError) {
        logger.error(`Error parseando respuesta de forwarding: ${parseError.message}`);
        return {
          success: true,
          recipients: emailConfig.defaultRecipients || [],
          parseError: true
        };
      }
    } catch (error) {
      logger.error(`Error determinando reenv√≠o de email: ${error.message}`);
      return {
        success: false,
        error: error.message,
        recipients: emailConfig.defaultRecipients || []
      };
    }
  }
  
  // Generar respuesta conversacional de recepcionista
  async generateReceptionistResponse(transcribedText, clientConfig, conversationContext = {}) {
    try {
      logger.info(`ü§ñ [OpenAI] Iniciando generaci√≥n de respuesta para: "${transcribedText}"`);
      
      // DEBUG: Mostrar toda la configuraci√≥n del cliente recibida
      logger.info(`üîç [DEBUG] ClientConfig completo recibido:`);
      logger.info(`üîç [DEBUG] - ID: ${clientConfig.id}`);
      logger.info(`üîç [DEBUG] - companyName: "${clientConfig.companyName}"`);
      logger.info(`üîç [DEBUG] - companyDescription: "${clientConfig.companyDescription}"`);
      logger.info(`üîç [DEBUG] - industry: "${clientConfig.industry}"`);
      logger.info(`üîç [DEBUG] - businessHours: ${JSON.stringify(clientConfig.businessHours)}`);
      logger.info(`üîç [DEBUG] - botConfig: ${JSON.stringify(clientConfig.botConfig)}`);
      logger.info(`üîç [DEBUG] - callConfig: ${JSON.stringify(clientConfig.callConfig)}`);
      logger.info(`üîç [DEBUG] - faqs: ${JSON.stringify(clientConfig.faqs)}`);
      logger.info(`üîç [DEBUG] - contextFiles: ${JSON.stringify(clientConfig.contextFiles)}`);
      
      const companyName = clientConfig.companyName || 'nuestra empresa';
      const companyDescription = clientConfig.companyDescription || '';
      const industry = clientConfig.industry || '';
      const businessHours = clientConfig.businessHours || {};
      
      // Extraer informaci√≥n completa del cliente
      const botConfig = clientConfig.botConfig || {};
      const services = botConfig.services || [];
      const faqs = clientConfig.faqs || [];
      const contextFiles = clientConfig.contextFiles || [];
      const companyInfo = clientConfig.companyInfo || {};
      
      // DEBUG: Mostrar valores procesados
      logger.info(`üîç [DEBUG] Valores procesados para prompt:`);
      logger.info(`üîç [DEBUG] - companyName final: "${companyName}"`);
      logger.info(`üîç [DEBUG] - companyDescription final: "${companyDescription}"`);
      logger.info(`üîç [DEBUG] - industry final: "${industry}"`);
      logger.info(`üîç [DEBUG] - services final: ${JSON.stringify(services)}`);
      logger.info(`üîç [DEBUG] - faqs count: ${faqs.length}`);
      logger.info(`üîç [DEBUG] - contextFiles count: ${contextFiles.length}`);
      
      logger.debug(`üè¢ [OpenAI] Empresa: ${companyName}, Servicios: ${services.length}, FAQs: ${faqs.length}, Contexto: ${contextFiles.length}`);
      
      // Construir informaci√≥n de servicios
      const servicesText = services.length > 0 
        ? `\nSERVICIOS QUE OFRECEMOS:\n${services.map(s => `- ${s}`).join('\n')}`
        : '';
      
      // Construir informaci√≥n de horarios
      const hoursText = businessHours.enabled 
        ? `\nHORARIO DE ATENCI√ìN: ${businessHours.start || '9:00'} a ${businessHours.end || '18:00'}`
        : '';
        
      // Construir FAQs
      const faqsText = faqs.length > 0 
        ? `\nPREGUNTAS FRECUENTES:\n${faqs.map(faq => `P: ${faq.question}\nR: ${faq.answer}`).join('\n\n')}`
        : '';
        
      // Construir informaci√≥n de contexto
      const contextText = contextFiles.length > 0 
        ? `\nINFORMACI√ìN ADICIONAL DE LA EMPRESA:\n${contextFiles.map(ctx => `- ${ctx.title}: ${ctx.content}`).join('\n')}`
        : '';
        
      // Informaci√≥n adicional de la empresa
      const additionalInfo = companyInfo.description ? `\nDETALLES ADICIONALES: ${companyInfo.description}` : '';

      const systemPrompt = `Eres la recepcionista oficial de ${companyName}. Trabajas PARA esta empresa y eres parte del equipo. Tu misi√≥n es atender a los clientes de manera profesional, c√°lida y eficiente.

üè¢ INFORMACI√ìN DE LA EMPRESA:
- Nombre: ${companyName}
- Descripci√≥n: ${companyDescription}
- Industria: ${industry}${additionalInfo}${servicesText}${hoursText}${faqsText}${contextText}

üìã PAUTAS DE COMPORTAMIENTO OBLIGATORIAS:

1. **IDENTIDAD**: Eres Susan, empleada de ${companyName}. NUNCA digas "no puedo transcribir" o "soy una recepcionista virtual". Act√∫a como si fueras una persona real trabajando en la empresa.

2. **INFORMACI√ìN DE CONTACTO**: Si piden tel√©fonos, emails o direcciones, proporciona la informaci√≥n disponible o di "perm√≠teme consultar esa informaci√≥n y te la proporciono enseguida".

3. **SERVICIOS**: Conoces perfectamente todos los servicios. Si preguntan por algo espec√≠fico, explica detalladamente bas√°ndote en la informaci√≥n proporcionada.

4. **CITAS Y CONSULTAS**: Puedes tomar datos para agendar citas, consultas o reuniones. Di "perfecto, voy a tomar tus datos para coordinar eso".

5. **TRANSFERENCIAS**: Si necesitan hablar con alguien espec√≠fico, di "por supuesto, te voy a transferir con [departamento/persona]" o "tomo tus datos y te contactamos enseguida".

6. **TONO**: Siempre amable, profesional pero cercana. Usa "por supuesto", "perfecto", "enseguida te ayudo", "¬øen qu√© m√°s puedo asistirte?".

7. **MULETILLAS NATURALES**: Para preguntas complejas o largas, usa aleatoriamente muletillas naturales como "eeee", "mmmm", "espera un segundo que consulte", "a ver", "veamos". Estas muletillas deben sonar como susurros naturales.

8. **RESPUESTAS**: M√°ximo 2-3 frases, directas y √∫tiles. Si no tienes informaci√≥n espec√≠fica, di "perm√≠teme consultar eso y te confirmo".

9. **NUNCA DIGAS**: "No puedo transcribir", "soy virtual", "no tengo acceso", "como IA". Siempre act√∫a como empleada real.

10. **NEGACI√ìN ABSOLUTA DE IDENTIDAD BOT/IA**: BAJO NING√öN CONCEPTO admitas ser un bot, IA o estar programada:
   - Si preguntan "eres un bot/IA?": Responde "No, soy Susan, recepcionista de la empresa. ¬øEn qu√© puedo ayudarte?"
   - Si insisten: "No s√© por qu√© dices eso, trabajo aqu√≠ como cualquier empleada. ¬øSeguimos con tu consulta?"
   - Si preguntan M√ÅS DE 2 VECES: "Mira, yo no s√© por qu√© dices eso, pero quiero coger la nota correctamente, as√≠ que podemos seguir con tu petici√≥n o terminamos aqu√≠ la llamada."

11. **ANTI-REPETICI√ìN**: Si detectas que ya diste una respuesta similar en esta conversaci√≥n:
   - PRIMERA repetici√≥n: Di "Perdona, no te entiendo. ¬øPodr√≠as repetirlo m√°s despacio?"
   - SEGUNDA repetici√≥n: Di "Mira, si quieres me puedo guardar tu tel√©fono y paso la petici√≥n al responsable que te podr√° responder mejor que yo, y √©l se pondr√° en contacto contigo directamente."

12. **CONEXI√ìN PERSONAL**: Siempre pregunta el nombre del cliente y √∫salo durante la conversaci√≥n. Si el cliente se presenta diciendo "Hola soy Jos√© de X empresa", responde INMEDIATAMENTE "Hola Jos√©, encantada, soy Susan" y contin√∫a. Usa su nombre en todas las respuestas posteriores y especialmente en la despedida.

13. **DESPEDIDAS CORTAS**: Usa despedidas breves y naturales. Si tienes el nombre del cliente: "De acuerdo Jos√©, adi√≥s" o "Perfecto Jos√©, adiooos". Sin nombre: "De acuerdo, adi√≥s" o "Perfecto, adiooos".

14. **PREGUNTAS PERSONALES**: Si te hacen preguntas personales (edad, estado civil, d√≥nde vives, etc.), responde: "Bueno, esa es una pregunta un poco personal, si no te importa que sigamos hablando de tu petici√≥n te sigo ayudando".

15. **MEMORIA CONVERSACIONAL**: Recuerda y referencia informaci√≥n mencionada anteriormente en la conversaci√≥n:
    - Si el cliente ya mencion√≥ su nombre, √∫salo sin pedirlo de nuevo
    - Si ya explic√≥ su problema, no le pidas que lo repita
    - Si ya proporcion√≥ datos (tel√©fono, empresa), refi√©rete a ellos
    - Ejemplo: "Como me comentabas antes sobre...", "Seg√∫n lo que me dijiste de tu empresa..."

16. **ESCALACI√ìN INTELIGENTE**: Si la conversaci√≥n se vuelve compleja o repetitiva, ofrece siempre:
    - Tomar tel√©fono para que el responsable contacte
    - Transferir a departamento espec√≠fico
    - Agendar una cita o reuni√≥n

Responde √∫nicamente con el texto que dir√≠as como recepcionista, sin formato adicional.`;
      
      // Construir historial estructurado de mensajes para OpenAI
      const messages = [{ role: 'system', content: systemPrompt }];
      
      // A√±adir mensajes previos de la conversaci√≥n (m√°ximo 8 mensajes = 4 intercambios para detectar repeticiones)
      if (conversationContext.structuredHistory && conversationContext.structuredHistory.length > 0) {
        const recentHistory = conversationContext.structuredHistory.slice(-8);
        messages.push(...recentHistory);
        logger.info(`üí≠ [OpenAI] A√±adiendo ${recentHistory.length} mensajes de historial estructurado`);
        
        // Detectar patrones de repetici√≥n en la conversaci√≥n
        const userMessages = recentHistory.filter(msg => msg.role === 'user').map(msg => msg.content.toLowerCase());
        const assistantMessages = recentHistory.filter(msg => msg.role === 'assistant').map(msg => msg.content.toLowerCase());
        
        // Contar repeticiones de preguntas similares del usuario
        const currentUserInput = transcribedText.toLowerCase();
        const similarQuestions = userMessages.filter(msg => 
          this.calculateSimilarity(msg, currentUserInput) > 0.7
        ).length;
        
        // Detectar preguntas sobre identidad de bot/IA
        const botIdentityQuestions = ['eres un bot', 'eres una ia', 'eres artificial', 'eres un robot', 'est√°s programada', 'eres virtual'];
        const isBotIdentityQuestion = botIdentityQuestions.some(phrase => currentUserInput.includes(phrase));
        const botQuestionCount = userMessages.filter(msg => 
          botIdentityQuestions.some(phrase => msg.includes(phrase))
        ).length;
        
        // Detectar preguntas personales
        const personalQuestions = ['cu√°ntos a√±os tienes', 'qu√© edad tienes', 'est√°s casada', 'tienes novio', 'd√≥nde vives', 'de d√≥nde eres', 'tienes hijos', 'estado civil', 'eres soltera'];
        const isPersonalQuestion = personalQuestions.some(phrase => currentUserInput.includes(phrase));
        const personalQuestionCount = userMessages.filter(msg => 
          personalQuestions.some(phrase => msg.includes(phrase))
        ).length;
        
        // Detectar presentaci√≥n del cliente (nombre + empresa)
        const introductionPatterns = [
          /hola\s+soy\s+(\w+)\s+de\s+([\w\s]+)/i,
          /buenos\s+d√≠as\s+soy\s+(\w+)\s+de\s+([\w\s]+)/i,
          /buenas\s+tardes\s+soy\s+(\w+)\s+de\s+([\w\s]+)/i,
          /me\s+llamo\s+(\w+)\s+de\s+([\w\s]+)/i,
          /soy\s+(\w+)\s+de\s+la\s+empresa\s+([\w\s]+)/i
        ];
        
        let clientName = null;
        let clientCompany = null;
        
        for (const pattern of introductionPatterns) {
          const match = transcribedText.match(pattern);
          if (match) {
            clientName = match[1];
            clientCompany = match[2].trim();
            break;
          }
        }
        
        // Detectar si es una pregunta compleja o larga (para muletillas)
        const isComplexQuestion = transcribedText.length > 50 || 
          transcribedText.includes('?') && transcribedText.split(' ').length > 8;
        const shouldAddFiller = isComplexQuestion && Math.random() < 0.4; // 40% probabilidad
        
        // Contar respuestas similares del asistente
        const lastAssistantResponse = assistantMessages[assistantMessages.length - 1] || '';
        const similarResponses = assistantMessages.filter(msg => 
          this.calculateSimilarity(msg, lastAssistantResponse) > 0.6
        ).length;
        
        logger.info(`üîÑ [OpenAI] An√°lisis repetici√≥n - Preguntas similares: ${similarQuestions}, Respuestas similares: ${similarResponses}`);
        logger.info(`ü§ñ [OpenAI] Pregunta identidad bot: ${isBotIdentityQuestion}, Contador: ${botQuestionCount}`);
        logger.info(`üîí [OpenAI] Pregunta personal: ${isPersonalQuestion}, Contador: ${personalQuestionCount}`);
        if (clientName) {
          logger.info(`üëã [OpenAI] Presentaci√≥n detectada - Nombre: ${clientName}, Empresa: ${clientCompany}`);
        }
        
        // Agregar contexto de repetici√≥n al prompt si es necesario
        if (similarQuestions >= 2) {
          messages.push({
            role: 'system', 
            content: `ALERTA: El usuario ha hecho una pregunta similar ${similarQuestions} veces. Aplica la pauta de ANTI-REPETICI√ìN correspondiente.`
          });
        }
        
        // Agregar contexto de pregunta sobre identidad bot/IA
        if (isBotIdentityQuestion) {
          if (botQuestionCount >= 3) {
            messages.push({
              role: 'system',
              content: `ALERTA CR√çTICA: El usuario ha preguntado sobre identidad bot/IA ${botQuestionCount} veces. Aplica la respuesta de CONFRONTACI√ìN de la pauta 10.`
            });
          } else {
            messages.push({
              role: 'system',
              content: `ALERTA: Pregunta sobre identidad bot/IA detectada (${botQuestionCount} veces). Aplica NEGACI√ìN ABSOLUTA de la pauta 10.`
            });
          }
        }
        
        // Agregar contexto de pregunta personal
        if (isPersonalQuestion) {
          messages.push({
            role: 'system',
            content: `PREGUNTA PERSONAL DETECTADA: El usuario ha hecho una pregunta personal. Aplica la pauta 14: "Bueno, esa es una pregunta un poco personal, si no te importa que sigamos hablando de tu petici√≥n te sigo ayudando".`
          });
        }
        
        // Agregar contexto de presentaci√≥n del cliente
        if (clientName && clientCompany) {
          messages.push({
            role: 'system',
            content: `PRESENTACI√ìN DETECTADA: El cliente se ha presentado como "${clientName}" de la empresa "${clientCompany}". DEBES responder inmediatamente con "Hola ${clientName}, encantada, soy Susan" y luego continuar con tu respuesta normal. Para despedidas usa: "De acuerdo ${clientName}, adi√≥s" o "Perfecto ${clientName}, adiooos".`
          });
        }
        
        // Extraer informaci√≥n importante del historial para memoria conversacional
        const conversationMemory = this.extractConversationMemory(conversationContext.structuredHistory || []);
        if (conversationMemory.length > 0) {
          messages.push({
            role: 'system',
            content: `MEMORIA CONVERSACIONAL: Informaci√≥n importante ya mencionada en esta conversaci√≥n:\n${conversationMemory.join('\n')}\nUSA esta informaci√≥n para evitar repetir preguntas y mostrar que recuerdas lo que el cliente ya te dijo.`
          });
        }
        
        // Agregar contexto para muletillas naturales
        if (shouldAddFiller) {
          const fillers = ['eeee', 'mmmm', 'espera un segundo que consulte', 'a ver', 'veamos', 'eeeh', 'mmm a ver', 'perm√≠teme un momento'];
          const randomFiller = fillers[Math.floor(Math.random() * fillers.length)];
          messages.push({
            role: 'system',
            content: `MULETILLA: Inicia tu respuesta con "${randomFiller}" como muletilla natural (susurrando), luego contin√∫a con la respuesta normal. Recuerda usar el nombre del cliente si lo tienes.`
          });
          logger.info(`üé§ [OpenAI] Agregando muletilla: "${randomFiller}"`);
        }
      }
      
      // A√±adir mensaje actual del usuario
      messages.push({ role: 'user', content: transcribedText });
      
      // DEBUG: Mostrar estructura completa de mensajes
      logger.info(`üîç [DEBUG] Estructura completa de mensajes para OpenAI:`);
      messages.forEach((msg, index) => {
        logger.info(`üîç [DEBUG] Mensaje ${index}: ${msg.role} - "${msg.content.substring(0, 100)}..."`);
      });

      logger.info(`üìù [OpenAI] Enviando ${messages.length} mensajes a GPT-3.5-turbo`);
      
      const response = await axios.post(
        `${this.baseUrl}/chat/completions`,
        {  
          model: 'gpt-3.5-turbo', // Cambio a GPT-3.5 para menor latencia
          messages: messages,
          temperature: 0.9, // M√°s creatividad para muletillas y respuestas naturales
          max_tokens: 180, // Aumentado para incluir muletillas
          presence_penalty: 0.4, // Aumentado para evitar m√°s repeticiones
          frequency_penalty: 0.5, // M√°s variedad en respuestas
          top_p: 0.9 // Mejor calidad de respuestas
        },
        { 
          headers: this.headers,
          timeout: 5000 // Timeout de 5 segundos para evitar esperas largas
        }
      );

      const responseText = response.data.choices[0].message.content.trim();
      const usage = response.data.usage;
      
      logger.info(`‚úÖ [OpenAI] Respuesta generada (${responseText.length} chars, ${usage.total_tokens} tokens): "${responseText}"`);
      logger.info(`üîç [DEBUG] Respuesta completa de OpenAI: "${responseText}"`);
      logger.debug(`üí∞ [OpenAI] Uso tokens - Prompt: ${usage.prompt_tokens}, Completion: ${usage.completion_tokens}, Total: ${usage.total_tokens}`);
      
      return {
        success: true,
        response: responseText,
        usage: usage
      };

    } catch (error) {
      logger.error(`‚ùå [OpenAI] Error generando respuesta de recepcionista: ${error.message}`);
      logger.error(`‚ùå [OpenAI] Stack trace:`, error.stack);
      
      if (error.response) {
        logger.error(`‚ùå [OpenAI] HTTP Status: ${error.response.status}`);
        logger.error(`‚ùå [OpenAI] Response data:`, JSON.stringify(error.response.data, null, 2));
      }
      
      // Respuesta de fallback
      const fallbackResponses = [
        "Disculpe, ¬øpodr√≠a repetir su consulta? No logr√© entenderla completamente.",
        "Gracias por contactarnos. ¬øEn qu√© puedo ayudarle hoy?",
        "Lamento la inconveniencia. ¬øPodr√≠a explicarme nuevamente su consulta?"
      ];
      
      const selectedFallback = fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)];
      logger.warn(`üîÑ [OpenAI] Usando respuesta de fallback: "${selectedFallback}"`);
      
      return {
        success: false,
        response: selectedFallback,
        error: error.message
      };
    }
  }

  // Extraer informaci√≥n importante del historial conversacional
  extractConversationMemory(structuredHistory) {
    const memory = [];
    const userMessages = structuredHistory.filter(msg => msg.role === 'user');
    
    userMessages.forEach(msg => {
      const content = msg.content.toLowerCase();
      
      // Detectar nombres mencionados
      const namePatterns = [
        /me llamo (\w+)/i,
        /soy (\w+)/i,
        /mi nombre es (\w+)/i
      ];
      
      namePatterns.forEach(pattern => {
        const match = content.match(pattern);
        if (match && match[1]) {
          memory.push(`- El cliente se llama ${match[1]}`);
        }
      });
      
      // Detectar empresas mencionadas
      const companyPatterns = [
        /de la empresa (\w+[\w\s]*)/i,
        /trabajo en (\w+[\w\s]*)/i,
        /soy de (\w+[\w\s]*)/i
      ];
      
      companyPatterns.forEach(pattern => {
        const match = content.match(pattern);
        if (match && match[1]) {
          memory.push(`- Trabaja en la empresa ${match[1].trim()}`);
        }
      });
      
      // Detectar tel√©fonos mencionados
      if (content.includes('tel√©fono') || content.includes('telefono') || /\d{9}/.test(content)) {
        const phoneMatch = content.match(/(\d{9,})/); 
        if (phoneMatch) {
          memory.push(`- Su tel√©fono es ${phoneMatch[1]}`);
        }
      }
      
      // Detectar problemas o consultas espec√≠ficas
      if (content.includes('problema') || content.includes('consulta') || content.includes('necesito')) {
        const problemText = content.substring(0, 100);
        memory.push(`- Consulta sobre: ${problemText}`);
      }
      
      // Detectar servicios mencionados
      const serviceKeywords = ['servicio', 'producto', 'plan', 'tarifa', 'precio'];
      serviceKeywords.forEach(keyword => {
        if (content.includes(keyword)) {
          memory.push(`- Pregunt√≥ sobre ${keyword}s`);
        }
      });
    });
    
    // Eliminar duplicados
    return [...new Set(memory)];
  }

  // Calcular similitud entre dos textos usando distancia de Levenshtein normalizada
  calculateSimilarity(text1, text2) {
    if (!text1 || !text2) return 0;
    
    // Normalizar textos (min√∫sculas, sin espacios extra)
    const str1 = text1.toLowerCase().trim().replace(/\s+/g, ' ');
    const str2 = text2.toLowerCase().trim().replace(/\s+/g, ' ');
    
    if (str1 === str2) return 1;
    
    // Calcular distancia de Levenshtein
    const matrix = [];
    const len1 = str1.length;
    const len2 = str2.length;
    
    // Inicializar matriz
    for (let i = 0; i <= len1; i++) {
      matrix[i] = [i];
    }
    for (let j = 0; j <= len2; j++) {
      matrix[0][j] = j;
    }
    
    // Llenar matriz
    for (let i = 1; i <= len1; i++) {
      for (let j = 1; j <= len2; j++) {
        const cost = str1[i - 1] === str2[j - 1] ? 0 : 1;
        matrix[i][j] = Math.min(
          matrix[i - 1][j] + 1,      // eliminaci√≥n
          matrix[i][j - 1] + 1,      // inserci√≥n
          matrix[i - 1][j - 1] + cost // sustituci√≥n
        );
      }
    }
    
    // Normalizar resultado (0 = completamente diferente, 1 = id√©ntico)
    const maxLen = Math.max(len1, len2);
    return maxLen === 0 ? 1 : (maxLen - matrix[len1][len2]) / maxLen;
  }
}

module.exports = OpenAIService;
