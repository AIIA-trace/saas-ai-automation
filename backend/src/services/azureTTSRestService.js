const axios = require('axios');
const logger = require('../utils/logger');
const fs = require('fs');

class AzureTTSRestService {
  constructor() {
    // DEBUG: Credenciales hardcodeadas
    this.subscriptionKey = '3iouAt5oVcf6Nu91XSU9Igrpfjy6iLhD4W9YgKxZArDjS8Fhdnb7JQQJ99BIAC5RqLJXJ3w3AAAYACOGorTt';
    this.region = 'westeurope';
    this.token = null;
    this.tokenExpiration = 0;
    this.isWarmedUp = false;
    this.warmupPromise = null;
  }

  async getToken() {
    if (this.token && Date.now() < this.tokenExpiration) {
      return this.token;
    }

    return await this.getAuthToken();
  }

  /**
   * Pre-autentica Azure TTS para evitar cuelgues durante llamadas reales
   */
  async warmup() {
    if (this.isWarmedUp && this.warmupPromise) {
      logger.info('ğŸ”¥ AZURE WARMUP: Ya estÃ¡ en progreso, esperando...');
      return await this.warmupPromise;
    }

    if (this.isWarmedUp) {
      logger.info('âœ… AZURE WARMUP: Ya completado previamente');
      return true;
    }

    logger.info('ğŸ”¥ AZURE WARMUP: Iniciando pre-autenticaciÃ³n...');
    
    this.warmupPromise = this._performWarmup();
    const result = await this.warmupPromise;
    
    if (result) {
      this.isWarmedUp = true;
      logger.info('âœ… AZURE WARMUP: Completado exitosamente');
    } else {
      logger.error('âŒ AZURE WARMUP: FallÃ³');
    }
    
    return result;
  }

  async _performWarmup() {
    try {
      // Pre-autenticar para obtener token
      logger.info('ğŸ”¥ WARMUP: Obteniendo token de autenticaciÃ³n...');
      const token = await this.getAuthToken();
      
      if (!token) {
        logger.error('âŒ WARMUP: No se pudo obtener token');
        return false;
      }

      // Generar audio de prueba muy corto para calentar el pipeline
      logger.info('ğŸ”¥ WARMUP: Generando audio de prueba...');
      const text = "Warmup";
      const testResult = await this.generateSpeech(text, 'es-ES-DarioNeural');
      
      if (!testResult.success) {
        logger.error('âŒ WARMUP: Audio de prueba fallÃ³');
        return false;
      }

      logger.info('âœ… WARMUP: Pipeline completo verificado');
      return true;
      
    } catch (error) {
      logger.error(`âŒ WARMUP: Error durante warmup: ${error.message}`);
      return false;
    }
  }

  async getAuthToken() {
    const authId = `AUTH_${Date.now()}`;
    logger.info(`ğŸ” [${authId}] Solicitando NUEVO token de Azure...`);
    
    try {
      const response = await axios.post(
        `https://${this.region}.api.cognitive.microsoft.com/sts/v1.0/issueToken`,
        null,
        {
          headers: {
            'Ocp-Apim-Subscription-Key': this.subscriptionKey,
            'Content-Type': 'application/x-www-form-urlencoded'
          },
          timeout: 10000
        }
      );
      
      this.token = response.data;
      this.tokenExpiration = Date.now() + 9 * 60 * 1000; // 9 minutos de validez
      
      logger.info(`ğŸ” [${authId}] âœ… Token obtenido y cacheado por 9 minutos`);
      return this.token;

    } catch (error) {
      logger.error(`âŒ [${authId}] Error obteniendo token: ${error.message}`);
      
      if (error.response?.status === 401) {
        logger.error(`ğŸ” [${authId}] UNAUTHORIZED - Key invÃ¡lida`);
      } else if (error.response?.status === 403) {
        logger.error(`ğŸ” [${authId}] FORBIDDEN - Sin permisos`);
      } else if (error.response?.status === 429) {
        logger.error(`ğŸ” [${authId}] RATE LIMIT - Demasiadas peticiones`);
      }
      
      throw error;
    }
  }

  async generateSpeech(text, voice, format) {
    // Ignorar cualquier formato recibido y forzar mulaw
    const finalFormat = 'raw-8khz-8bit-mono-mulaw';
    
    // MAPEAR FORMATO PARA TWILIO COMPATIBILITY
    let azureFormat = finalFormat;
    if (finalFormat === 'raw-8khz-8bit-mono-mulaw') {
      azureFormat = 'raw-8khz-8bit-mono-mulaw';
      logger.info(`ğŸµ Usando formato mulaw directo para Twilio: ${azureFormat}`);
    }
    const speechStartTime = Date.now();
    const startTime = speechStartTime;
    console.log(`ğŸ”Š ===== AZURE TTS AUDIO GENERATION START =====`);
    console.log(`â° Timestamp: ${new Date().toISOString()}`);
    
    try {
      // ANÃLISIS COMPLETO DE ENTRADA
      console.log(`ğŸ“ INPUT ANALYSIS:`);
      console.log(`  â”œâ”€â”€ Text received: "${text ? text.substring(0, 100) : 'NULL/UNDEFINED'}..."`);
      console.log(`  â”œâ”€â”€ Text type: ${typeof text}`);
      console.log(`  â”œâ”€â”€ Text length: ${text ? text.length : 0}`);
      console.log(`  â”œâ”€â”€ Text is empty: ${!text || text.trim().length === 0}`);
      console.log(`  â”œâ”€â”€ Voice requested: "${voice}"`);
      console.log(`  â”œâ”€â”€ Voice type: ${typeof voice}`);
      console.log(`  â”œâ”€â”€ Format: "${finalFormat}" (PCM para conversiÃ³n a mulaw)`);
      console.log(`  â””â”€â”€ Region: "${this.region}"`);
      
      // Validar que el texto no estÃ© vacÃ­o
      if (!text || text.trim().length === 0) {
        console.error('âŒ EMPTY TEXT ERROR:');
        console.error('  â”œâ”€â”€ Text is null/undefined or empty');
        console.error('  â”œâ”€â”€ This will cause empty audio generation');
        console.error('  â””â”€â”€ Check database query and client configuration');
        return { 
          success: false, 
          error: 'Texto vacÃ­o o undefined',
          cause: 'EMPTY_TEXT',
          textReceived: text,
          voiceReceived: voice
        };
      }

      console.log(`ğŸ”Š ===== AZURE TTS DEBUG START =====`);
      console.log(`ğŸ”Š Texto: "${text.substring(0, 100)}..."`);
      console.log(`ğŸ”Š Voz solicitada: "${voice}"`);
      console.log(`ğŸ”Š Formato: "${finalFormat}" (PCM 16kHz 16-bit mono)`);
      console.log(`ğŸ”Š RazÃ³n del formato: PCM es fÃ¡cil de convertir a mulaw para Twilio`);
      
      // Validar voz antes de usar
      const validVoices = [
        'es-ES-DarioNeural', 'es-ES-ElviraNeural', 'es-ES-AlvaroNeural',
        'en-US-LolaMultilingualNeural', 'es-ES-ArabellaMultilingualNeural'
      ];
      
      if (!validVoices.includes(voice)) {
        console.log(`âš ï¸ VOZ NO VÃLIDA: "${voice}" no estÃ¡ en la lista de voces vÃ¡lidas`);
        console.log(`âš ï¸ Voces vÃ¡lidas: ${validVoices.join(', ')}`);
        console.log(`âš ï¸ Usando fallback: es-ES-DarioNeural`);
        voice = 'es-ES-DarioNeural';
      } else {
        console.log(`âœ… VOZ VÃLIDA: "${voice}" estÃ¡ en la lista de voces vÃ¡lidas`);
      }
      
      const token = await this.getToken();
      
      const ssml = `
        <speak version='1.0' xml:lang='es-ES'>
          <voice name='${voice}'>
            ${text}
          </voice>
        </speak>
      `;

      console.log(`ğŸ” SSML Final:`, ssml);
      console.log(`ğŸ” SSML Length:`, ssml.length);
      console.log(`ğŸ” Token exists:`, !!token);
      console.log(`ğŸ” Token length:`, token ? token.length : 0);
      console.log(`ğŸ” Request URL:`, `https://${this.region}.tts.speech.microsoft.com/cognitiveservices/v1`);
      
      console.log(`ğŸ”Š Texto enviado a Azure TTS: ${text}`);
      
      const requestConfig = {
        headers: {
          'Ocp-Apim-Subscription-Key': this.subscriptionKey,
          'Content-Type': 'application/ssml+xml',
          'X-Microsoft-OutputFormat': finalFormat,
          'User-Agent': 'Mozilla/5.0 (compatible; TTS-Service/1.0)',
          'Accept': 'audio/wav, audio/*',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
          // Headers adicionales para identificarse como aplicaciÃ³n legÃ­tima
          'X-Forwarded-For': '127.0.0.1',
          'X-Real-IP': '127.0.0.1',
          'Origin': 'https://speech.microsoft.com'
        },
        responseType: 'arraybuffer',
        timeout: 15000, // 15 segundos timeout explÃ­cito
        maxRedirects: 0 // No seguir redirects
      };
      
      console.log(`ğŸ” Request Headers:`, JSON.stringify(requestConfig.headers, null, 2));
      
      // HACER LA PETICIÃ“N HTTP CON TIMEOUT
      const timeoutPromise = new Promise((_, reject) => {
        setTimeout(() => {
          reject(new Error('AGGRESSIVE_TIMEOUT: Auth request hung after 1000ms'));
        }, 1000);
      });
      
      const requestPromise = axios.post(
        `https://${this.region}.tts.speech.microsoft.com/cognitiveservices/v1`,
        ssml,
        requestConfig
      );
      
      // DETECTAR CONTEXTO DE LLAMADA
      const isInCall = process.env.TWILIO_CALL_ACTIVE === 'true' || global.activeTwilioStreams > 0;
      console.log(`ğŸš€ Starting Azure TTS request with 1s timeout...`);
      console.log(`ğŸ“ CONTEXTO DE LLAMADA:`);
      console.log(`  â”œâ”€â”€ En llamada activa: ${isInCall}`);
      console.log(`  â”œâ”€â”€ Streams activos: ${global.activeTwilioStreams || 0}`);
      console.log(`  â”œâ”€â”€ Variables entorno Twilio: ${Object.keys(process.env).filter(k => k.includes('TWILIO')).length}`);
      console.log(`  â””â”€â”€ Timestamp: ${new Date().toISOString()}`);
      
      const response = await Promise.race([requestPromise, timeoutPromise]);
      
      console.log(`ğŸ”Š Azure TTS Response Status: ${response.status}`);
      console.log(`ğŸ”Š Azure TTS Response Headers: ${JSON.stringify(response.headers)}`);
      
      const requestEndTime = Date.now();
      const requestDuration = requestEndTime - speechStartTime;
      
      console.log(`âœ… AZURE RESPONSE ANALYSIS:`);
      console.log(`  â”œâ”€â”€ Status Code: ${response.status}`);
      console.log(`  â”œâ”€â”€ Content-Type: ${response.headers['content-type']}`);
      console.log(`  â”œâ”€â”€ Audio Buffer Length: ${response.data ? response.data.length : 0} bytes`);
      console.log(`  â”œâ”€â”€ Audio Buffer Type: ${response.data ? typeof response.data : 'undefined'}`);
      console.log(`  â”œâ”€â”€ Audio Buffer Empty: ${!response.data || response.data.length === 0}`);
      console.log(`  â”œâ”€â”€ Request Duration: ${requestDuration}ms`);
      console.log(`  â”œâ”€â”€ Total Process Time: ${Date.now() - speechStartTime}ms`);
      
      // ğŸ” ANÃLISIS DETALLADO DEL AUDIO BUFFER
      console.log(`  â””â”€â”€ ğŸµ AUDIO BUFFER DEEP ANALYSIS:`);
      if (response.data && response.data.length > 0) {
        const buffer = Buffer.from(response.data);
        console.log(`      â”œâ”€â”€ Buffer is valid: ${Buffer.isBuffer(buffer)}`);
        console.log(`      â”œâ”€â”€ Buffer length: ${buffer.length} bytes`);
        console.log(`      â”œâ”€â”€ First 16 bytes (hex): ${buffer.subarray(0, 16).toString('hex')}`);
        console.log(`      â”œâ”€â”€ First 16 bytes (ascii): ${buffer.subarray(0, 16).toString('ascii').replace(/[^\x20-\x7E]/g, '.')}`);
        
        // Verificar si es un archivo PCM vÃ¡lido (debe empezar con RIFF)
        const header = buffer.subarray(0, 4).toString('ascii');
        console.log(`      â”œâ”€â”€ Audio header: "${header}"`);
        console.log(`      â”œâ”€â”€ Is RIFF format: ${header === 'RIFF'}`);
        
        if (header === 'RIFF') {
          const waveHeader = buffer.subarray(8, 12).toString('ascii');
          console.log(`      â”œâ”€â”€ WAVE header: "${waveHeader}"`);
          console.log(`      â”œâ”€â”€ Is valid WAVE: ${waveHeader === 'WAVE'}`);
          
          // Obtener informaciÃ³n del formato
          const fmtChunk = buffer.indexOf('fmt ');
          if (fmtChunk !== -1) {
            const audioFormat = buffer.readUInt16LE(fmtChunk + 8);
            const channels = buffer.readUInt16LE(fmtChunk + 10);
            const sampleRate = buffer.readUInt32LE(fmtChunk + 12);
            const bitsPerSample = buffer.readUInt16LE(fmtChunk + 22);
            
            console.log(`      â”œâ”€â”€ Audio Format: ${audioFormat} (1=PCM)`);
            console.log(`      â”œâ”€â”€ Channels: ${channels}`);
            console.log(`      â”œâ”€â”€ Sample Rate: ${sampleRate} Hz`);
            console.log(`      â”œâ”€â”€ Bits per Sample: ${bitsPerSample}`);
            
            // Buscar el chunk de datos
            const dataChunk = buffer.indexOf('data');
            if (dataChunk !== -1) {
              const dataSize = buffer.readUInt32LE(dataChunk + 4);
              console.log(`      â”œâ”€â”€ Data chunk size: ${dataSize} bytes`);
              console.log(`      â”œâ”€â”€ Audio duration: ~${(dataSize / (sampleRate * channels * (bitsPerSample/8))).toFixed(2)}s`);
              console.log(`      â””â”€â”€ âœ… VALID PCM AUDIO DETECTED`);
            } else {
              console.log(`      â””â”€â”€ âŒ NO DATA CHUNK FOUND - Invalid audio`);
            }
          } else {
            console.log(`      â””â”€â”€ âŒ NO FMT CHUNK FOUND - Invalid audio`);
          }
        } else {
          console.log(`      â”œâ”€â”€ Unknown format header: "${header}"`);
          console.log(`      â”œâ”€â”€ Expected: "RIFF" for PCM audio`);
          console.log(`      â””â”€â”€ âŒ INVALID AUDIO FORMAT - Not PCM`);
        }
        
        // Verificar si el buffer contiene solo zeros (audio silencioso)
        const nonZeroBytes = buffer.filter(byte => byte !== 0).length;
        const zeroPercentage = ((buffer.length - nonZeroBytes) / buffer.length * 100).toFixed(1);
        console.log(`      â”œâ”€â”€ Non-zero bytes: ${nonZeroBytes}/${buffer.length}`);
        console.log(`      â”œâ”€â”€ Zero percentage: ${zeroPercentage}%`);
        
        if (zeroPercentage > 95) {
          console.log(`      â””â”€â”€ âš ï¸ MOSTLY SILENT AUDIO - ${zeroPercentage}% zeros`);
        } else if (zeroPercentage > 50) {
          console.log(`      â””â”€â”€ âš ï¸ PARTIALLY SILENT AUDIO - ${zeroPercentage}% zeros`);
        } else {
          console.log(`      â””â”€â”€ âœ… AUDIO HAS CONTENT - ${zeroPercentage}% zeros`);
        }
      } else {
        console.log(`      â””â”€â”€ âŒ NO AUDIO BUFFER - Azure returned empty response`);
      }
      
      console.log(`  â””â”€â”€ ğŸ¯ LATENCY ANALYSIS:`);
      
      // ANÃLISIS DETALLADO DE LATENCIA
      if (requestDuration > 3000) {
        console.log(`      â”œâ”€â”€ âš ï¸ HIGH LATENCY DETECTED: ${requestDuration}ms > 3000ms`);
        console.log(`      â”œâ”€â”€ ğŸ” POSSIBLE CAUSES:`);
        console.log(`      â”‚   â”œâ”€â”€ Network latency to Azure ${this.region}`);
        console.log(`      â”‚   â”œâ”€â”€ Azure TTS service overload`);
        console.log(`      â”‚   â”œâ”€â”€ Large text processing time`);
        console.log(`      â”‚   â””â”€â”€ Production environment resource limits`);
        console.log(`      â””â”€â”€ ğŸ’¡ RECOMMENDATIONS:`);
        console.log(`          â”œâ”€â”€ Try different Azure region (eastus, centralus)`);
        console.log(`          â”œâ”€â”€ Reduce text length or complexity`);
        console.log(`          â”œâ”€â”€ Pre-generate common phrases`);
        console.log(`          â””â”€â”€ Implement caching for repeated texts`);
      } else if (requestDuration > 1000) {
        console.log(`      â”œâ”€â”€ âš ï¸ MODERATE LATENCY: ${requestDuration}ms > 1000ms`);
        console.log(`      â””â”€â”€ ğŸ’¡ Consider optimization if this persists`);
      } else {
        console.log(`      â””â”€â”€ âœ… GOOD LATENCY: ${requestDuration}ms < 1000ms`);
      }
      
      // ğŸ” VALIDACIÃ“N EXHAUSTIVA DEL AUDIO BUFFER
      if (!response.data || response.data.length === 0) {
        console.error(`âŒ EMPTY AUDIO BUFFER DETECTED:`);
        console.error(`  â”œâ”€â”€ Azure returned empty or null audio data`);
        console.error(`  â”œâ”€â”€ This will cause silent audio playback`);
        console.error(`  â”œâ”€â”€ Status was ${response.status} but no audio content`);
        console.error(`  â”œâ”€â”€ Content-Type: ${response.headers['content-type']}`);
        console.error(`  â”œâ”€â”€ Response Headers: ${JSON.stringify(response.headers)}`);
        console.error(`  â””â”€â”€ ğŸ¯ ROOT CAUSE: Azure TTS generated no audio`);
        
        return {
          success: false,
          error: 'Audio buffer vacÃ­o desde Azure - TTS no generÃ³ audio',
          cause: 'EMPTY_AUDIO_BUFFER',
          statusCode: response.status,
          contentType: response.headers['content-type'],
          responseHeaders: response.headers,
          diagnosis: 'Azure TTS responded with HTTP 200 but no audio content'
        };
      }
      
      // ğŸ” VALIDACIÃ“N DE FORMATO DE AUDIO
      const buffer = Buffer.from(response.data);
      const header = buffer.subarray(0, 4).toString('ascii');
      
      // Validar formato segÃºn lo solicitado
      if (!finalFormat.includes('mulaw')) {
        logger.warn(`âš ï¸ Formato forzado a mulaw: ${finalFormat} no es nativo Twilio`);
        finalFormat = 'raw-8khz-8bit-mono-mulaw';
      }
      if (finalFormat === 'raw-8khz-8bit-mono-mulaw') {
        // Para mulaw, no esperamos header RIFF
        console.log(`ğŸµ MULAW FORMAT VALIDATION:`);
        console.log(`  â”œâ”€â”€ Format requested: ${finalFormat}`);
        console.log(`  â”œâ”€â”€ Buffer length: ${buffer.length} bytes`);
        console.log(`  â”œâ”€â”€ First 16 bytes: ${buffer.subarray(0, 16).toString('hex')}`);
        console.log(`  â””â”€â”€ âœ… Raw mulaw format - no RIFF header expected`);
      } else {
        // Para PCM, esperamos header RIFF
        if (header !== 'RIFF') {
          console.error(`âŒ INVALID AUDIO FORMAT DETECTED:`);
          console.error(`  â”œâ”€â”€ Expected: "RIFF" header for PCM audio`);
          console.error(`  â”œâ”€â”€ Received: "${header}" (${buffer.subarray(0, 4).toString('hex')})`);
          console.error(`  â”œâ”€â”€ Buffer length: ${buffer.length} bytes`);
          console.error(`  â”œâ”€â”€ First 32 bytes: ${buffer.subarray(0, 32).toString('hex')}`);
          console.error(`  â””â”€â”€ ğŸ¯ ROOT CAUSE: Azure returned invalid audio format`);
          
          return {
            success: false,
            error: 'Formato de audio invÃ¡lido desde Azure',
            cause: 'INVALID_AUDIO_FORMAT',
            expectedHeader: 'RIFF',
            receivedHeader: header,
            bufferLength: buffer.length,
            diagnosis: 'Azure TTS returned data but not in expected PCM format'
          };
        }
      }
      
      // ğŸ” VALIDACIÃ“N DE CONTENIDO DE AUDIO (SILENCIO)
      let nonZeroBytes, zeroPercentage;
      
      if (finalFormat === 'raw-8khz-8bit-mono-mulaw') {
        // Para mulaw, el silencio es 0xFF (255), no 0x00
        const silentBytes = buffer.filter(byte => byte === 0xFF).length;
        nonZeroBytes = buffer.length - silentBytes;
        zeroPercentage = (silentBytes / buffer.length * 100);
        
        console.log(`ğŸµ MULAW SILENCE ANALYSIS:`);
        console.log(`  â”œâ”€â”€ Silent bytes (0xFF): ${silentBytes}/${buffer.length}`);
        console.log(`  â”œâ”€â”€ Audio bytes: ${nonZeroBytes}/${buffer.length}`);
        console.log(`  â””â”€â”€ Silence percentage: ${zeroPercentage.toFixed(1)}%`);
      } else {
        // Para PCM, el silencio es 0x00
        nonZeroBytes = buffer.filter(byte => byte !== 0).length;
        zeroPercentage = ((buffer.length - nonZeroBytes) / buffer.length * 100);
      }
      
      if (zeroPercentage > 95) {
        console.error(`âŒ SILENT AUDIO DETECTED:`);
        console.error(`  â”œâ”€â”€ Audio buffer is ${zeroPercentage.toFixed(1)}% silent`);
        console.error(`  â”œâ”€â”€ Non-silent bytes: ${nonZeroBytes}/${buffer.length}`);
        console.error(`  â”œâ”€â”€ This will result in no audible sound`);
        console.error(`  â””â”€â”€ ğŸ¯ ROOT CAUSE: Azure generated silent/empty audio`);
        
        return {
          success: false,
          error: 'Audio silencioso generado por Azure',
          cause: 'SILENT_AUDIO',
          zeroPercentage: zeroPercentage,
          nonZeroBytes: nonZeroBytes,
          totalBytes: buffer.length,
          diagnosis: 'Azure TTS generated valid format but silent audio content'
        };
      }
      
      console.log(`ğŸ”Š ===== AZURE TTS DEBUG SUCCESS =====`);
      console.log(`âœ… AUDIO VALIDATION PASSED:`);
      
      if (finalFormat === 'raw-8khz-8bit-mono-mulaw') {
        console.log(`  â”œâ”€â”€ Valid RAW mulaw format: âœ“`);
        console.log(`  â”œâ”€â”€ Audio content present: âœ“ (${zeroPercentage.toFixed(1)}% silent)`);
        console.log(`  â”œâ”€â”€ Buffer size: ${buffer.length} bytes`);
        console.log(`  â””â”€â”€ Ready for direct Twilio streaming (no conversion needed)`);
      } else {
        console.log(`  â”œâ”€â”€ Valid RIFF/PCM format: âœ“`);
        console.log(`  â”œâ”€â”€ Audio content present: âœ“ (${zeroPercentage.toFixed(1)}% zeros)`);
        console.log(`  â”œâ”€â”€ Buffer size: ${buffer.length} bytes`);
        console.log(`  â””â”€â”€ Ready for mulaw conversion and Twilio streaming`);
      }
      
      // Function to trim leading silence from raw mulaw buffer
      function trimLeadingSilence(audioBuffer) {
        // Mulaw silence is represented by 0xFF (or 0x7F in some encodings)
        // We'll skip all 0xFF bytes at the start
        let i = 0;
        const maxSilence = 24000; // Max 3 seconds of silence (8000 samples per second)
        
        while (i < audioBuffer.length && i < maxSilence) {
          if (audioBuffer[i] !== 0xFF) {
            break;
          }
          i++;
        }
        
        return audioBuffer.slice(i);
      }

      const trimmedBuffer = trimLeadingSilence(buffer);

      // Save audio to file
      const fileName = `/tmp/debug_${Date.now()}.wav`;
      try {
        fs.writeFileSync(fileName, trimmedBuffer);
        logger.info(`ğŸ”§ Audio guardado en ${fileName}`);
      } catch (error) {
        logger.error(`âŒ Error guardando audio: ${error.message}`);
      }
      
      return {
        success: true,
        audioBuffer: trimmedBuffer,
        contentType: response.headers['content-type'],
        audioAnalysis: {
          format: finalFormat === 'raw-8khz-8bit-mono-mulaw' ? 'RAW_MULAW' : 'RIFF/PCM',
          bufferSize: buffer.length,
          zeroPercentage: zeroPercentage,
          nonZeroBytes: nonZeroBytes,
          isValid: true
        }
      };

    } catch (error) {
      const errorDuration = Date.now() - startTime;
      console.error('ğŸ”Š ===== AZURE TTS ERROR ANALYSIS =====');
      console.error('âŒ VOZ USADA EN ERROR:', voice);
      console.error('âŒ TEXTO ENVIADO:', text.substring(0, 100));
      console.error('âŒ FORMATO SOLICITADO:', finalFormat);
      console.error('âŒ REGIÃ“N AZURE:', this.region);
      console.error('âŒ ERROR DURATION:', errorDuration + 'ms');
      
      // DETECTAR TIMEOUT ESPECÃFICAMENTE (incluyendo el agresivo)
      if (error.message?.includes('TTS_AGGRESSIVE_TIMEOUT')) {
        console.error('ğŸ”Š ===== AGGRESSIVE TTS TIMEOUT DETECTED =====');
        console.error('â° AGGRESSIVE TIMEOUT ANALYSIS:');
        console.error(`  â”œâ”€â”€ Duration: ${errorDuration}ms`);
        console.error(`  â”œâ”€â”€ Aggressive Timeout Limit: 7000ms`);
        console.error(`  â”œâ”€â”€ Region: ${this.region}`);
        console.error(`  â”œâ”€â”€ Text Length: ${text?.length || 0} chars`);
        console.error('  â””â”€â”€ ğŸ¯ ROOT CAUSE: TTS se colgÃ³ en producciÃ³n (Render issue)');
        console.error('      â”œâ”€â”€ Azure TTS hanging in containerized environment');
        console.error('      â”œâ”€â”€ Render resource limits causing process hang');
        console.error('      â”œâ”€â”€ Event loop blocking in production');
        console.error('      â””â”€â”€ Network/DNS resolution issues');
        
        return {
          success: false,
          error: 'Azure TTS colgado en producciÃ³n - usando fallback',
          cause: 'TTS_HANGING_IN_PRODUCTION',
          duration: errorDuration,
          timeout: 7000,
          region: this.region,
          isProductionHang: true,
          recommendations: [
            'Usar audio de fallback inmediatamente',
            'Implementar cache de audio pre-generado',
            'Considerar servicio TTS alternativo',
            'Monitorear recursos de Render'
          ]
        };
      } else if (error.code === 'ECONNABORTED' || error.message?.includes('timeout')) {
        console.error('ğŸ”Š ===== STANDARD TIMEOUT ERROR DETECTED =====');
        console.error('â° TIMEOUT ANALYSIS:');
        console.error(`  â”œâ”€â”€ Duration: ${errorDuration}ms`);
        console.error(`  â”œâ”€â”€ Timeout Limit: 10000ms`);
        console.error(`  â”œâ”€â”€ Region: ${this.region}`);
        console.error(`  â”œâ”€â”€ Text Length: ${text?.length || 0} chars`);
        console.error('  â””â”€â”€ ğŸ¯ ROOT CAUSE ANALYSIS:');
        console.error('      â”œâ”€â”€ Azure TTS service is slow in production');
        console.error('      â”œâ”€â”€ Network latency from Render to Azure westeurope');
        console.error('      â”œâ”€â”€ Render resource limits affecting HTTP requests');
        console.error('      â””â”€â”€ Azure service overload or maintenance');
        
        return {
          success: false,
          error: 'Azure TTS timeout - servicio no responde',
          cause: 'TIMEOUT_ERROR',
          duration: errorDuration,
          timeout: 10000,
          region: this.region,
          recommendations: [
            'Cambiar regiÃ³n a eastus o centralus',
            'Reducir longitud del texto',
            'Implementar cache de audio',
            'Usar audio pre-generado como fallback'
          ]
        };
      }
      
      // ANÃLISIS ESPECÃFICO DEL ERROR 400
      if (error.response?.status === 400) {
        console.error('ğŸ” ERROR 400 - BAD REQUEST ANALYSIS:');
        console.error('  â”œâ”€â”€ Status Code:', error.response.status);
        console.error('  â”œâ”€â”€ Status Text:', error.response.statusText);
        console.error('  â”œâ”€â”€ Azure Region Used:', this.region);
        console.error('  â”œâ”€â”€ Voice Name Sent:', voice);
        console.error('  â”œâ”€â”€ SSML Length:', ssml?.length || 'undefined');
        console.error('  â”œâ”€â”€ Text Length:', text?.length || 'undefined');
        console.error('  â”œâ”€â”€ Format Requested:', finalFormat);
        
        // Analizar respuesta de Azure
        if (error.response.data) {
          const errorData = Buffer.isBuffer(error.response.data) 
            ? error.response.data.toString('utf8') 
            : error.response.data;
          console.error('  â”œâ”€â”€ Azure Error Response:', errorData);
          
          // Buscar mensajes especÃ­ficos de error
          if (typeof errorData === 'string') {
            if (errorData.includes('voice')) {
              console.error('  â”œâ”€â”€ ğŸ¯ VOICE ERROR DETECTED in response');
            }
            if (errorData.includes('Unsupported')) {
              console.error('  â”œâ”€â”€ ğŸ¯ UNSUPPORTED ERROR DETECTED in response');
            }
            if (errorData.includes('Invalid')) {
              console.error('  â”œâ”€â”€ ğŸ¯ INVALID ERROR DETECTED in response');
            }
          }
        }
        
        // Verificar headers de la peticiÃ³n
        console.error('  â”œâ”€â”€ Request Headers Sent:');
        console.error('  â”‚   â”œâ”€â”€ Authorization:', error.config?.headers?.Authorization ? 'Present' : 'Missing');
        console.error('  â”‚   â”œâ”€â”€ Content-Type:', error.config?.headers['Content-Type']);
        console.error('  â”‚   â””â”€â”€ X-Microsoft-OutputFormat:', error.config?.headers['X-Microsoft-OutputFormat']);
        
        // Verificar SSML
        console.error('  â”œâ”€â”€ SSML Analysis:');
        console.error('  â”‚   â”œâ”€â”€ SSML Valid XML:', ssml ? 'Present' : 'Missing');
        console.error('  â”‚   â”œâ”€â”€ Voice Tag:', ssml?.includes(`<voice name='${voice}'>`) ? 'Correct' : 'Incorrect');
        console.error('  â”‚   â””â”€â”€ Language Tag:', ssml?.includes("xml:lang='es-ES'") ? 'Present' : 'Missing');
        
        console.error('  â””â”€â”€ ğŸ” POSSIBLE CAUSES:');
        console.error('      â”œâ”€â”€ Invalid voice name for region');
        console.error('      â”œâ”€â”€ Unsupported output format');
        console.error('      â”œâ”€â”€ Malformed SSML');
        console.error('      â””â”€â”€ Authentication/authorization issue');
      }
      
      console.error('âŒ Full Error Details:');
      console.error('  Status:', error.response?.status);
      console.error('  Status Text:', error.response?.statusText);
      console.error('  Response Data:', error.response?.data);
      console.error('  Response Headers:', error.response?.headers);
      console.error('  Request URL:', error.config?.url);
      console.error('  Request Method:', error.config?.method);
      console.error('  Request Headers:', error.config?.headers);
      console.error('  Request Data Length:', error.config?.data?.length);
      console.error('  Error Message:', error.message);
      console.error('  Error Code:', error.code);
      
      // Si hay response data, intentar parsearlo
      if (error.response?.data) {
        const errorText = Buffer.isBuffer(error.response.data) ? error.response.data.toString('utf8') : error.response.data;
        console.error('  Parsed Error Response:', errorText);
      }
      
      console.error('ğŸ”Š ===== AZURE TTS DEBUG ERROR END =====');
      
      // Log final de diagnÃ³stico
      console.error('ğŸ”§ DIAGNOSTIC SUMMARY:');
      console.error(`  Voice: "${voice}" | Text: "${text.substring(0, 50)}..." | Status: ${error.response?.status}`);
      console.error(`  Region: ${this.region} | Format: ${finalFormat}`);
      
      return {
        success: false,
        error: error.message,
        statusCode: error.response?.status,
        azureError: error.response?.data,
        voiceUsed: voice,
        textSent: text.substring(0, 100),
        region: this.region,
        format: finalFormat
      };
    }
  }
}

// Crear instancia del servicio
const azureTTSRestServiceInstance = new AzureTTSRestService();

// AÃ±adir mÃ©todo initialize
azureTTSRestServiceInstance.initialize = function() {
  console.log('âœ… Azure TTS REST Service initialized');
  // ConfiguraciÃ³n inicial si es necesaria
};

// Exportar la instancia
module.exports = azureTTSRestServiceInstance;
